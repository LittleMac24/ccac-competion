{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Load Datasets<H1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "bracket_training = pd.read_csv(f\"{path}/bracket_training.csv\", sep= \",\")\n",
    "# bracket_training\n",
    "\n",
    "bracket_test = pd.read_csv(f'{path}/bracket_test.csv')\n",
    "\n",
    "college_info = pd.read_csv(f'{path}/institutions.csv', sep = ',', encoding= 'utf-8')\n",
    "\n",
    "df_kenpom = pd.read_csv('Kenpom Data.csv')\n",
    "\n",
    "distances_ew_df = pd.read_csv(f'{path}/SemifinalWinner_East_West.csv', sep = '|')\n",
    "\n",
    "\n",
    "# --- Step 1: Extract the full team name (excluding the trailing seed rank)\n",
    "# Instead of taking only the first token, we remove the last token (which is the seed rank)\n",
    "df_kenpom['Team_Name'] = df_kenpom['Team'].apply(lambda x: ' '.join(x.split()[:-1]))\n",
    "\n",
    "# --- Step 2: Apply manual corrections to match college_info['Institution_Name']\n",
    "# Mapping dictionary: keys are the names extracted from KenPom and values are the correct names from college_info.\n",
    "mapping = {\n",
    "    # Changes applied:\n",
    "    \"Connecticut\": \"UConn\",            # \"Connecticut\" → \"UConn\"\n",
    "    \"Houston\": \"Houston\",              # No change needed\n",
    "    \"Purdue\": \"Purdue\",                # No change needed\n",
    "    \"Auburn\": \"Auburn\",                # No change needed\n",
    "    \"Tennessee\": \"Tennessee\",          # No change needed\n",
    "    \"Arizona\": \"Arizona\",              # No change needed\n",
    "    \"Duke\": \"Duke\",                    # No change needed\n",
    "    \"Iowa St.\": \"Iowa St.\",             # No change needed\n",
    "    \"North Carolina\": \"North Carolina\",# No change needed\n",
    "    \"Illinois\": \"Illinois\",            # No change needed\n",
    "    \"Creighton\": \"Creighton\",          # No change needed\n",
    "    \"Gonzaga\": \"Gonzaga\",              # No change needed\n",
    "    \"Marquette\": \"Marquette\",          # No change needed\n",
    "    \"Alabama\": \"Alabama\",              # No change needed\n",
    "    \"Baylor\": \"Baylor\",                # No change needed\n",
    "    \"Michigan St.\": \"Michigan St.\",     # No change needed\n",
    "    \"Wisconsin\": \"Wisconsin\",          # No change needed\n",
    "    \"BYU\": \"BYU\",                      # No change needed\n",
    "    \"Clemson\": \"Clemson\",              # No change needed\n",
    "    \"Saint Mary's\": \"Saint Mary's\",    # No change needed\n",
    "    \"San Diego St.\": \"San Diego St.\",   # No change needed\n",
    "    \"Kentucky\": \"Kentucky\",            # No change needed\n",
    "    \"Colorado\": \"Colorado\",            # No change needed\n",
    "    \"Texas\": \"Texas\",                  # No change needed\n",
    "    \"Florida\": \"Florida\",              # No change needed\n",
    "    \"Kansas\": \"Kansas\",                # No change needed\n",
    "    \"New Mexico\": \"New Mexico\",        # No change needed\n",
    "    \"Nebraska\": \"Nebraska\",            # No change needed\n",
    "    \"Texas Tech\": \"Texas Tech\",        # No change needed\n",
    "    \"Dayton\": \"Dayton\",                # No change needed\n",
    "    \"Mississippi St.\": \"Mississippi St.\",# No change needed\n",
    "    \"Texas A&M\": \"Texas A&M\",          # No change needed\n",
    "    \"Colorado St.\": \"Colorado St.\",    # No change needed\n",
    "    \"Nevada\": \"Nevada\",                # No change needed\n",
    "    \"Northwestern\": \"Northwestern\",    # No change needed\n",
    "    \"Washington St.\": \"Washington St.\",# No change needed\n",
    "    \"TCU\": \"TCU\",                    # No change needed\n",
    "    \"Boise St.\": \"Boise St.\",          # No change needed\n",
    "    \"N.C. State\": \"NC State\",          # \"N.C. State\" → \"NC State\" (remove periods)\n",
    "    \"Florida Atlantic\": \"FAU\",         # \"Florida Atlantic\" → \"FAU\"\n",
    "    \"Utah St.\": \"Utah St.\",            # No change needed\n",
    "    \"Grand Canyon\": \"Grand Canyon\",    # No change needed\n",
    "    \"Drake\": \"Drake\",                  # No change needed\n",
    "    \"South Carolina\": \"South Carolina\",# No change needed\n",
    "    \"Oregon\": \"Oregon\",                # No change needed\n",
    "    \"James Madison\": \"James Madison\",  # No change needed\n",
    "    \"McNeese St.\": \"McNeese\",           # \"McNeese St.\" → \"McNeese\"\n",
    "    \"Virginia\": \"Virginia\",            # No change needed\n",
    "    \"Samford\": \"Samford\",              # No change needed\n",
    "    \"Duquesne\": \"Duquesne\",            # No change needed\n",
    "    \"Yale\": \"Yale\",                    # No change needed\n",
    "    \"Charleston\": \"Charleston\",        # No change needed\n",
    "    \"Vermont\": \"Vermont\",              # No change needed\n",
    "    \"UAB\": \"UAB\",                      # No change needed\n",
    "    \"Morehead St.\": \"Morehead St.\",     # No change needed\n",
    "    \"Akron\": \"Akron\",                  # No change needed\n",
    "    \"Oakland\": \"Oakland\",              # No change needed\n",
    "    \"Western Kentucky\": \"Western Ky.\", # \"Western Kentucky\" → \"Western Ky.\"\n",
    "    \"South Dakota St.\": \"South Dakota St.\",# No change needed\n",
    "    \"Colgate\": \"Colgate\",              # No change needed\n",
    "    \"Longwood\": \"Longwood\",            # No change needed\n",
    "    \"Long Beach St.\": \"Long Beach St.\",# No change needed\n",
    "    \"Saint Peter's\": \"Saint Peter's\",  # No change needed\n",
    "    \"Stetson\": \"Stetson\",              # No change needed\n",
    "    \"Montana St.\": \"Montana St.\",      # No change needed\n",
    "    \"Grambling St.\": \"Grambling St.\",    # No change needed\n",
    "    \"Howard\": \"Howard\",                # No change needed\n",
    "    \"Wagner\": \"Wagner\"                 # No change needed\n",
    "}\n",
    "\n",
    "# Apply the mapping so that each Team_Name matches college_info['Institution_Name']\n",
    "df_kenpom['Team_Name'] = df_kenpom['Team_Name'].map(mapping)\n",
    "\n",
    "# --- Step 3: Process the Seed_Rank column\n",
    "df_kenpom['Seed_Rank'] = df_kenpom['Team'].str.extract(r'(\\d+)$')\n",
    "df_kenpom = df_kenpom.dropna(subset=['Seed_Rank'])\n",
    "df_kenpom['Seed_Rank'] = df_kenpom['Seed_Rank'].astype(int)\n",
    "\n",
    "# Create a cleaned DataFrame with selected columns and set index as Team_Name\n",
    "df_ken_clean = df_kenpom.loc[:, ['Rk', 'Team_Name', 'Seed_Rank', 'NetRtg', 'Luck']]\n",
    "df_ken_clean = df_ken_clean.set_index('Team_Name')\n",
    "\n",
    "# --- Step 4: Merge with the college_info dataset\n",
    "# Now, set the index of college_info to 'Institution_Name' to match\n",
    "college_info_ken_df = college_info.join(df_ken_clean, how='left', on='InstitutionName')\n",
    "\n",
    "#Fast way to create new columns\n",
    "college_info_ken_df['win_%'] = college_info_ken_df['RegularSeasonWins']/ (college_info_ken_df['RegularSeasonWins'] + college_info_ken_df['RegularSeasonLosses'])\n",
    "\n",
    "#Join Ken info to bracket training and bracket test\n",
    "college_info_ken_df = college_info_ken_df.set_index('InstitutionID')\n",
    "train_df = bracket_training.join(\n",
    "    college_info_ken_df.add_prefix(\"W_\"), on=\"RegionWinner_West\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix(\"E_\"), on=\"RegionWinner_East\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix('M_'), on=\"RegionWinner_Midwest\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix('S_'), on='RegionWinner_South'\n",
    ")\n",
    "\n",
    "test_df = bracket_test.join(\n",
    "    college_info_ken_df.add_prefix(\"W_\"), on=\"RegionWinner_West\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix(\"E_\"), on=\"RegionWinner_East\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix('M_'), on=\"RegionWinner_Midwest\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix('S_'), on='RegionWinner_South'\n",
    ")\n",
    "\n",
    "classic1_df_train = train_df[\n",
    "    [\n",
    "        'CustomerID',\n",
    "        #'CustomerAreaCode', 'CustomerPostalCode',\n",
    "       'CustomerPostalCodeLatitude', 'CustomerPostalCodeLongitude',\n",
    "       'CustomerDMACode',\n",
    "        'CustomerDMADescription',\n",
    "       'NCAACustomerRecordCreated', 'BracketEntryId',\n",
    "       'BracketEntryCreatedDate', 'RegionWinner_East', 'RegionWinner_West',\n",
    "       'RegionWinner_South', 'RegionWinner_Midwest',\n",
    "       'SemifinalWinner_East_West', 'SemifinalWinner_South_Midwest',\n",
    "       'NationalChampion',\n",
    "       'E_InstitutionName',\n",
    "        # 'E_InstitutionNickname',\n",
    "        #'E_InstitutionAbbreviation', 'E_InstitutionCity',\n",
    "        #'E_InstitutionState', 'E_InstitutionPostalCode',\n",
    "       'E_InstitutionDMACode',\n",
    "        # 'E_InstitutionDMADescription',\n",
    "       'E_InstitutionLatitude', 'E_InstitutionLongitude',\n",
    "       'E_InstitutionConference', 'E_InstitutionEnrollment_Male',\n",
    "       'E_InstitutionEnrollment_Female', 'E_InstitutionEnrollment_Total',\n",
    "       'E_InstitutionNCAAMemberSinceDate', 'E_RegularSeasonWins',\n",
    "       'E_RegularSeasonLosses', 'E_RegularSeasonAverageAttendance',\n",
    "       'E_RegularSeasonAverageScore',\n",
    "       'E_Rk',\n",
    "       'E_Seed_Rank', 'E_NetRtg', 'E_Luck',\n",
    "       'M_InstitutionName',\n",
    "        # 'M_InstitutionNickname',\n",
    "        #'M_InstitutionAbbreviation', 'M_InstitutionCity',\n",
    "        #'M_InstitutionState', 'M_InstitutionPostalCode',\n",
    "       'M_InstitutionDMACode',\n",
    "        # 'M_InstitutionDMADescription',\n",
    "       'M_InstitutionLatitude', 'M_InstitutionLongitude',\n",
    "       'M_InstitutionConference', 'M_InstitutionEnrollment_Male',\n",
    "       'M_InstitutionEnrollment_Female', 'M_InstitutionEnrollment_Total',\n",
    "       'M_InstitutionNCAAMemberSinceDate', 'M_RegularSeasonWins',\n",
    "       'M_RegularSeasonLosses', 'M_RegularSeasonAverageAttendance',\n",
    "       'M_RegularSeasonAverageScore',\n",
    "       'M_Rk',\n",
    "       'M_Seed_Rank', 'M_NetRtg', 'M_Luck',\n",
    "       'S_InstitutionName',\n",
    "        # 'S_InstitutionNickname',\n",
    "        #'S_InstitutionAbbreviation', 'S_InstitutionCity',\n",
    "        #'S_InstitutionState', 'S_InstitutionPostalCode',\n",
    "       'S_InstitutionDMACode',\n",
    "        # 'S_InstitutionDMADescription',\n",
    "       'S_InstitutionLatitude', 'S_InstitutionLongitude',\n",
    "       'S_InstitutionConference', 'S_InstitutionEnrollment_Male',\n",
    "       'S_InstitutionEnrollment_Female', 'S_InstitutionEnrollment_Total',\n",
    "       'S_InstitutionNCAAMemberSinceDate', 'S_RegularSeasonWins',\n",
    "       'S_RegularSeasonLosses', 'S_RegularSeasonAverageAttendance',\n",
    "       'S_RegularSeasonAverageScore',\n",
    "       'S_Rk',\n",
    "       'S_Seed_Rank', 'S_NetRtg', 'S_Luck',\n",
    "       'W_InstitutionName',\n",
    "        #'W_InstitutionNickname', 'W_InstitutionAbbreviation',\n",
    "        #'W_InstitutionCity', 'W_InstitutionState', 'W_InstitutionPostalCode',\n",
    "       'W_InstitutionDMACode',\n",
    "        #'W_InstitutionDMADescription',\n",
    "       'W_InstitutionLatitude', 'W_InstitutionLongitude',\n",
    "       'W_InstitutionConference',\n",
    "       'W_InstitutionEnrollment_Male',\n",
    "       'W_InstitutionEnrollment_Female', 'W_InstitutionEnrollment_Total',\n",
    "       'W_InstitutionNCAAMemberSinceDate', 'W_RegularSeasonWins',\n",
    "       'W_RegularSeasonLosses', 'W_RegularSeasonAverageAttendance',\n",
    "       'W_RegularSeasonAverageScore',\n",
    "       'W_Rk',\n",
    "       'W_Seed_Rank', 'W_NetRtg', 'W_Luck',\n",
    "    ]\n",
    "]\n",
    "\n",
    "classic1_df_test = test_df[\n",
    "    [\n",
    "        'CustomerID',\n",
    "        #'CustomerAreaCode', 'CustomerPostalCode',\n",
    "       'CustomerPostalCodeLatitude', 'CustomerPostalCodeLongitude',\n",
    "       'CustomerDMACode',\n",
    "        'CustomerDMADescription',\n",
    "       'NCAACustomerRecordCreated', 'BracketEntryId',\n",
    "       'BracketEntryCreatedDate', 'RegionWinner_East', 'RegionWinner_West',\n",
    "       'RegionWinner_South', 'RegionWinner_Midwest',\n",
    "       'E_InstitutionName',\n",
    "        # 'E_InstitutionNickname',\n",
    "        #'E_InstitutionAbbreviation', 'E_InstitutionCity',\n",
    "        #'E_InstitutionState', 'E_InstitutionPostalCode',\n",
    "       'E_InstitutionDMACode',\n",
    "        # 'E_InstitutionDMADescription',\n",
    "       'E_InstitutionLatitude', 'E_InstitutionLongitude',\n",
    "       'E_InstitutionConference', 'E_InstitutionEnrollment_Male',\n",
    "       'E_InstitutionEnrollment_Female', 'E_InstitutionEnrollment_Total',\n",
    "       'E_InstitutionNCAAMemberSinceDate', 'E_RegularSeasonWins',\n",
    "       'E_RegularSeasonLosses', 'E_RegularSeasonAverageAttendance',\n",
    "       'E_RegularSeasonAverageScore',\n",
    "       'E_Rk',\n",
    "       'E_Seed_Rank', 'E_NetRtg', 'E_Luck',\n",
    "       'M_InstitutionName',\n",
    "        # 'M_InstitutionNickname',\n",
    "        #'M_InstitutionAbbreviation', 'M_InstitutionCity',\n",
    "        #'M_InstitutionState', 'M_InstitutionPostalCode',\n",
    "       'M_InstitutionDMACode',\n",
    "        # 'M_InstitutionDMADescription',\n",
    "       'M_InstitutionLatitude', 'M_InstitutionLongitude',\n",
    "       'M_InstitutionConference', 'M_InstitutionEnrollment_Male',\n",
    "       'M_InstitutionEnrollment_Female', 'M_InstitutionEnrollment_Total',\n",
    "       'M_InstitutionNCAAMemberSinceDate', 'M_RegularSeasonWins',\n",
    "       'M_RegularSeasonLosses', 'M_RegularSeasonAverageAttendance',\n",
    "       'M_RegularSeasonAverageScore',\n",
    "       'M_Rk',\n",
    "       'M_Seed_Rank', 'M_NetRtg', 'M_Luck',\n",
    "       'S_InstitutionName',\n",
    "        # 'S_InstitutionNickname',\n",
    "        #'S_InstitutionAbbreviation', 'S_InstitutionCity',\n",
    "        #'S_InstitutionState', 'S_InstitutionPostalCode',\n",
    "       'S_InstitutionDMACode',\n",
    "        # 'S_InstitutionDMADescription',\n",
    "       'S_InstitutionLatitude', 'S_InstitutionLongitude',\n",
    "       'S_InstitutionConference', 'S_InstitutionEnrollment_Male',\n",
    "       'S_InstitutionEnrollment_Female', 'S_InstitutionEnrollment_Total',\n",
    "       'S_InstitutionNCAAMemberSinceDate', 'S_RegularSeasonWins',\n",
    "       'S_RegularSeasonLosses', 'S_RegularSeasonAverageAttendance',\n",
    "       'S_RegularSeasonAverageScore',\n",
    "       'S_Rk',\n",
    "       'S_Seed_Rank', 'S_NetRtg', 'S_Luck',\n",
    "       'W_InstitutionName',\n",
    "        #'W_InstitutionNickname', 'W_InstitutionAbbreviation',\n",
    "        #'W_InstitutionCity', 'W_InstitutionState', 'W_InstitutionPostalCode',\n",
    "       'W_InstitutionDMACode',\n",
    "        #'W_InstitutionDMADescription',\n",
    "       'W_InstitutionLatitude', 'W_InstitutionLongitude',\n",
    "       'W_InstitutionConference',\n",
    "       'W_InstitutionEnrollment_Male',\n",
    "       'W_InstitutionEnrollment_Female', 'W_InstitutionEnrollment_Total',\n",
    "       'W_InstitutionNCAAMemberSinceDate', 'W_RegularSeasonWins',\n",
    "       'W_RegularSeasonLosses', 'W_RegularSeasonAverageAttendance',\n",
    "       'W_RegularSeasonAverageScore',\n",
    "       'W_Rk',\n",
    "       'W_Seed_Rank', 'W_NetRtg', 'W_Luck',\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Create separate imputers:\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "\n",
    "# List the columns to impute:\n",
    "num_cols = ['CustomerPostalCodeLatitude', 'CustomerPostalCodeLongitude']\n",
    "cat_cols = ['CustomerDMACode', 'CustomerDMADescription']\n",
    "\n",
    "# Impute in the training set using .loc:\n",
    "classic1_df_train.loc[:, num_cols] = num_imputer.fit_transform(classic1_df_train.loc[:, num_cols])\n",
    "classic1_df_train.loc[:, cat_cols] = cat_imputer.fit_transform(classic1_df_train.loc[:, cat_cols])\n",
    "\n",
    "# And in the test set using .loc:\n",
    "classic1_df_test.loc[:, num_cols] = num_imputer.transform(classic1_df_test.loc[:, num_cols])\n",
    "classic1_df_test.loc[:, cat_cols] = cat_imputer.transform(classic1_df_test.loc[:, cat_cols])\n",
    "\n",
    "num_brackets_df_train = classic1_df_train.groupby(by = 'CustomerID').agg(bracket_entry_count= pd.NamedAgg(column = \"BracketEntryId\", aggfunc = 'count'))\n",
    "num_brackets_df_test = classic1_df_test.groupby(by = 'CustomerID').agg(bracket_entry_count= pd.NamedAgg(column = \"BracketEntryId\", aggfunc = 'count'))\n",
    "\n",
    "\n",
    "classic1_df_train['m_win_%'] = classic1_df_train['M_RegularSeasonWins']/ (classic1_df_train['M_RegularSeasonWins'] + classic1_df_train['M_RegularSeasonLosses'])\n",
    "classic1_df_train['s_win_%'] = classic1_df_train['S_RegularSeasonWins']/ (classic1_df_train['S_RegularSeasonWins'] + classic1_df_train['S_RegularSeasonLosses'])\n",
    "classic1_df_train['e_win_%'] = classic1_df_train['E_RegularSeasonWins']/ (classic1_df_train['E_RegularSeasonWins'] + classic1_df_train['E_RegularSeasonLosses'])\n",
    "classic1_df_train['w_win_%'] = classic1_df_train['W_RegularSeasonWins']/ (classic1_df_train['W_RegularSeasonWins'] + classic1_df_train['W_RegularSeasonLosses'])\n",
    "\n",
    "classic1_df_test['m_win_%'] = classic1_df_test['M_RegularSeasonWins']/ (classic1_df_test['M_RegularSeasonWins'] + classic1_df_test['M_RegularSeasonLosses'])\n",
    "classic1_df_test['s_win_%'] = classic1_df_test['S_RegularSeasonWins']/ (classic1_df_test['S_RegularSeasonWins'] + classic1_df_test['S_RegularSeasonLosses'])\n",
    "classic1_df_test['e_win_%'] = classic1_df_test['E_RegularSeasonWins']/ (classic1_df_test['E_RegularSeasonWins'] + classic1_df_test['E_RegularSeasonLosses'])\n",
    "classic1_df_test['w_win_%'] = classic1_df_test['W_RegularSeasonWins']/ (classic1_df_test['W_RegularSeasonWins'] + classic1_df_test['W_RegularSeasonLosses'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions_EW.csv ✅\n",
      "Recall (Logistic Regression): 0.8394182791773154\n",
      "Accuracy (Logistic Regression): 0.6758201607630476\n",
      "Confusion Matrix (Logistic Regression):\n",
      "[[ 3777  5790]\n",
      " [ 2639 13795]]\n"
     ]
    }
   ],
   "source": [
    "# Model Two Classifiers with Pipelines (Random Forest & Logistic Regression)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "\n",
    "# Define the closeness function (calculates difference in Haversine distances)\n",
    "def closeness(userlat: float, userlon: float, team1lat: float, team1lon: float, team2lat: float, team2lon: float) -> float:\n",
    "    def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "        R = 6371  # Earth's radius in km\n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "        delta_lat = lat2 - lat1\n",
    "        delta_lon = lon2 - lon1\n",
    "        a = np.sin(delta_lat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon / 2) ** 2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        return R * c\n",
    "    d1 = haversine_distance(userlat, userlon, team1lat, team1lon)\n",
    "    d2 = haversine_distance(userlat, userlon, team2lat, team2lon)\n",
    "    return d1 - d2\n",
    "\n",
    "# Custom sigmoid transformer (for ordinal features if needed)\n",
    "def sigmoid_transform(X):\n",
    "    try:\n",
    "        return  1 - (1 / (1 + np.exp(-X)))\n",
    "    except ZeroDivisionError:\n",
    "        print('Bad Process!')\n",
    "        \n",
    "sigmoid_transformer = FunctionTransformer(sigmoid_transform, validate=False)\n",
    "\n",
    "# Load the data\n",
    "df_train = classic1_df_train\n",
    "df_test = classic1_df_test\n",
    "\n",
    "# Add closeness feature to df_train using E and W columns\n",
    "df_train['closeness'] = closeness(\n",
    "    userlat=classic1_df_train['CustomerPostalCodeLatitude'],\n",
    "    userlon=classic1_df_train['CustomerPostalCodeLongitude'],\n",
    "    team1lat=classic1_df_train['E_InstitutionLatitude'],\n",
    "    team1lon=classic1_df_train['E_InstitutionLongitude'],\n",
    "    team2lat=classic1_df_train['W_InstitutionLatitude'],\n",
    "    team2lon=classic1_df_train['W_InstitutionLongitude']\n",
    ")\n",
    "\n",
    "# Optionally, add closeness to df_test if required for predictions\n",
    "# Add closeness feature to df_train using E and W columns\n",
    "df_test['closeness'] = closeness(\n",
    "    userlat=classic1_df_test['CustomerPostalCodeLatitude'],\n",
    "    userlon=classic1_df_test['CustomerPostalCodeLongitude'],\n",
    "    team1lat=classic1_df_test['E_InstitutionLatitude'],\n",
    "    team1lon=classic1_df_test['E_InstitutionLongitude'],\n",
    "    team2lat=classic1_df_test['W_InstitutionLatitude'],\n",
    "    team2lon=classic1_df_test['W_InstitutionLongitude']\n",
    ")\n",
    "# Drop withheld features\n",
    "features_to_withHold = [\n",
    "    'E_InstitutionName', 'E_InstitutionDMACode', 'E_InstitutionLatitude', 'E_InstitutionLongitude',\n",
    "    'E_InstitutionNCAAMemberSinceDate', 'E_InstitutionEnrollment_Female',\n",
    "    'W_InstitutionName', 'W_InstitutionDMACode', 'W_InstitutionLatitude', 'W_InstitutionLongitude',\n",
    "    'W_InstitutionEnrollment_Male', 'W_InstitutionEnrollment_Female', 'W_InstitutionNCAAMemberSinceDate'\n",
    "]\n",
    "df_train = df_train.drop(columns=features_to_withHold)\n",
    "df_test = df_test.drop(columns=features_to_withHold)\n",
    "\n",
    "# Create lists of east and west features based on column prefixes\n",
    "features_east = [col for col in df_train.columns if col.startswith('E_')]\n",
    "features_west = [col for col in df_train.columns if col.startswith('W_')]\n",
    "\n",
    "# Remove the target column if present in feature lists\n",
    "target = \"SemifinalWinner_East_West\"\n",
    "if target in features_east:\n",
    "    features_east.remove(target)\n",
    "if target in features_west:\n",
    "    features_west.remove(target)\n",
    "\n",
    "# Combine east and west features\n",
    "features = features_east + features_west\n",
    "\n",
    "# Define the target variable\n",
    "y = (df_train[target] == df_train['RegionWinner_East']).astype(int)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_train[features], y, test_size=0.2, random_state=24\n",
    ")\n",
    "\n",
    "# Define non-numeric columns (e.g., conference info)\n",
    "non_numeric_columns = ['E_InstitutionConference', 'W_InstitutionConference']\n",
    "\n",
    "# Define ordinal features if available (empty list if none)\n",
    "ordinal_features = ['E_Rk','E_Seed_Rank', 'W_Rk', 'W_Seed_Rank']  # Modify here if you later add ordinal features\n",
    "\n",
    "# Identify numeric columns for each pipeline\n",
    "numeric_features_tree = [col for col in features if col not in non_numeric_columns]\n",
    "numeric_features_log = [col for col in features if col not in non_numeric_columns and col not in ordinal_features]\n",
    "\n",
    "# Preprocessing pipeline for tree-based models\n",
    "preprocessor_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features_tree),\n",
    "        ('cat', OneHotEncoder(), non_numeric_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocessing pipeline for logistic regression\n",
    "preprocessor_log = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features_log),\n",
    "        ('cat', OneHotEncoder(), non_numeric_columns),\n",
    "        ('ordinal', sigmoid_transformer, ordinal_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline for Random Forest (with SelectKBest)\n",
    "model_RandomForest = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_tree),\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Pipeline for Logistic Regression (with LassoCV feature selection)\n",
    "model_log_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_log),\n",
    "    ('selector', SelectFromModel(LassoCV(cv=5, alphas=[0.0001, 0.001, 0.01, 0.1], random_state=42), prefit=False)),\n",
    "    ('classifier', LogisticRegressionCV(cv=5, max_iter=2000))\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid for Random Forest\n",
    "hyperparameter_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# # Grid search over the Random Forest pipeline\n",
    "# grid_search = GridSearchCV(model_RandomForest, param_grid=hyperparameter_grid, cv=5, scoring='accuracy')\n",
    "# grid_search.fit(df_train, y)\n",
    "\n",
    "# Evaluate the best Random Forest model\n",
    "# y_pred_tree = grid_search.predict(test_df[features])\n",
    "# print(f'Recall (Random Forest): {recall_score(y_test, y_pred_tree)}')\n",
    "# print(f'Accuracy (Random Forest): {accuracy_score(y_test, y_pred_tree)}')\n",
    "# print(f'Confusion Matrix (Random Forest):\\n{confusion_matrix(y_test, y_pred_tree)}')\n",
    "\n",
    "# Fit and evaluate the Logistic Regression pipeline\n",
    "model_log_reg.fit(df_train[features], y)\n",
    "y_pred_log_ew = model_log_reg.predict(df_test)\n",
    "\n",
    "# # Predict on external test set using the best Random Forest model\n",
    "df_test['SemifinalWinner_East_West'] = df_test['RegionWinner_East'].where(y_pred_log_ew == df_test['RegionWinner_East'], df_test['RegionWinner_West'])\n",
    "# df_test['SemifinalWinner_East_West'].to_csv(\"predictions_EW.csv\", index=False)\n",
    "print(\"Predictions saved to predictions_EW.csv ✅\")\n",
    "\n",
    "model_log_reg.fit(X_train, y_train)\n",
    "y_pred_log = model_log_reg.predict(X_test)\n",
    "print(f'Recall (Logistic Regression): {recall_score(y_test, y_pred_log)}')\n",
    "print(f'Accuracy (Logistic Regression): {accuracy_score(y_test, y_pred_log)}')\n",
    "print(f'Confusion Matrix (Logistic Regression):\\n{confusion_matrix(y_test, y_pred_log)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>CustomerPostalCodeLatitude</th>\n",
       "      <th>CustomerPostalCodeLongitude</th>\n",
       "      <th>CustomerDMACode</th>\n",
       "      <th>CustomerDMADescription</th>\n",
       "      <th>NCAACustomerRecordCreated</th>\n",
       "      <th>BracketEntryId</th>\n",
       "      <th>BracketEntryCreatedDate</th>\n",
       "      <th>RegionWinner_East</th>\n",
       "      <th>RegionWinner_West</th>\n",
       "      <th>RegionWinner_South</th>\n",
       "      <th>RegionWinner_Midwest</th>\n",
       "      <th>E_InstitutionName</th>\n",
       "      <th>E_InstitutionDMACode</th>\n",
       "      <th>E_InstitutionLatitude</th>\n",
       "      <th>E_InstitutionLongitude</th>\n",
       "      <th>E_InstitutionConference</th>\n",
       "      <th>E_InstitutionEnrollment_Male</th>\n",
       "      <th>E_InstitutionEnrollment_Female</th>\n",
       "      <th>E_InstitutionEnrollment_Total</th>\n",
       "      <th>E_InstitutionNCAAMemberSinceDate</th>\n",
       "      <th>E_RegularSeasonWins</th>\n",
       "      <th>E_RegularSeasonLosses</th>\n",
       "      <th>E_RegularSeasonAverageAttendance</th>\n",
       "      <th>E_RegularSeasonAverageScore</th>\n",
       "      <th>E_Rk</th>\n",
       "      <th>E_Seed_Rank</th>\n",
       "      <th>E_NetRtg</th>\n",
       "      <th>E_Luck</th>\n",
       "      <th>M_InstitutionName</th>\n",
       "      <th>M_InstitutionDMACode</th>\n",
       "      <th>M_InstitutionLatitude</th>\n",
       "      <th>M_InstitutionLongitude</th>\n",
       "      <th>M_InstitutionConference</th>\n",
       "      <th>M_InstitutionEnrollment_Male</th>\n",
       "      <th>M_InstitutionEnrollment_Female</th>\n",
       "      <th>M_InstitutionEnrollment_Total</th>\n",
       "      <th>M_InstitutionNCAAMemberSinceDate</th>\n",
       "      <th>M_RegularSeasonWins</th>\n",
       "      <th>M_RegularSeasonLosses</th>\n",
       "      <th>M_RegularSeasonAverageAttendance</th>\n",
       "      <th>M_RegularSeasonAverageScore</th>\n",
       "      <th>M_Rk</th>\n",
       "      <th>M_Seed_Rank</th>\n",
       "      <th>M_NetRtg</th>\n",
       "      <th>M_Luck</th>\n",
       "      <th>S_InstitutionName</th>\n",
       "      <th>S_InstitutionDMACode</th>\n",
       "      <th>S_InstitutionLatitude</th>\n",
       "      <th>S_InstitutionLongitude</th>\n",
       "      <th>S_InstitutionConference</th>\n",
       "      <th>S_InstitutionEnrollment_Male</th>\n",
       "      <th>S_InstitutionEnrollment_Female</th>\n",
       "      <th>S_InstitutionEnrollment_Total</th>\n",
       "      <th>S_InstitutionNCAAMemberSinceDate</th>\n",
       "      <th>S_RegularSeasonWins</th>\n",
       "      <th>S_RegularSeasonLosses</th>\n",
       "      <th>S_RegularSeasonAverageAttendance</th>\n",
       "      <th>S_RegularSeasonAverageScore</th>\n",
       "      <th>S_Rk</th>\n",
       "      <th>S_Seed_Rank</th>\n",
       "      <th>S_NetRtg</th>\n",
       "      <th>S_Luck</th>\n",
       "      <th>W_InstitutionName</th>\n",
       "      <th>W_InstitutionDMACode</th>\n",
       "      <th>W_InstitutionLatitude</th>\n",
       "      <th>W_InstitutionLongitude</th>\n",
       "      <th>W_InstitutionConference</th>\n",
       "      <th>W_InstitutionEnrollment_Male</th>\n",
       "      <th>W_InstitutionEnrollment_Female</th>\n",
       "      <th>W_InstitutionEnrollment_Total</th>\n",
       "      <th>W_InstitutionNCAAMemberSinceDate</th>\n",
       "      <th>W_RegularSeasonWins</th>\n",
       "      <th>W_RegularSeasonLosses</th>\n",
       "      <th>W_RegularSeasonAverageAttendance</th>\n",
       "      <th>W_RegularSeasonAverageScore</th>\n",
       "      <th>W_Rk</th>\n",
       "      <th>W_Seed_Rank</th>\n",
       "      <th>W_NetRtg</th>\n",
       "      <th>W_Luck</th>\n",
       "      <th>m_win_%</th>\n",
       "      <th>s_win_%</th>\n",
       "      <th>e_win_%</th>\n",
       "      <th>w_win_%</th>\n",
       "      <th>closeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73662</td>\n",
       "      <td>35.7225</td>\n",
       "      <td>-78.8408</td>\n",
       "      <td>560.0</td>\n",
       "      <td>RALEIGH - DURHAM (FAYETVLLE)</td>\n",
       "      <td>3/29/20</td>\n",
       "      <td>2074118</td>\n",
       "      <td>3/19/24 18:50</td>\n",
       "      <td>164</td>\n",
       "      <td>457</td>\n",
       "      <td>288</td>\n",
       "      <td>559</td>\n",
       "      <td>UConn</td>\n",
       "      <td>533</td>\n",
       "      <td>41.80910</td>\n",
       "      <td>-72.24995</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>10645</td>\n",
       "      <td>11834</td>\n",
       "      <td>22479</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>14017.88</td>\n",
       "      <td>81.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>582</td>\n",
       "      <td>40.42821</td>\n",
       "      <td>-86.91444</td>\n",
       "      <td>Big Ten Conference</td>\n",
       "      <td>21670</td>\n",
       "      <td>16279</td>\n",
       "      <td>37949</td>\n",
       "      <td>09/01/1914</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>13329.06</td>\n",
       "      <td>83.39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Houston</td>\n",
       "      <td>618</td>\n",
       "      <td>29.72039</td>\n",
       "      <td>-95.34354</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>18290</td>\n",
       "      <td>19653</td>\n",
       "      <td>37943</td>\n",
       "      <td>09/01/1949</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>9347.35</td>\n",
       "      <td>73.03</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.17</td>\n",
       "      <td>0.042</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>560</td>\n",
       "      <td>35.91177</td>\n",
       "      <td>-79.05097</td>\n",
       "      <td>Atlantic Coast Conference</td>\n",
       "      <td>8068</td>\n",
       "      <td>12174</td>\n",
       "      <td>20242</td>\n",
       "      <td>09/01/1906</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>15767.47</td>\n",
       "      <td>81.47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>856.858920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6679</td>\n",
       "      <td>45.4840</td>\n",
       "      <td>-122.5973</td>\n",
       "      <td>820.0</td>\n",
       "      <td>PORTLAND, OR</td>\n",
       "      <td>4/2/24</td>\n",
       "      <td>2692634</td>\n",
       "      <td>3/20/24 16:56</td>\n",
       "      <td>164</td>\n",
       "      <td>457</td>\n",
       "      <td>193</td>\n",
       "      <td>328</td>\n",
       "      <td>UConn</td>\n",
       "      <td>533</td>\n",
       "      <td>41.80910</td>\n",
       "      <td>-72.24995</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>10645</td>\n",
       "      <td>11834</td>\n",
       "      <td>22479</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>14017.88</td>\n",
       "      <td>81.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>616</td>\n",
       "      <td>38.95855</td>\n",
       "      <td>-95.24757</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>8859</td>\n",
       "      <td>9845</td>\n",
       "      <td>18704</td>\n",
       "      <td>09/01/1908</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>13952.66</td>\n",
       "      <td>75.25</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.058</td>\n",
       "      <td>Duke</td>\n",
       "      <td>560</td>\n",
       "      <td>36.00114</td>\n",
       "      <td>-78.93762</td>\n",
       "      <td>Atlantic Coast Conference</td>\n",
       "      <td>3137</td>\n",
       "      <td>3448</td>\n",
       "      <td>6585</td>\n",
       "      <td>09/01/1925</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>11475.81</td>\n",
       "      <td>79.84</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>26.47</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>560</td>\n",
       "      <td>35.91177</td>\n",
       "      <td>-79.05097</td>\n",
       "      <td>Atlantic Coast Conference</td>\n",
       "      <td>8068</td>\n",
       "      <td>12174</td>\n",
       "      <td>20242</td>\n",
       "      <td>09/01/1906</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>15767.47</td>\n",
       "      <td>81.47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>233.225676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63024</td>\n",
       "      <td>37.4603</td>\n",
       "      <td>-86.3249</td>\n",
       "      <td>529.0</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>12/8/21</td>\n",
       "      <td>1252684</td>\n",
       "      <td>3/18/24 15:13</td>\n",
       "      <td>311</td>\n",
       "      <td>29</td>\n",
       "      <td>334</td>\n",
       "      <td>169</td>\n",
       "      <td>Iowa St.</td>\n",
       "      <td>679</td>\n",
       "      <td>42.02621</td>\n",
       "      <td>-93.64851</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>14070</td>\n",
       "      <td>11171</td>\n",
       "      <td>25241</td>\n",
       "      <td>09/01/1908</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>12059.44</td>\n",
       "      <td>75.56</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26.47</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>652</td>\n",
       "      <td>41.26536</td>\n",
       "      <td>-95.94781</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>1789</td>\n",
       "      <td>2501</td>\n",
       "      <td>4290</td>\n",
       "      <td>09/01/1923</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>13651.44</td>\n",
       "      <td>80.53</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>24.22</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>541</td>\n",
       "      <td>38.03891</td>\n",
       "      <td>-84.50475</td>\n",
       "      <td>Southeastern Conference</td>\n",
       "      <td>9596</td>\n",
       "      <td>13127</td>\n",
       "      <td>22723</td>\n",
       "      <td>09/01/1936</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>17427.94</td>\n",
       "      <td>89.44</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19.29</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>789</td>\n",
       "      <td>32.23267</td>\n",
       "      <td>-110.95080</td>\n",
       "      <td>Pac-12 Conference</td>\n",
       "      <td>13090</td>\n",
       "      <td>17292</td>\n",
       "      <td>30382</td>\n",
       "      <td>09/01/1936</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>12118.18</td>\n",
       "      <td>87.94</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.55</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>-1508.231521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60371</td>\n",
       "      <td>47.4924</td>\n",
       "      <td>-122.2359</td>\n",
       "      <td>819.0</td>\n",
       "      <td>SEATTLE - TACOMA</td>\n",
       "      <td>3/22/23</td>\n",
       "      <td>1950205</td>\n",
       "      <td>3/19/24 15:21</td>\n",
       "      <td>164</td>\n",
       "      <td>457</td>\n",
       "      <td>288</td>\n",
       "      <td>559</td>\n",
       "      <td>UConn</td>\n",
       "      <td>533</td>\n",
       "      <td>41.80910</td>\n",
       "      <td>-72.24995</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>10645</td>\n",
       "      <td>11834</td>\n",
       "      <td>22479</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>14017.88</td>\n",
       "      <td>81.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>582</td>\n",
       "      <td>40.42821</td>\n",
       "      <td>-86.91444</td>\n",
       "      <td>Big Ten Conference</td>\n",
       "      <td>21670</td>\n",
       "      <td>16279</td>\n",
       "      <td>37949</td>\n",
       "      <td>09/01/1914</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>13329.06</td>\n",
       "      <td>83.39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Houston</td>\n",
       "      <td>618</td>\n",
       "      <td>29.72039</td>\n",
       "      <td>-95.34354</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>18290</td>\n",
       "      <td>19653</td>\n",
       "      <td>37943</td>\n",
       "      <td>09/01/1949</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>9347.35</td>\n",
       "      <td>73.03</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.17</td>\n",
       "      <td>0.042</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>560</td>\n",
       "      <td>35.91177</td>\n",
       "      <td>-79.05097</td>\n",
       "      <td>Atlantic Coast Conference</td>\n",
       "      <td>8068</td>\n",
       "      <td>12174</td>\n",
       "      <td>20242</td>\n",
       "      <td>09/01/1906</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>15767.47</td>\n",
       "      <td>81.47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>181.285289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18415</td>\n",
       "      <td>40.1096</td>\n",
       "      <td>-75.1550</td>\n",
       "      <td>504.0</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>2/20/24</td>\n",
       "      <td>2756293</td>\n",
       "      <td>3/20/24 18:40</td>\n",
       "      <td>164</td>\n",
       "      <td>457</td>\n",
       "      <td>387</td>\n",
       "      <td>169</td>\n",
       "      <td>UConn</td>\n",
       "      <td>533</td>\n",
       "      <td>41.80910</td>\n",
       "      <td>-72.24995</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>10645</td>\n",
       "      <td>11834</td>\n",
       "      <td>22479</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>14017.88</td>\n",
       "      <td>81.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>652</td>\n",
       "      <td>41.26536</td>\n",
       "      <td>-95.94781</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>1789</td>\n",
       "      <td>2501</td>\n",
       "      <td>4290</td>\n",
       "      <td>09/01/1923</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>13651.44</td>\n",
       "      <td>80.53</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>24.22</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>617</td>\n",
       "      <td>43.03903</td>\n",
       "      <td>-87.92796</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>3328</td>\n",
       "      <td>4200</td>\n",
       "      <td>7528</td>\n",
       "      <td>09/01/1928</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>14084.65</td>\n",
       "      <td>78.29</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>23.02</td>\n",
       "      <td>0.035</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>560</td>\n",
       "      <td>35.91177</td>\n",
       "      <td>-79.05097</td>\n",
       "      <td>Atlantic Coast Conference</td>\n",
       "      <td>8068</td>\n",
       "      <td>12174</td>\n",
       "      <td>20242</td>\n",
       "      <td>09/01/1906</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>15767.47</td>\n",
       "      <td>81.47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>-269.573059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14440</th>\n",
       "      <td>17938</td>\n",
       "      <td>32.1422</td>\n",
       "      <td>-111.0506</td>\n",
       "      <td>789.0</td>\n",
       "      <td>TUCSON (SIERRA VISTA)</td>\n",
       "      <td>2/11/22</td>\n",
       "      <td>2085292</td>\n",
       "      <td>3/19/24 19:05</td>\n",
       "      <td>164</td>\n",
       "      <td>29</td>\n",
       "      <td>288</td>\n",
       "      <td>559</td>\n",
       "      <td>UConn</td>\n",
       "      <td>533</td>\n",
       "      <td>41.80910</td>\n",
       "      <td>-72.24995</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>10645</td>\n",
       "      <td>11834</td>\n",
       "      <td>22479</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>14017.88</td>\n",
       "      <td>81.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>582</td>\n",
       "      <td>40.42821</td>\n",
       "      <td>-86.91444</td>\n",
       "      <td>Big Ten Conference</td>\n",
       "      <td>21670</td>\n",
       "      <td>16279</td>\n",
       "      <td>37949</td>\n",
       "      <td>09/01/1914</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>13329.06</td>\n",
       "      <td>83.39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Houston</td>\n",
       "      <td>618</td>\n",
       "      <td>29.72039</td>\n",
       "      <td>-95.34354</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>18290</td>\n",
       "      <td>19653</td>\n",
       "      <td>37943</td>\n",
       "      <td>09/01/1949</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>9347.35</td>\n",
       "      <td>73.03</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.17</td>\n",
       "      <td>0.042</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>789</td>\n",
       "      <td>32.23267</td>\n",
       "      <td>-110.95080</td>\n",
       "      <td>Pac-12 Conference</td>\n",
       "      <td>13090</td>\n",
       "      <td>17292</td>\n",
       "      <td>30382</td>\n",
       "      <td>09/01/1936</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>12118.18</td>\n",
       "      <td>87.94</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.55</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>3562.681680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14441</th>\n",
       "      <td>20450</td>\n",
       "      <td>41.6338</td>\n",
       "      <td>-80.1488</td>\n",
       "      <td>516.0</td>\n",
       "      <td>ERIE</td>\n",
       "      <td>3/19/21</td>\n",
       "      <td>615949</td>\n",
       "      <td>3/17/24 20:22</td>\n",
       "      <td>164</td>\n",
       "      <td>457</td>\n",
       "      <td>334</td>\n",
       "      <td>559</td>\n",
       "      <td>UConn</td>\n",
       "      <td>533</td>\n",
       "      <td>41.80910</td>\n",
       "      <td>-72.24995</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>10645</td>\n",
       "      <td>11834</td>\n",
       "      <td>22479</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>14017.88</td>\n",
       "      <td>81.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>582</td>\n",
       "      <td>40.42821</td>\n",
       "      <td>-86.91444</td>\n",
       "      <td>Big Ten Conference</td>\n",
       "      <td>21670</td>\n",
       "      <td>16279</td>\n",
       "      <td>37949</td>\n",
       "      <td>09/01/1914</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>13329.06</td>\n",
       "      <td>83.39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.048</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>541</td>\n",
       "      <td>38.03891</td>\n",
       "      <td>-84.50475</td>\n",
       "      <td>Southeastern Conference</td>\n",
       "      <td>9596</td>\n",
       "      <td>13127</td>\n",
       "      <td>22723</td>\n",
       "      <td>09/01/1936</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>17427.94</td>\n",
       "      <td>89.44</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19.29</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>560</td>\n",
       "      <td>35.91177</td>\n",
       "      <td>-79.05097</td>\n",
       "      <td>Atlantic Coast Conference</td>\n",
       "      <td>8068</td>\n",
       "      <td>12174</td>\n",
       "      <td>20242</td>\n",
       "      <td>09/01/1906</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>15767.47</td>\n",
       "      <td>81.47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>12.299279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14442</th>\n",
       "      <td>71151</td>\n",
       "      <td>38.2423</td>\n",
       "      <td>-122.1314</td>\n",
       "      <td>862.0</td>\n",
       "      <td>SACRAMNTO - STKTN - MODESTO</td>\n",
       "      <td>2/22/21</td>\n",
       "      <td>13727</td>\n",
       "      <td>2/21/24 0:10</td>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "      <td>288</td>\n",
       "      <td>169</td>\n",
       "      <td>BYU</td>\n",
       "      <td>770</td>\n",
       "      <td>40.25085</td>\n",
       "      <td>-111.64930</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>13555</td>\n",
       "      <td>14698</td>\n",
       "      <td>28253</td>\n",
       "      <td>09/01/1939</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>13481.27</td>\n",
       "      <td>81.85</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>19.96</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>652</td>\n",
       "      <td>41.26536</td>\n",
       "      <td>-95.94781</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>1789</td>\n",
       "      <td>2501</td>\n",
       "      <td>4290</td>\n",
       "      <td>09/01/1923</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>13651.44</td>\n",
       "      <td>80.53</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>24.22</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>Houston</td>\n",
       "      <td>618</td>\n",
       "      <td>29.72039</td>\n",
       "      <td>-95.34354</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>18290</td>\n",
       "      <td>19653</td>\n",
       "      <td>37943</td>\n",
       "      <td>09/01/1949</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>9347.35</td>\n",
       "      <td>73.03</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.17</td>\n",
       "      <td>0.042</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>789</td>\n",
       "      <td>32.23267</td>\n",
       "      <td>-110.95080</td>\n",
       "      <td>Pac-12 Conference</td>\n",
       "      <td>13090</td>\n",
       "      <td>17292</td>\n",
       "      <td>30382</td>\n",
       "      <td>09/01/1936</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>12118.18</td>\n",
       "      <td>87.94</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.55</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>-284.921428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>18790</td>\n",
       "      <td>40.5959</td>\n",
       "      <td>-111.9644</td>\n",
       "      <td>770.0</td>\n",
       "      <td>SALT LAKE CITY</td>\n",
       "      <td>3/19/24</td>\n",
       "      <td>3019220</td>\n",
       "      <td>3/20/24 23:21</td>\n",
       "      <td>164</td>\n",
       "      <td>457</td>\n",
       "      <td>288</td>\n",
       "      <td>169</td>\n",
       "      <td>UConn</td>\n",
       "      <td>533</td>\n",
       "      <td>41.80910</td>\n",
       "      <td>-72.24995</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>10645</td>\n",
       "      <td>11834</td>\n",
       "      <td>22479</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>14017.88</td>\n",
       "      <td>81.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>652</td>\n",
       "      <td>41.26536</td>\n",
       "      <td>-95.94781</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>1789</td>\n",
       "      <td>2501</td>\n",
       "      <td>4290</td>\n",
       "      <td>09/01/1923</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>13651.44</td>\n",
       "      <td>80.53</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>24.22</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>Houston</td>\n",
       "      <td>618</td>\n",
       "      <td>29.72039</td>\n",
       "      <td>-95.34354</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>18290</td>\n",
       "      <td>19653</td>\n",
       "      <td>37943</td>\n",
       "      <td>09/01/1949</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>9347.35</td>\n",
       "      <td>73.03</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.17</td>\n",
       "      <td>0.042</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>560</td>\n",
       "      <td>35.91177</td>\n",
       "      <td>-79.05097</td>\n",
       "      <td>Atlantic Coast Conference</td>\n",
       "      <td>8068</td>\n",
       "      <td>12174</td>\n",
       "      <td>20242</td>\n",
       "      <td>09/01/1906</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>15767.47</td>\n",
       "      <td>81.47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>392.233162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14444</th>\n",
       "      <td>62847</td>\n",
       "      <td>44.3926</td>\n",
       "      <td>-94.9218</td>\n",
       "      <td>613.0</td>\n",
       "      <td>MINNEAPOLIS - ST. PAUL</td>\n",
       "      <td>3/18/24</td>\n",
       "      <td>3032491</td>\n",
       "      <td>3/20/24 23:37</td>\n",
       "      <td>37</td>\n",
       "      <td>610</td>\n",
       "      <td>387</td>\n",
       "      <td>260</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>522</td>\n",
       "      <td>32.59938</td>\n",
       "      <td>-85.48826</td>\n",
       "      <td>Southeastern Conference</td>\n",
       "      <td>12695</td>\n",
       "      <td>12684</td>\n",
       "      <td>25379</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>10182.91</td>\n",
       "      <td>83.32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27.99</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>881</td>\n",
       "      <td>47.66653</td>\n",
       "      <td>-117.40060</td>\n",
       "      <td>West Coast Conference</td>\n",
       "      <td>2286</td>\n",
       "      <td>2670</td>\n",
       "      <td>4956</td>\n",
       "      <td>09/01/1938</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>6368.78</td>\n",
       "      <td>84.88</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>23.17</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>617</td>\n",
       "      <td>43.03903</td>\n",
       "      <td>-87.92796</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>3328</td>\n",
       "      <td>4200</td>\n",
       "      <td>7528</td>\n",
       "      <td>09/01/1928</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>14084.65</td>\n",
       "      <td>78.29</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>23.02</td>\n",
       "      <td>0.035</td>\n",
       "      <td>Saint Mary's</td>\n",
       "      <td>807</td>\n",
       "      <td>37.84073</td>\n",
       "      <td>-122.10900</td>\n",
       "      <td>West Coast Conference</td>\n",
       "      <td>859</td>\n",
       "      <td>1090</td>\n",
       "      <td>1949</td>\n",
       "      <td>09/01/1961</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>3458.15</td>\n",
       "      <td>74.24</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>19.43</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>-833.677482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14445 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CustomerID  CustomerPostalCodeLatitude  CustomerPostalCodeLongitude  \\\n",
       "0           73662                     35.7225                     -78.8408   \n",
       "1            6679                     45.4840                    -122.5973   \n",
       "2           63024                     37.4603                     -86.3249   \n",
       "3           60371                     47.4924                    -122.2359   \n",
       "4           18415                     40.1096                     -75.1550   \n",
       "...           ...                         ...                          ...   \n",
       "14440       17938                     32.1422                    -111.0506   \n",
       "14441       20450                     41.6338                     -80.1488   \n",
       "14442       71151                     38.2423                    -122.1314   \n",
       "14443       18790                     40.5959                    -111.9644   \n",
       "14444       62847                     44.3926                     -94.9218   \n",
       "\n",
       "      CustomerDMACode        CustomerDMADescription NCAACustomerRecordCreated  \\\n",
       "0               560.0  RALEIGH - DURHAM (FAYETVLLE)                   3/29/20   \n",
       "1               820.0                  PORTLAND, OR                    4/2/24   \n",
       "2               529.0                    LOUISVILLE                   12/8/21   \n",
       "3               819.0              SEATTLE - TACOMA                   3/22/23   \n",
       "4               504.0                  PHILADELPHIA                   2/20/24   \n",
       "...               ...                           ...                       ...   \n",
       "14440           789.0         TUCSON (SIERRA VISTA)                   2/11/22   \n",
       "14441           516.0                          ERIE                   3/19/21   \n",
       "14442           862.0   SACRAMNTO - STKTN - MODESTO                   2/22/21   \n",
       "14443           770.0                SALT LAKE CITY                   3/19/24   \n",
       "14444           613.0        MINNEAPOLIS - ST. PAUL                   3/18/24   \n",
       "\n",
       "       BracketEntryId BracketEntryCreatedDate  RegionWinner_East  \\\n",
       "0             2074118           3/19/24 18:50                164   \n",
       "1             2692634           3/20/24 16:56                164   \n",
       "2             1252684           3/18/24 15:13                311   \n",
       "3             1950205           3/19/24 15:21                164   \n",
       "4             2756293           3/20/24 18:40                164   \n",
       "...               ...                     ...                ...   \n",
       "14440         2085292           3/19/24 19:05                164   \n",
       "14441          615949           3/17/24 20:22                164   \n",
       "14442           13727            2/21/24 0:10                 77   \n",
       "14443         3019220           3/20/24 23:21                164   \n",
       "14444         3032491           3/20/24 23:37                 37   \n",
       "\n",
       "       RegionWinner_West  RegionWinner_South  RegionWinner_Midwest  \\\n",
       "0                    457                 288                   559   \n",
       "1                    457                 193                   328   \n",
       "2                     29                 334                   169   \n",
       "3                    457                 288                   559   \n",
       "4                    457                 387                   169   \n",
       "...                  ...                 ...                   ...   \n",
       "14440                 29                 288                   559   \n",
       "14441                457                 334                   559   \n",
       "14442                 29                 288                   169   \n",
       "14443                457                 288                   169   \n",
       "14444                610                 387                   260   \n",
       "\n",
       "      E_InstitutionName  E_InstitutionDMACode  E_InstitutionLatitude  \\\n",
       "0                 UConn                   533               41.80910   \n",
       "1                 UConn                   533               41.80910   \n",
       "2              Iowa St.                   679               42.02621   \n",
       "3                 UConn                   533               41.80910   \n",
       "4                 UConn                   533               41.80910   \n",
       "...                 ...                   ...                    ...   \n",
       "14440             UConn                   533               41.80910   \n",
       "14441             UConn                   533               41.80910   \n",
       "14442               BYU                   770               40.25085   \n",
       "14443             UConn                   533               41.80910   \n",
       "14444            Auburn                   522               32.59938   \n",
       "\n",
       "       E_InstitutionLongitude  E_InstitutionConference  \\\n",
       "0                   -72.24995      Big East Conference   \n",
       "1                   -72.24995      Big East Conference   \n",
       "2                   -93.64851        Big 12 Conference   \n",
       "3                   -72.24995      Big East Conference   \n",
       "4                   -72.24995      Big East Conference   \n",
       "...                       ...                      ...   \n",
       "14440               -72.24995      Big East Conference   \n",
       "14441               -72.24995      Big East Conference   \n",
       "14442              -111.64930        Big 12 Conference   \n",
       "14443               -72.24995      Big East Conference   \n",
       "14444               -85.48826  Southeastern Conference   \n",
       "\n",
       "       E_InstitutionEnrollment_Male  E_InstitutionEnrollment_Female  \\\n",
       "0                             10645                           11834   \n",
       "1                             10645                           11834   \n",
       "2                             14070                           11171   \n",
       "3                             10645                           11834   \n",
       "4                             10645                           11834   \n",
       "...                             ...                             ...   \n",
       "14440                         10645                           11834   \n",
       "14441                         10645                           11834   \n",
       "14442                         13555                           14698   \n",
       "14443                         10645                           11834   \n",
       "14444                         12695                           12684   \n",
       "\n",
       "       E_InstitutionEnrollment_Total E_InstitutionNCAAMemberSinceDate  \\\n",
       "0                              22479                       09/01/1910   \n",
       "1                              22479                       09/01/1910   \n",
       "2                              25241                       09/01/1908   \n",
       "3                              22479                       09/01/1910   \n",
       "4                              22479                       09/01/1910   \n",
       "...                              ...                              ...   \n",
       "14440                          22479                       09/01/1910   \n",
       "14441                          22479                       09/01/1910   \n",
       "14442                          28253                       09/01/1939   \n",
       "14443                          22479                       09/01/1910   \n",
       "14444                          25379                       09/01/1910   \n",
       "\n",
       "       E_RegularSeasonWins  E_RegularSeasonLosses  \\\n",
       "0                       31                      3   \n",
       "1                       31                      3   \n",
       "2                       27                      7   \n",
       "3                       31                      3   \n",
       "4                       31                      3   \n",
       "...                    ...                    ...   \n",
       "14440                   31                      3   \n",
       "14441                   31                      3   \n",
       "14442                   23                     10   \n",
       "14443                   31                      3   \n",
       "14444                   27                      7   \n",
       "\n",
       "       E_RegularSeasonAverageAttendance  E_RegularSeasonAverageScore  E_Rk  \\\n",
       "0                              14017.88                        81.47     1   \n",
       "1                              14017.88                        81.47     1   \n",
       "2                              12059.44                        75.56     8   \n",
       "3                              14017.88                        81.47     1   \n",
       "4                              14017.88                        81.47     1   \n",
       "...                                 ...                          ...   ...   \n",
       "14440                          14017.88                        81.47     1   \n",
       "14441                          14017.88                        81.47     1   \n",
       "14442                          13481.27                        81.85    18   \n",
       "14443                          14017.88                        81.47     1   \n",
       "14444                          10182.91                        83.32     4   \n",
       "\n",
       "       E_Seed_Rank  E_NetRtg  E_Luck M_InstitutionName  M_InstitutionDMACode  \\\n",
       "0                1     36.43   0.037            Purdue                   582   \n",
       "1                1     36.43   0.037            Kansas                   616   \n",
       "2                2     26.47   0.002         Creighton                   652   \n",
       "3                1     36.43   0.037            Purdue                   582   \n",
       "4                1     36.43   0.037         Creighton                   652   \n",
       "...            ...       ...     ...               ...                   ...   \n",
       "14440            1     36.43   0.037            Purdue                   582   \n",
       "14441            1     36.43   0.037            Purdue                   582   \n",
       "14442            6     19.96  -0.048         Creighton                   652   \n",
       "14443            1     36.43   0.037         Creighton                   652   \n",
       "14444            4     27.99  -0.080           Gonzaga                   881   \n",
       "\n",
       "       M_InstitutionLatitude  M_InstitutionLongitude M_InstitutionConference  \\\n",
       "0                   40.42821               -86.91444      Big Ten Conference   \n",
       "1                   38.95855               -95.24757       Big 12 Conference   \n",
       "2                   41.26536               -95.94781     Big East Conference   \n",
       "3                   40.42821               -86.91444      Big Ten Conference   \n",
       "4                   41.26536               -95.94781     Big East Conference   \n",
       "...                      ...                     ...                     ...   \n",
       "14440               40.42821               -86.91444      Big Ten Conference   \n",
       "14441               40.42821               -86.91444      Big Ten Conference   \n",
       "14442               41.26536               -95.94781     Big East Conference   \n",
       "14443               41.26536               -95.94781     Big East Conference   \n",
       "14444               47.66653              -117.40060   West Coast Conference   \n",
       "\n",
       "       M_InstitutionEnrollment_Male  M_InstitutionEnrollment_Female  \\\n",
       "0                             21670                           16279   \n",
       "1                              8859                            9845   \n",
       "2                              1789                            2501   \n",
       "3                             21670                           16279   \n",
       "4                              1789                            2501   \n",
       "...                             ...                             ...   \n",
       "14440                         21670                           16279   \n",
       "14441                         21670                           16279   \n",
       "14442                          1789                            2501   \n",
       "14443                          1789                            2501   \n",
       "14444                          2286                            2670   \n",
       "\n",
       "       M_InstitutionEnrollment_Total M_InstitutionNCAAMemberSinceDate  \\\n",
       "0                              37949                       09/01/1914   \n",
       "1                              18704                       09/01/1908   \n",
       "2                               4290                       09/01/1923   \n",
       "3                              37949                       09/01/1914   \n",
       "4                               4290                       09/01/1923   \n",
       "...                              ...                              ...   \n",
       "14440                          37949                       09/01/1914   \n",
       "14441                          37949                       09/01/1914   \n",
       "14442                           4290                       09/01/1923   \n",
       "14443                           4290                       09/01/1923   \n",
       "14444                           4956                       09/01/1938   \n",
       "\n",
       "       M_RegularSeasonWins  M_RegularSeasonLosses  \\\n",
       "0                       29                      4   \n",
       "1                       22                     10   \n",
       "2                       23                      9   \n",
       "3                       29                      4   \n",
       "4                       23                      9   \n",
       "...                    ...                    ...   \n",
       "14440                   29                      4   \n",
       "14441                   29                      4   \n",
       "14442                   23                      9   \n",
       "14443                   23                      9   \n",
       "14444                   25                      7   \n",
       "\n",
       "       M_RegularSeasonAverageAttendance  M_RegularSeasonAverageScore  M_Rk  \\\n",
       "0                              13329.06                        83.39     3   \n",
       "1                              13952.66                        75.25    27   \n",
       "2                              13651.44                        80.53    11   \n",
       "3                              13329.06                        83.39     3   \n",
       "4                              13651.44                        80.53    11   \n",
       "...                                 ...                          ...   ...   \n",
       "14440                          13329.06                        83.39     3   \n",
       "14441                          13329.06                        83.39     3   \n",
       "14442                          13651.44                        80.53    11   \n",
       "14443                          13651.44                        80.53    11   \n",
       "14444                           6368.78                        84.88    12   \n",
       "\n",
       "       M_Seed_Rank  M_NetRtg  M_Luck S_InstitutionName  S_InstitutionDMACode  \\\n",
       "0                1     30.62   0.048           Houston                   618   \n",
       "1                4     17.94   0.058              Duke                   560   \n",
       "2                3     24.22  -0.018          Kentucky                   541   \n",
       "3                1     30.62   0.048           Houston                   618   \n",
       "4                3     24.22  -0.018         Marquette                   617   \n",
       "...            ...       ...     ...               ...                   ...   \n",
       "14440            1     30.62   0.048           Houston                   618   \n",
       "14441            1     30.62   0.048          Kentucky                   541   \n",
       "14442            3     24.22  -0.018           Houston                   618   \n",
       "14443            3     24.22  -0.018           Houston                   618   \n",
       "14444            5     23.17  -0.051         Marquette                   617   \n",
       "\n",
       "       S_InstitutionLatitude  S_InstitutionLongitude  \\\n",
       "0                   29.72039               -95.34354   \n",
       "1                   36.00114               -78.93762   \n",
       "2                   38.03891               -84.50475   \n",
       "3                   29.72039               -95.34354   \n",
       "4                   43.03903               -87.92796   \n",
       "...                      ...                     ...   \n",
       "14440               29.72039               -95.34354   \n",
       "14441               38.03891               -84.50475   \n",
       "14442               29.72039               -95.34354   \n",
       "14443               29.72039               -95.34354   \n",
       "14444               43.03903               -87.92796   \n",
       "\n",
       "         S_InstitutionConference  S_InstitutionEnrollment_Male  \\\n",
       "0              Big 12 Conference                         18290   \n",
       "1      Atlantic Coast Conference                          3137   \n",
       "2        Southeastern Conference                          9596   \n",
       "3              Big 12 Conference                         18290   \n",
       "4            Big East Conference                          3328   \n",
       "...                          ...                           ...   \n",
       "14440          Big 12 Conference                         18290   \n",
       "14441    Southeastern Conference                          9596   \n",
       "14442          Big 12 Conference                         18290   \n",
       "14443          Big 12 Conference                         18290   \n",
       "14444        Big East Conference                          3328   \n",
       "\n",
       "       S_InstitutionEnrollment_Female  S_InstitutionEnrollment_Total  \\\n",
       "0                               19653                          37943   \n",
       "1                                3448                           6585   \n",
       "2                               13127                          22723   \n",
       "3                               19653                          37943   \n",
       "4                                4200                           7528   \n",
       "...                               ...                            ...   \n",
       "14440                           19653                          37943   \n",
       "14441                           13127                          22723   \n",
       "14442                           19653                          37943   \n",
       "14443                           19653                          37943   \n",
       "14444                            4200                           7528   \n",
       "\n",
       "      S_InstitutionNCAAMemberSinceDate  S_RegularSeasonWins  \\\n",
       "0                           09/01/1949                   30   \n",
       "1                           09/01/1925                   24   \n",
       "2                           09/01/1936                   23   \n",
       "3                           09/01/1949                   30   \n",
       "4                           09/01/1928                   25   \n",
       "...                                ...                  ...   \n",
       "14440                       09/01/1949                   30   \n",
       "14441                       09/01/1936                   23   \n",
       "14442                       09/01/1949                   30   \n",
       "14443                       09/01/1949                   30   \n",
       "14444                       09/01/1928                   25   \n",
       "\n",
       "       S_RegularSeasonLosses  S_RegularSeasonAverageAttendance  \\\n",
       "0                          4                           9347.35   \n",
       "1                          8                          11475.81   \n",
       "2                          9                          17427.94   \n",
       "3                          4                           9347.35   \n",
       "4                          9                          14084.65   \n",
       "...                      ...                               ...   \n",
       "14440                      4                           9347.35   \n",
       "14441                      9                          17427.94   \n",
       "14442                      4                           9347.35   \n",
       "14443                      4                           9347.35   \n",
       "14444                      9                          14084.65   \n",
       "\n",
       "       S_RegularSeasonAverageScore  S_Rk  S_Seed_Rank  S_NetRtg  S_Luck  \\\n",
       "0                            73.03     2            1     31.17   0.042   \n",
       "1                            79.84     7            4     26.47  -0.064   \n",
       "2                            89.44    23            3     19.29  -0.040   \n",
       "3                            73.03     2            1     31.17   0.042   \n",
       "4                            78.29    13            2     23.02   0.035   \n",
       "...                            ...   ...          ...       ...     ...   \n",
       "14440                        73.03     2            1     31.17   0.042   \n",
       "14441                        89.44    23            3     19.29  -0.040   \n",
       "14442                        73.03     2            1     31.17   0.042   \n",
       "14443                        73.03     2            1     31.17   0.042   \n",
       "14444                        78.29    13            2     23.02   0.035   \n",
       "\n",
       "      W_InstitutionName  W_InstitutionDMACode  W_InstitutionLatitude  \\\n",
       "0        North Carolina                   560               35.91177   \n",
       "1        North Carolina                   560               35.91177   \n",
       "2               Arizona                   789               32.23267   \n",
       "3        North Carolina                   560               35.91177   \n",
       "4        North Carolina                   560               35.91177   \n",
       "...                 ...                   ...                    ...   \n",
       "14440           Arizona                   789               32.23267   \n",
       "14441    North Carolina                   560               35.91177   \n",
       "14442           Arizona                   789               32.23267   \n",
       "14443    North Carolina                   560               35.91177   \n",
       "14444      Saint Mary's                   807               37.84073   \n",
       "\n",
       "       W_InstitutionLongitude    W_InstitutionConference  \\\n",
       "0                   -79.05097  Atlantic Coast Conference   \n",
       "1                   -79.05097  Atlantic Coast Conference   \n",
       "2                  -110.95080          Pac-12 Conference   \n",
       "3                   -79.05097  Atlantic Coast Conference   \n",
       "4                   -79.05097  Atlantic Coast Conference   \n",
       "...                       ...                        ...   \n",
       "14440              -110.95080          Pac-12 Conference   \n",
       "14441               -79.05097  Atlantic Coast Conference   \n",
       "14442              -110.95080          Pac-12 Conference   \n",
       "14443               -79.05097  Atlantic Coast Conference   \n",
       "14444              -122.10900      West Coast Conference   \n",
       "\n",
       "       W_InstitutionEnrollment_Male  W_InstitutionEnrollment_Female  \\\n",
       "0                              8068                           12174   \n",
       "1                              8068                           12174   \n",
       "2                             13090                           17292   \n",
       "3                              8068                           12174   \n",
       "4                              8068                           12174   \n",
       "...                             ...                             ...   \n",
       "14440                         13090                           17292   \n",
       "14441                          8068                           12174   \n",
       "14442                         13090                           17292   \n",
       "14443                          8068                           12174   \n",
       "14444                           859                            1090   \n",
       "\n",
       "       W_InstitutionEnrollment_Total W_InstitutionNCAAMemberSinceDate  \\\n",
       "0                              20242                       09/01/1906   \n",
       "1                              20242                       09/01/1906   \n",
       "2                              30382                       09/01/1936   \n",
       "3                              20242                       09/01/1906   \n",
       "4                              20242                       09/01/1906   \n",
       "...                              ...                              ...   \n",
       "14440                          30382                       09/01/1936   \n",
       "14441                          20242                       09/01/1906   \n",
       "14442                          30382                       09/01/1936   \n",
       "14443                          20242                       09/01/1906   \n",
       "14444                           1949                       09/01/1961   \n",
       "\n",
       "       W_RegularSeasonWins  W_RegularSeasonLosses  \\\n",
       "0                       27                      7   \n",
       "1                       27                      7   \n",
       "2                       25                      8   \n",
       "3                       27                      7   \n",
       "4                       27                      7   \n",
       "...                    ...                    ...   \n",
       "14440                   25                      8   \n",
       "14441                   27                      7   \n",
       "14442                   25                      8   \n",
       "14443                   27                      7   \n",
       "14444                   26                      7   \n",
       "\n",
       "       W_RegularSeasonAverageAttendance  W_RegularSeasonAverageScore  W_Rk  \\\n",
       "0                              15767.47                        81.47     9   \n",
       "1                              15767.47                        81.47     9   \n",
       "2                              12118.18                        87.94     6   \n",
       "3                              15767.47                        81.47     9   \n",
       "4                              15767.47                        81.47     9   \n",
       "...                                 ...                          ...   ...   \n",
       "14440                          12118.18                        87.94     6   \n",
       "14441                          15767.47                        81.47     9   \n",
       "14442                          12118.18                        87.94     6   \n",
       "14443                          15767.47                        81.47     9   \n",
       "14444                           3458.15                        74.24    20   \n",
       "\n",
       "       W_Seed_Rank  W_NetRtg  W_Luck   m_win_%   s_win_%   e_win_%   w_win_%  \\\n",
       "0                1     26.19  -0.038  0.878788  0.882353  0.911765  0.794118   \n",
       "1                1     26.19  -0.038  0.687500  0.750000  0.911765  0.794118   \n",
       "2                2     26.55  -0.047  0.718750  0.718750  0.794118  0.757576   \n",
       "3                1     26.19  -0.038  0.878788  0.882353  0.911765  0.794118   \n",
       "4                1     26.19  -0.038  0.718750  0.735294  0.911765  0.794118   \n",
       "...            ...       ...     ...       ...       ...       ...       ...   \n",
       "14440            2     26.55  -0.047  0.878788  0.882353  0.911765  0.757576   \n",
       "14441            1     26.19  -0.038  0.878788  0.718750  0.911765  0.794118   \n",
       "14442            2     26.55  -0.047  0.718750  0.882353  0.696970  0.757576   \n",
       "14443            1     26.19  -0.038  0.718750  0.882353  0.911765  0.794118   \n",
       "14444            5     19.43   0.008  0.781250  0.735294  0.794118  0.787879   \n",
       "\n",
       "         closeness  \n",
       "0       856.858920  \n",
       "1       233.225676  \n",
       "2     -1508.231521  \n",
       "3       181.285289  \n",
       "4      -269.573059  \n",
       "...            ...  \n",
       "14440  3562.681680  \n",
       "14441    12.299279  \n",
       "14442  -284.921428  \n",
       "14443   392.233162  \n",
       "14444  -833.677482  \n",
       "\n",
       "[14445 rows x 85 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classic1_df_test\n",
    "#  classic1_df_test.loc[:,['RegionWinner_East', \"RegionWinner_West\", 'E_Rk','E_Seed_Rank', 'W_Rk', 'W_Seed_Rank']]\n",
    "\n",
    "\n",
    "# rank_164 = 1 / (1 + np.exp(-1))\n",
    "# rank_457 = 1/(1 + np.exp(-9))\n",
    "\n",
    "# print(rank_164, rank_457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1307174178.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['closeness'] = closeness(userlat=classic1_df_train['CustomerPostalCodeLatitude'],\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 368.738752668698, tolerance: 2.5577017624828593\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 136.9820171375868, tolerance: 2.557471797386581\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103.1310640902775, tolerance: 2.556538789638654\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 208.73214171903965, tolerance: 2.557490809792106\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 91.51011874376854, tolerance: 2.556977511970864\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.501e+01, tolerance: 3.197e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv ✅\n"
     ]
    }
   ],
   "source": [
    "#Model Two Random Forest Classifier\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "\n",
    "# Load the data\n",
    "df_train = classic1_df_train\n",
    "df_test = df_test\n",
    "\n",
    "# #DownSample Data (Takes % of Dataset and keeps statistical properties)\n",
    "# sample_size_perc = .3\n",
    "# df_train_downsampled = df_train.sample(frac=sample_size_perc, random_state=24)\n",
    "\n",
    "#Add Closeness Feature to df_train\n",
    "df_train['closeness'] = closeness(userlat=classic1_df_train['CustomerPostalCodeLatitude'],\n",
    "                                      userlon=classic1_df_train['CustomerPostalCodeLongitude'],\n",
    "                                      team1lat=classic1_df_train['M_InstitutionLatitude'],\n",
    "                                      team1lon=classic1_df_train['M_InstitutionLongitude'],\n",
    "                                      team2lat=classic1_df_train['S_InstitutionLatitude'],\n",
    "                                      team2lon=classic1_df_train['S_InstitutionLongitude'])\n",
    "\n",
    "\n",
    "#For Full Size Sample\n",
    "# df_test = classic1_df_test #Change df_test to have new created features\n",
    "\n",
    "features_to_withHold = ['M_InstitutionName',\n",
    " 'M_InstitutionDMACode',\n",
    " 'M_InstitutionLatitude',\n",
    " 'M_InstitutionLongitude',\n",
    " 'M_InstitutionNCAAMemberSinceDate',\n",
    " 'M_InstitutionEnrollment_Female',\n",
    " 'S_InstitutionName',\n",
    " 'S_InstitutionDMACode',\n",
    " 'S_InstitutionLatitude',\n",
    " 'S_InstitutionLongitude',\n",
    " 'S_InstitutionEnrollment_Male',\n",
    " 'S_InstitutionEnrollment_Female',\n",
    " 'S_InstitutionNCAAMemberSinceDate'\n",
    " ]\n",
    "\n",
    "# #For Downsampled Training Set\n",
    "# df_train_downsampled = df_train_downsampled.drop(columns = features_to_withHold)\n",
    "\n",
    "# For Full Size Training Set\n",
    "df_train = df_train.drop(columns = features_to_withHold)\n",
    "df_test = df_test.drop(columns = features_to_withHold)\n",
    "\n",
    "\n",
    "# Create 2 List of Features column names for east and west features\n",
    "features_midwest = [col for col in df_train.columns if col.startswith('M_')]\n",
    "features_south = [col for col in df_train.columns if col.startswith('S_')]\n",
    "\n",
    "# Remove Semifinal Winner from both list\n",
    "if 'SemifinalWinner_South_Midwest' in features_south:\n",
    "    features_south.remove('SemifinalWinner_South_Midwest')\n",
    "\n",
    "if 'SemifinalWinner_South_Midwest' in features_midwest:\n",
    "    features_midwest.remove('SemifinalWinner_South_Midwest')\n",
    "\n",
    "\n",
    "# The target variable is SemifinalWinner_East_West\n",
    "y_train = (df_train['SemifinalWinner_South_Midwest'] == df_train['RegionWinner_Midwest']).astype(int)\n",
    "\n",
    "# Combine the East and West features\n",
    "features = features_midwest + features_south\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_train[features],\n",
    "#                                                      (df_train['SemifinalWinner_South_Midwest'] == df_train_down['RegionWinner_Midwest']).astype(int),\n",
    "#                                                        test_size=.2, random_state=24)\n",
    "\n",
    "\n",
    "# Define non-numeric columns (such as postal codes or conference)\n",
    "non_numeric_columns = [ 'M_InstitutionConference',\n",
    "                        'S_InstitutionConference']\n",
    "\n",
    "\n",
    "ordinal_features = ['S_Rk', 'M_Rk','S_Seed_Rank', 'M_Seed_Rank']\n",
    "\n",
    "# Identify numeric columns for scaling (exclude non-numeric columns)\n",
    "numeric_features_tree = [col for col in features if col not in non_numeric_columns]\n",
    "\n",
    "# Identify numeric columns for scaling (exclude non-numeric columns)\n",
    "numeric_features_log = [col for col in features if col not in non_numeric_columns and col not in ordinal_features]\n",
    "\n",
    "\n",
    "# Preprocessing for numeric and non-numeric columns\n",
    "preprocessor_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features_tree),  # Scale numeric features\n",
    "        ('cat', OneHotEncoder(), non_numeric_columns)  # One-hot encode non-numeric features\n",
    "    ])\n",
    "\n",
    "# Preprocessing for numeric and non-numeric columns\n",
    "preprocessor_log = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features_log),  # Scale numeric features\n",
    "        ('cat', OneHotEncoder(), non_numeric_columns),\n",
    "        ('ordinal', sigmoid_transformer, ordinal_features) # One-hot encode non-numeric features\n",
    "    ])\n",
    "\n",
    "# Create the pipeline with preprocessing and the classifier\n",
    "model_RandomForest = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_tree),\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "model_log_reg = Pipeline(\n",
    "    steps=[\n",
    "    ('preprocessor', preprocessor_log),\n",
    "    ('selector', SelectFromModel(LassoCV(cv=5, alphas= [0.0001, 0.001, 0.01, 0.1], random_state = 42),  prefit =False)),\n",
    "    ('classifier', LogisticRegressionCV(cv=5, max_iter=2000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_RandomForest, param_grid=hyperparameter_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(df_train[features], y_train) #I believe I need the predicted values from the training set!\n",
    "\n",
    "\n",
    "y_pred_tree= grid_search.predict(df_test[features])\n",
    "\n",
    "model_log_reg.fit(df_train[features], y_train)\n",
    "y_pred_log_ms = model_log_reg.predict(df_test[features])\n",
    "\n",
    "# print(f'Recall: {recall_score(y_test, y_pred_tree)}')\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred_tree)}')\n",
    "# print(f'Confusian Matrix: {confusion_matrix(y_test, y_pred_tree)}')\n",
    "\n",
    "# print(f'Recall: {recall_score(y_test, y_pred_log)}')\n",
    "# print(f'Accuracy: {accuracy_score(y_test, y_pred_log)}')\n",
    "# print(f'Confusian Matrix: {confusion_matrix(y_test, y_pred_log)}')\n",
    "\n",
    "#Printing Results back from Unique IDs!\n",
    "df_test['SemifinalWinner_South_Midwest'] = df_test['RegionWinner_Midwest'].where(y_pred_log_ms == df_test['RegionWinner_Midwest'], df_test['RegionWinner_South'])\n",
    "\n",
    "# Save the predictions to a CSV (only include the prediction column)\n",
    "# df_test[['SemifinalWinner_South_Midwest']].to_csv(\"predictions_MS.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to predictions.csv ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_InstitutionLatitude'] = nat_champ_df['E_InstitutionLatitude'].where(nat_champ_df[\"SemifinalWinner_East_West\"] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_InstitutionLatitude'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_InstitutionLongitude'] = nat_champ_df['E_InstitutionLongitude'].where(nat_champ_df[\"SemifinalWinner_East_West\"] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_InstitutionLongitude'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_InstitutionLongitude'] = nat_champ_df['M_InstitutionLongitude'].where(nat_champ_df[\"SemifinalWinner_South_Midwest\"] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_InstitutionLongitude'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_InstitutionLatitude'] = nat_champ_df['M_InstitutionLatitude'].where(nat_champ_df[\"SemifinalWinner_South_Midwest\"] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_InstitutionLatitude'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_Total_Enrollment'] = nat_champ_df['E_InstitutionEnrollment_Total'].where(nat_champ_df[\"SemifinalWinner_East_West\"] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_InstitutionEnrollment_Total'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_Total_Enrollment'] = nat_champ_df['M_InstitutionEnrollment_Total'].where(nat_champ_df[\"SemifinalWinner_South_Midwest\"] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_InstitutionEnrollment_Total'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_RegularSeasonWins'] = nat_champ_df['E_RegularSeasonWins'].where(nat_champ_df['SemifinalWinner_East_West'] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_RegularSeasonWins'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_RegularSeasonWins'] = nat_champ_df['M_RegularSeasonWins'].where(nat_champ_df['SemifinalWinner_South_Midwest'] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_RegularSeasonWins'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_RegularSeasonAverageAttendance'] = nat_champ_df['E_RegularSeasonAverageAttendance'].where(nat_champ_df['SemifinalWinner_East_West'] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_RegularSeasonAverageAttendance'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_RegularSeasonAverageAttendance'] = nat_champ_df['M_RegularSeasonAverageAttendance'].where(nat_champ_df['SemifinalWinner_South_Midwest'] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_RegularSeasonAverageAttendance'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_Rk'] = nat_champ_df['E_Rk'].where(nat_champ_df['SemifinalWinner_East_West'] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_Rk'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_Rk'] = nat_champ_df['M_Rk'].where(nat_champ_df['SemifinalWinner_South_Midwest'] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_Rk'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_InstitutionConference'] = nat_champ_df['E_InstitutionConference'].where(nat_champ_df['SemifinalWinner_East_West'] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_InstitutionConference'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_InstitutionConference'] = nat_champ_df['M_InstitutionConference'].where(nat_champ_df['SemifinalWinner_South_Midwest'] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_InstitutionConference'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_Seed_Rank'] = nat_champ_df['E_Seed_Rank'].where(nat_champ_df['SemifinalWinner_East_West'] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_Seed_Rank'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_Seed_Rank'] = nat_champ_df['M_Seed_Rank'].where(nat_champ_df['SemifinalWinner_South_Midwest'] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_Seed_Rank'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_NetRtg'] = nat_champ_df['E_NetRtg'].where(nat_champ_df['SemifinalWinner_East_West'] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_NetRtg'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_NetRtg'] = nat_champ_df['M_NetRtg'].where(nat_champ_df['SemifinalWinner_South_Midwest'] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_NetRtg'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_Luck'] = nat_champ_df['E_Luck'].where(nat_champ_df['SemifinalWinner_East_West'] == nat_champ_df['RegionWinner_East'], nat_champ_df['W_Luck'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_Luck'] = nat_champ_df['M_Luck'].where(nat_champ_df['SemifinalWinner_South_Midwest'] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['S_Luck'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['EW_win_%'] = nat_champ_df['e_win_%'].where(nat_champ_df['SemifinalWinner_East_West'] == nat_champ_df['RegionWinner_East'], nat_champ_df['w_win_%'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['MS_win_%'] = nat_champ_df['m_win_%'].where(nat_champ_df['SemifinalWinner_South_Midwest'] == nat_champ_df['RegionWinner_Midwest'], nat_champ_df['s_win_%'])\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['closeness'] = closeness(\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['win_perc_diff'] = nat_champ_df['EW_win_%'] - nat_champ_df['MS_win_%']\n",
      "/var/folders/40/t1rj18bn0m7gjwdx4lsq57tm0000gn/T/ipykernel_3356/1810808664.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nat_champ_df['NationalChampion_Binary'] = (nat_champ_df['NationalChampion'] == nat_champ_df['SemifinalWinner_East_West']).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Random Forest - Validation):\n",
      "[[ 3786  7407]\n",
      " [ 2538 12270]]\n",
      "Accuracy (Random Forest - Validation): 0.6175147109726549\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 846.516437100443, tolerance: 2.037748748798082\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 931.7327937830541, tolerance: 2.0376672972680585\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 731.232461507163, tolerance: 2.0368787971298365\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 775.8048927298569, tolerance: 2.0385474333241227\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 563.8837332231233, tolerance: 2.0370083220153288\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.182e+03, tolerance: 2.547e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Logistic Regression - Validation):\n",
      "[[ 4117  7076]\n",
      " [ 2784 12024]]\n",
      "Accuracy (Logistic Regression - Validation): 0.6207838160070767\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 907.4042228698199, tolerance: 2.547818970971275\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 607.0102658067153, tolerance: 2.548341946712089\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 818.1214176240828, tolerance: 2.545906795061614\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 915.0232660228321, tolerance: 2.54793653679754\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 784.3830532448119, tolerance: 2.5477097719273183\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/Users/michaelwhitfield/school-coding-projects/mgmt-474/virtual/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+03, tolerance: 3.184e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1. Prepare Training Data: Create a subset and target variable\n",
    "# =============================================================================\n",
    "\n",
    "nat_champ_df = classic1_df_train  # Copy to avoid modifying the original\n",
    "\n",
    "# Define mappings for the EW group: (suffix, true_prefix, false_prefix)\n",
    "ew_cols = [\n",
    "    (\"InstitutionLatitude\", \"E_\", \"W_\"),\n",
    "    (\"InstitutionLongitude\", \"E_\", \"W_\"),\n",
    "    (\"InstitutionEnrollment_Total\", \"E_\", \"W_\"),\n",
    "    (\"RegularSeasonWins\", \"E_\", \"W_\"),\n",
    "    (\"RegularSeasonAverageAttendance\", \"E_\", \"W_\"),\n",
    "    (\"Rk\", \"E_\", \"W_\"),\n",
    "    (\"InstitutionConference\", \"E_\", \"W_\"),\n",
    "    (\"Seed_Rank\", \"E_\", \"W_\"),\n",
    "    (\"NetRtg\", \"E_\", \"W_\"),\n",
    "    (\"Luck\", \"E_\", \"W_\"),\n",
    "    (\"win_%\", \"e_\", \"w_\")\n",
    "]\n",
    "\n",
    "# Define mappings for the MS group: (suffix, true_prefix, false_prefix)\n",
    "ms_cols = [\n",
    "    (\"InstitutionLatitude\", \"M_\", \"S_\"),\n",
    "    (\"InstitutionLongitude\", \"M_\", \"S_\"),\n",
    "    (\"InstitutionEnrollment_Total\", \"M_\", \"S_\"),\n",
    "    (\"RegularSeasonWins\", \"M_\", \"S_\"),\n",
    "    (\"RegularSeasonAverageAttendance\", \"M_\", \"S_\"),\n",
    "    (\"Rk\", \"M_\", \"S_\"),\n",
    "    (\"InstitutionConference\", \"M_\", \"S_\"),\n",
    "    (\"Seed_Rank\", \"M_\", \"S_\"),\n",
    "    (\"NetRtg\", \"M_\", \"S_\"),\n",
    "    (\"Luck\", \"M_\", \"S_\"),\n",
    "    (\"win_%\", \"m_\", \"s_\")\n",
    "]\n",
    "\n",
    "# Create EW columns in the training dataset\n",
    "for suffix, true_prefix, false_prefix in ew_cols:\n",
    "    new_col = \"EW_\" + suffix\n",
    "    nat_champ_df[new_col] = nat_champ_df[true_prefix + suffix].where(\n",
    "        nat_champ_df[\"SemifinalWinner_East_West\"] == nat_champ_df[\"RegionWinner_East\"],\n",
    "        nat_champ_df[false_prefix + suffix]\n",
    "    )\n",
    "\n",
    "# Create MS columns in the training dataset\n",
    "for suffix, true_prefix, false_prefix in ms_cols:\n",
    "    new_col = \"MS_\" + suffix\n",
    "    nat_champ_df[new_col] = nat_champ_df[true_prefix + suffix].where(\n",
    "        nat_champ_df[\"SemifinalWinner_South_Midwest\"] == nat_champ_df[\"RegionWinner_Midwest\"],\n",
    "        nat_champ_df[false_prefix + suffix]\n",
    "    )\n",
    "\n",
    "# For the test dataset\n",
    "# Assume df_test is already loaded and classic1_df_test is available for source values.\n",
    "nat_champ_df_test = df_test\n",
    "\n",
    "# Create EW columns in the test dataset\n",
    "for suffix, true_prefix, false_prefix in ew_cols:\n",
    "    new_col = \"EW_\" + suffix\n",
    "    nat_champ_df_test[new_col] = classic1_df_test[true_prefix + suffix].where(\n",
    "        nat_champ_df_test[\"SemifinalWinner_East_West\"] == classic1_df_test[\"RegionWinner_East\"],\n",
    "        classic1_df_test[false_prefix + suffix]\n",
    "    )\n",
    "\n",
    "# Create MS columns in the test dataset\n",
    "for suffix, true_prefix, false_prefix in ms_cols:\n",
    "    new_col = \"MS_\" + suffix\n",
    "    nat_champ_df_test[new_col] = classic1_df_test[true_prefix + suffix].where(\n",
    "        nat_champ_df_test[\"SemifinalWinner_South_Midwest\"] == classic1_df_test[\"RegionWinner_Midwest\"],\n",
    "        classic1_df_test[false_prefix + suffix]\n",
    "    )\n",
    "\n",
    "\n",
    "# Compute \"closeness\" feature (ensure your closeness function can operate on Series or use apply row-wise)\n",
    "nat_champ_df['closeness'] = closeness(\n",
    "    userlat=nat_champ_df['CustomerPostalCodeLatitude'],\n",
    "    userlon=nat_champ_df['CustomerPostalCodeLongitude'],\n",
    "    team1lat=nat_champ_df['EW_InstitutionLatitude'],\n",
    "    team1lon=nat_champ_df['EW_InstitutionLongitude'],\n",
    "    team2lat=nat_champ_df['MS_InstitutionLatitude'],\n",
    "    team2lon=nat_champ_df['MS_InstitutionLongitude']\n",
    ")\n",
    "\n",
    "nat_champ_df['win_perc_diff'] = nat_champ_df['EW_win_%'] - nat_champ_df['MS_win_%']\n",
    "\n",
    "nat_champ_df_test['closeness'] = closeness(\n",
    "    userlat=nat_champ_df_test['CustomerPostalCodeLatitude'],\n",
    "    userlon=nat_champ_df_test['CustomerPostalCodeLongitude'],\n",
    "    team1lat=nat_champ_df_test['EW_InstitutionLatitude'],\n",
    "    team1lon=nat_champ_df_test['EW_InstitutionLongitude'],\n",
    "    team2lat=nat_champ_df_test['MS_InstitutionLatitude'],\n",
    "    team2lon=nat_champ_df_test['MS_InstitutionLongitude']\n",
    ")\n",
    "\n",
    "nat_champ_df_test['win_perc_diff'] = nat_champ_df_test['EW_win_%'] - nat_champ_df_test['MS_win_%']\n",
    "\n",
    "nat_champ_df['NationalChampion_Binary'] = (nat_champ_df['NationalChampion'] == nat_champ_df['SemifinalWinner_East_West']).astype(int)\n",
    "\n",
    "\n",
    "# ----- Drop unwanted columns (per your feature withholding list) -----\n",
    "features_to_withHold = [\n",
    "    'M_InstitutionName',\n",
    "    'M_InstitutionDMACode',\n",
    "    'M_InstitutionLatitude',\n",
    "    'M_InstitutionLongitude',\n",
    "    'M_InstitutionNCAAMemberSinceDate',\n",
    "    'M_InstitutionEnrollment_Female',\n",
    "    'S_InstitutionName',\n",
    "    'S_InstitutionDMACode',\n",
    "    'S_InstitutionLatitude',\n",
    "    'S_InstitutionLongitude',\n",
    "    'S_InstitutionEnrollment_Male',\n",
    "    'S_InstitutionEnrollment_Female',\n",
    "    'S_InstitutionNCAAMemberSinceDate',\n",
    "    'E_InstitutionName',\n",
    "    'E_InstitutionDMACode',\n",
    "    'E_InstitutionLatitude',\n",
    "    'E_InstitutionLongitude',\n",
    "    'E_InstitutionNCAAMemberSinceDate',\n",
    "    'E_InstitutionEnrollment_Female',\n",
    "    'W_InstitutionName',\n",
    "    'W_InstitutionDMACode',\n",
    "    'W_InstitutionLatitude',\n",
    "    'W_InstitutionLongitude',\n",
    "    'W_InstitutionEnrollment_Male',\n",
    "    'W_InstitutionEnrollment_Female',\n",
    "    'W_InstitutionNCAAMemberSinceDate',\n",
    "    'RegionWinner_Midwest',\n",
    "    'RegionWinner_South',\n",
    "    'RegionWinner_East',\n",
    "    'RegionWinner_West',\n",
    "     'CustomerPostalCodeLatitude', 'CustomerPostalCodeLongitude',\n",
    "     'CustomerDMACode', 'CustomerDMADescription', 'CustomerDMADescription', 'NCAACustomerRecordCreated', \n",
    "    'BracketEntryCreatedDate', 'SemifinalWinner_East_West',\n",
    "    'SemifinalWinner_South_Midwest', 'E_InstitutionConference', 'E_InstitutionEnrollment_Male', 'E_InstitutionEnrollment_Total',\n",
    "    'E_RegularSeasonWins', 'E_RegularSeasonLosses', 'E_RegularSeasonAverageAttendance', 'E_RegularSeasonAverageScore', 'E_Rk',\n",
    "        'E_Seed_Rank', 'E_NetRtg', 'E_Luck', 'M_InstitutionConference', 'M_InstitutionEnrollment_Male', 'M_InstitutionEnrollment_Total',\n",
    "        'M_RegularSeasonWins', 'M_RegularSeasonLosses', 'M_RegularSeasonAverageAttendance', 'M_RegularSeasonAverageScore', 'M_Rk', 'M_Seed_Rank',\n",
    "            'M_NetRtg', 'M_Luck', 'S_InstitutionConference', 'S_InstitutionEnrollment_Total', 'S_RegularSeasonWins', 'S_RegularSeasonLosses',\n",
    "            'S_RegularSeasonAverageAttendance', 'S_RegularSeasonAverageScore', 'S_Rk', 'S_Seed_Rank', 'S_NetRtg', 'S_Luck', 'W_InstitutionConference',\n",
    "                'W_InstitutionEnrollment_Total', 'W_RegularSeasonWins', 'W_RegularSeasonLosses', \n",
    "                'W_RegularSeasonAverageAttendance', 'W_RegularSeasonAverageScore', 'W_Rk', 'W_Seed_Rank', 'W_NetRtg', 'W_Luck', 'm_win_%', \n",
    "                's_win_%', 'e_win_%', 'w_win_%', \n",
    "]\n",
    "\n",
    "features_test_to_withhold = [ 'CustomerPostalCodeLatitude', 'CustomerPostalCodeLongitude',\n",
    "                             'BracketEntryCreatedDate', 'NCAACustomerRecordCreated',\n",
    "       'RegionWinner_East', 'RegionWinner_West',\n",
    "       'RegionWinner_South', 'RegionWinner_Midwest', 'E_InstitutionConference',\n",
    "       'E_InstitutionEnrollment_Male',\n",
    "       'E_RegularSeasonWins', 'E_RegularSeasonLosses',\n",
    "       'E_RegularSeasonAverageAttendance', 'E_RegularSeasonAverageScore',\n",
    "       'E_Rk', 'E_Seed_Rank', 'E_NetRtg', 'E_Luck', 'M_InstitutionConference',\n",
    "       'M_InstitutionEnrollment_Male', 'M_InstitutionEnrollment_Total',\n",
    "       'M_RegularSeasonWins', 'M_RegularSeasonLosses',\n",
    "       'M_RegularSeasonAverageAttendance', 'M_RegularSeasonAverageScore',\n",
    "       'M_Rk', 'M_Seed_Rank', 'M_NetRtg', 'M_Luck', 'S_InstitutionConference',\n",
    "       'S_InstitutionEnrollment_Total', 'S_RegularSeasonWins',\n",
    "       'S_RegularSeasonLosses', 'S_RegularSeasonAverageAttendance',\n",
    "       'S_RegularSeasonAverageScore', 'S_Rk', 'S_Seed_Rank', 'S_NetRtg',\n",
    "       'S_Luck', 'W_InstitutionConference', 'W_InstitutionEnrollment_Total',\n",
    "       'W_RegularSeasonWins', 'W_RegularSeasonLosses',\n",
    "       'W_RegularSeasonAverageAttendance', 'W_RegularSeasonAverageScore',\n",
    "       'W_Rk', 'W_Seed_Rank', 'W_NetRtg', 'W_Luck', 'm_win_%', 's_win_%',\n",
    "       'e_win_%', 'w_win_%','MS_Longintude', 'MS_Latitude',\n",
    "       'CustomerDMACode', 'CustomerDMADescription','CustomerDMADescription', 'NCAACustomerRecordCreated'\n",
    "       ]\n",
    "\n",
    "nat_champ_df = nat_champ_df.drop(columns=features_to_withHold)\n",
    "# print(nat_champ_df_test.columns)\n",
    "nat_champ_test = nat_champ_df_test.drop(columns=features_test_to_withhold)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Define Features for Modeling\n",
    "# =============================================================================\n",
    "\n",
    "# Define non-numeric and ordinal features (adjust based on your data)\n",
    "non_numeric_columns =  ['EW_InstitutionConference','MS_InstitutionConference']\n",
    "ordinal_features = ['MS_Rk', 'EW_Rk', 'MS_Seed_Rank', 'EW_Seed_Rank']\n",
    "\n",
    "# Define features as all columns except target columns\n",
    "features = [col for col in nat_champ_df.columns if col not in ['NationalChampion', 'NationalChampion_Binary']]\n",
    "\n",
    "# Identify numeric features for different models\n",
    "numeric_features_tree = [col for col in features if col not in non_numeric_columns]\n",
    "numeric_features_log = [col for col in features if col not in non_numeric_columns + ordinal_features]\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Split Data for Evaluation and Final Model Training\n",
    "# =============================================================================\n",
    "\n",
    "# Use a validation split for evaluation\n",
    "X = nat_champ_df[features]\n",
    "y = nat_champ_df['NationalChampion_Binary']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "# For final predictions, prepare full training and test sets\n",
    "X_train_full = X\n",
    "y_train_full = y\n",
    "X_test_full = nat_champ_test\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Preprocessing Pipelines\n",
    "# =============================================================================\n",
    "\n",
    "preprocessor_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features_tree),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), non_numeric_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor_log = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features_log),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), non_numeric_columns),\n",
    "        ('ordinal', sigmoid_transformer, ordinal_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Build Model Pipelines and Tune Hyperparameters\n",
    "# =============================================================================\n",
    "\n",
    "# Random Forest Pipeline\n",
    "model_RandomForest = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_tree),\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Logistic Regression Pipeline\n",
    "model_log_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_log),\n",
    "    ('selector', SelectFromModel(LassoCV(cv=5, alphas=[0.0001, 0.001, 0.01, 0.1], random_state=42))),\n",
    "    ('classifier', LogisticRegressionCV(cv=5, max_iter=2000))\n",
    "])\n",
    "\n",
    "# Hyperparameter grid for Random Forest\n",
    "hyperparameter_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model_RandomForest, param_grid=hyperparameter_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Model Fitting and Evaluation on Validation Set\n",
    "# =============================================================================\n",
    "\n",
    "# # Fit Random Forest on training split\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# y_pred_tree_val = grid_search.predict(X_val)\n",
    "\n",
    "# # Evaluate Random Forest on validation split\n",
    "# print(\"\\nConfusion Matrix (Random Forest - Validation):\")\n",
    "# print(confusion_matrix(y_val, y_pred_tree_val))\n",
    "# print(f\"Accuracy (Random Forest - Validation): {accuracy_score(y_val, y_pred_tree_val)}\\n\")\n",
    "\n",
    "# Fit Logistic Regression on training split\n",
    "model_log_reg.fit(X_train, y_train)\n",
    "y_pred_log_val = model_log_reg.predict(X_val)\n",
    "\n",
    "# Evaluate Logistic Regression on validation split\n",
    "print(\"Confusion Matrix (Logistic Regression - Validation):\")\n",
    "print(confusion_matrix(y_val, y_pred_log_val))\n",
    "print(f\"Accuracy (Logistic Regression - Validation): {accuracy_score(y_val, y_pred_log_val)}\\n\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Final Model Training on Full Data and Test Predictions\n",
    "# =============================================================================\n",
    "\n",
    "# # Fit final Random Forest model on full training data and predict test set\n",
    "# grid_search.fit(X_train_full, y_train_full)\n",
    "# y_pred_tree_test = grid_search.predict(X_test_full)\n",
    "\n",
    "# Fit final Logistic Regression model on full training data and predict test set\n",
    "model_log_reg.fit(X_train_full, y_train_full)\n",
    "y_pred_log_test = model_log_reg.predict(X_test_full)\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Final National Champion Prediction on Test Data\n",
    "# =============================================================================\n",
    "\n",
    "nat_champ_df_test['BracketEntryId'] = classic1_df_test['BracketEntryId']\n",
    "nat_champ_df_test['NationalChampion'] = np.where(\n",
    "    y_pred_log_test == 1,\n",
    "    nat_champ_test['SemifinalWinner_East_West'],\n",
    "    nat_champ_test['SemifinalWinner_South_Midwest']\n",
    ")\n",
    "nat_champ_df_test\n",
    "nat_champ_df_test.loc[\n",
    "    :, ['BracketEntryId', 'SemifinalWinner_East_West', 'SemifinalWinner_South_Midwest', 'NationalChampion']\n",
    "].to_csv('predictions_joint_test.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_1 = ax_1 = sns.countplot(x=model_1_df['SemifinalWinner_South_Midwest'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstitutionID</th>\n",
       "      <th>InstitutionName</th>\n",
       "      <th>InstitutionNickname</th>\n",
       "      <th>InstitutionAbbreviation</th>\n",
       "      <th>InstitutionCity</th>\n",
       "      <th>InstitutionState</th>\n",
       "      <th>InstitutionPostalCode</th>\n",
       "      <th>InstitutionDMACode</th>\n",
       "      <th>InstitutionDMADescription</th>\n",
       "      <th>InstitutionLatitude</th>\n",
       "      <th>InstitutionLongitude</th>\n",
       "      <th>InstitutionConference</th>\n",
       "      <th>InstitutionEnrollment_Male</th>\n",
       "      <th>InstitutionEnrollment_Female</th>\n",
       "      <th>InstitutionEnrollment_Total</th>\n",
       "      <th>InstitutionNCAAMemberSinceDate</th>\n",
       "      <th>RegularSeasonWins</th>\n",
       "      <th>RegularSeasonLosses</th>\n",
       "      <th>RegularSeasonAverageAttendance</th>\n",
       "      <th>RegularSeasonAverageScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>288</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Cougars</td>\n",
       "      <td>HOU</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>77204</td>\n",
       "      <td>618</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td>29.72039</td>\n",
       "      <td>-95.34354</td>\n",
       "      <td>Big 12 Conference</td>\n",
       "      <td>18290</td>\n",
       "      <td>19653</td>\n",
       "      <td>37943</td>\n",
       "      <td>09/01/1949</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>9347.35</td>\n",
       "      <td>73.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    InstitutionID InstitutionName InstitutionNickname InstitutionAbbreviation  \\\n",
       "14            288         Houston             Cougars                     HOU   \n",
       "\n",
       "   InstitutionCity InstitutionState InstitutionPostalCode  InstitutionDMACode  \\\n",
       "14         Houston               TX                 77204                 618   \n",
       "\n",
       "   InstitutionDMADescription  InstitutionLatitude  InstitutionLongitude  \\\n",
       "14                   HOUSTON             29.72039             -95.34354   \n",
       "\n",
       "   InstitutionConference  InstitutionEnrollment_Male  \\\n",
       "14     Big 12 Conference                       18290   \n",
       "\n",
       "    InstitutionEnrollment_Female  InstitutionEnrollment_Total  \\\n",
       "14                         19653                        37943   \n",
       "\n",
       "   InstitutionNCAAMemberSinceDate  RegularSeasonWins  RegularSeasonLosses  \\\n",
       "14                     09/01/1949                 30                    4   \n",
       "\n",
       "    RegularSeasonAverageAttendance  RegularSeasonAverageScore  \n",
       "14                         9347.35                      73.03  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_info[college_info['InstitutionID'] == 288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstitutionID</th>\n",
       "      <th>InstitutionName</th>\n",
       "      <th>InstitutionDMACode</th>\n",
       "      <th>RegularSeasonWins</th>\n",
       "      <th>RegularSeasonLosses</th>\n",
       "      <th>RegularSeasonAverageAttendance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>288</td>\n",
       "      <td>Houston</td>\n",
       "      <td>618</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>9347.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>559</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>582</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>13329.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>387</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>617</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>14084.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>694</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>557</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>16065.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>334</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>541</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>17427.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>169</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>652</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>13651.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    InstitutionID InstitutionName  InstitutionDMACode  RegularSeasonWins  \\\n",
       "14            288         Houston                 618                 30   \n",
       "23            559          Purdue                 582                 29   \n",
       "13            387       Marquette                 617                 25   \n",
       "37            694       Tennessee                 557                 24   \n",
       "9             334        Kentucky                 541                 23   \n",
       "61            169       Creighton                 652                 23   \n",
       "\n",
       "    RegularSeasonLosses  RegularSeasonAverageAttendance  \n",
       "14                    4                         9347.35  \n",
       "23                    4                        13329.06  \n",
       "13                    9                        14084.65  \n",
       "37                    8                        16065.47  \n",
       "9                     9                        17427.94  \n",
       "61                    9                        13651.44  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_picks = college_info[(college_info[\"InstitutionID\"] == 559) |\n",
    "             (college_info[\"InstitutionID\"] == 334) |\n",
    "             (college_info[\"InstitutionID\"] == 387) |\n",
    "             (college_info[\"InstitutionID\"] == 694) |\n",
    "             (college_info['InstitutionID'] == 169) |\n",
    "             (college_info[\"InstitutionID\"] == 288)].sort_values('RegularSeasonWins', ascending=False)\n",
    "top_picks.loc[:, ['InstitutionID', 'InstitutionName', 'InstitutionDMACode','RegularSeasonWins','RegularSeasonLosses','RegularSeasonAverageAttendance' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstitutionID</th>\n",
       "      <th>InstitutionName</th>\n",
       "      <th>InstitutionNickname</th>\n",
       "      <th>InstitutionAbbreviation</th>\n",
       "      <th>InstitutionCity</th>\n",
       "      <th>InstitutionState</th>\n",
       "      <th>InstitutionPostalCode</th>\n",
       "      <th>InstitutionDMACode</th>\n",
       "      <th>InstitutionDMADescription</th>\n",
       "      <th>InstitutionLatitude</th>\n",
       "      <th>InstitutionLongitude</th>\n",
       "      <th>InstitutionConference</th>\n",
       "      <th>InstitutionEnrollment_Male</th>\n",
       "      <th>InstitutionEnrollment_Female</th>\n",
       "      <th>InstitutionEnrollment_Total</th>\n",
       "      <th>InstitutionNCAAMemberSinceDate</th>\n",
       "      <th>RegularSeasonWins</th>\n",
       "      <th>RegularSeasonLosses</th>\n",
       "      <th>RegularSeasonAverageAttendance</th>\n",
       "      <th>RegularSeasonAverageScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>334</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>Wildcats</td>\n",
       "      <td>UK</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>KY</td>\n",
       "      <td>40506</td>\n",
       "      <td>541</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>38.03891</td>\n",
       "      <td>-84.50475</td>\n",
       "      <td>Southeastern Conference</td>\n",
       "      <td>9596</td>\n",
       "      <td>13127</td>\n",
       "      <td>22723</td>\n",
       "      <td>09/01/1936</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>17427.94</td>\n",
       "      <td>89.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InstitutionID InstitutionName InstitutionNickname InstitutionAbbreviation  \\\n",
       "9            334        Kentucky            Wildcats                      UK   \n",
       "\n",
       "  InstitutionCity InstitutionState InstitutionPostalCode  InstitutionDMACode  \\\n",
       "9       Lexington               KY                 40506                 541   \n",
       "\n",
       "  InstitutionDMADescription  InstitutionLatitude  InstitutionLongitude  \\\n",
       "9                 LEXINGTON             38.03891             -84.50475   \n",
       "\n",
       "     InstitutionConference  InstitutionEnrollment_Male  \\\n",
       "9  Southeastern Conference                        9596   \n",
       "\n",
       "   InstitutionEnrollment_Female  InstitutionEnrollment_Total  \\\n",
       "9                         13127                        22723   \n",
       "\n",
       "  InstitutionNCAAMemberSinceDate  RegularSeasonWins  RegularSeasonLosses  \\\n",
       "9                     09/01/1936                 23                    9   \n",
       "\n",
       "   RegularSeasonAverageAttendance  RegularSeasonAverageScore  \n",
       "9                        17427.94                      89.44  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_info[college_info[\"InstitutionID\"] == 334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstitutionID</th>\n",
       "      <th>InstitutionName</th>\n",
       "      <th>InstitutionNickname</th>\n",
       "      <th>InstitutionAbbreviation</th>\n",
       "      <th>InstitutionCity</th>\n",
       "      <th>InstitutionState</th>\n",
       "      <th>InstitutionPostalCode</th>\n",
       "      <th>InstitutionDMACode</th>\n",
       "      <th>InstitutionDMADescription</th>\n",
       "      <th>InstitutionLatitude</th>\n",
       "      <th>InstitutionLongitude</th>\n",
       "      <th>InstitutionConference</th>\n",
       "      <th>InstitutionEnrollment_Male</th>\n",
       "      <th>InstitutionEnrollment_Female</th>\n",
       "      <th>InstitutionEnrollment_Total</th>\n",
       "      <th>InstitutionNCAAMemberSinceDate</th>\n",
       "      <th>RegularSeasonWins</th>\n",
       "      <th>RegularSeasonLosses</th>\n",
       "      <th>RegularSeasonAverageAttendance</th>\n",
       "      <th>RegularSeasonAverageScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>387</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>Golden Eagles</td>\n",
       "      <td>MARQ</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>53233</td>\n",
       "      <td>617</td>\n",
       "      <td>MILWAUKEE</td>\n",
       "      <td>43.03903</td>\n",
       "      <td>-87.92796</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>3328</td>\n",
       "      <td>4200</td>\n",
       "      <td>7528</td>\n",
       "      <td>09/01/1928</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>14084.65</td>\n",
       "      <td>78.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    InstitutionID InstitutionName InstitutionNickname InstitutionAbbreviation  \\\n",
       "13            387       Marquette       Golden Eagles                    MARQ   \n",
       "\n",
       "   InstitutionCity InstitutionState InstitutionPostalCode  InstitutionDMACode  \\\n",
       "13       Milwaukee               WI                 53233                 617   \n",
       "\n",
       "   InstitutionDMADescription  InstitutionLatitude  InstitutionLongitude  \\\n",
       "13                 MILWAUKEE             43.03903             -87.92796   \n",
       "\n",
       "   InstitutionConference  InstitutionEnrollment_Male  \\\n",
       "13   Big East Conference                        3328   \n",
       "\n",
       "    InstitutionEnrollment_Female  InstitutionEnrollment_Total  \\\n",
       "13                          4200                         7528   \n",
       "\n",
       "   InstitutionNCAAMemberSinceDate  RegularSeasonWins  RegularSeasonLosses  \\\n",
       "13                     09/01/1928                 25                    9   \n",
       "\n",
       "    RegularSeasonAverageAttendance  RegularSeasonAverageScore  \n",
       "13                        14084.65                      78.29  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_info[college_info[\"InstitutionID\"] == 387]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstitutionID</th>\n",
       "      <th>InstitutionName</th>\n",
       "      <th>InstitutionNickname</th>\n",
       "      <th>InstitutionAbbreviation</th>\n",
       "      <th>InstitutionCity</th>\n",
       "      <th>InstitutionState</th>\n",
       "      <th>InstitutionPostalCode</th>\n",
       "      <th>InstitutionDMACode</th>\n",
       "      <th>InstitutionDMADescription</th>\n",
       "      <th>InstitutionLatitude</th>\n",
       "      <th>InstitutionLongitude</th>\n",
       "      <th>InstitutionConference</th>\n",
       "      <th>InstitutionEnrollment_Male</th>\n",
       "      <th>InstitutionEnrollment_Female</th>\n",
       "      <th>InstitutionEnrollment_Total</th>\n",
       "      <th>InstitutionNCAAMemberSinceDate</th>\n",
       "      <th>RegularSeasonWins</th>\n",
       "      <th>RegularSeasonLosses</th>\n",
       "      <th>RegularSeasonAverageAttendance</th>\n",
       "      <th>RegularSeasonAverageScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>164</td>\n",
       "      <td>UConn</td>\n",
       "      <td>Huskies</td>\n",
       "      <td>UCONN</td>\n",
       "      <td>Storrs</td>\n",
       "      <td>CT</td>\n",
       "      <td>06269</td>\n",
       "      <td>533</td>\n",
       "      <td>HARTFORD &amp; NEW HAVEN</td>\n",
       "      <td>41.8091</td>\n",
       "      <td>-72.24995</td>\n",
       "      <td>Big East Conference</td>\n",
       "      <td>10645</td>\n",
       "      <td>11834</td>\n",
       "      <td>22479</td>\n",
       "      <td>09/01/1910</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>14017.88</td>\n",
       "      <td>81.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    InstitutionID InstitutionName InstitutionNickname InstitutionAbbreviation  \\\n",
       "24            164           UConn             Huskies                   UCONN   \n",
       "\n",
       "   InstitutionCity InstitutionState InstitutionPostalCode  InstitutionDMACode  \\\n",
       "24          Storrs               CT                 06269                 533   \n",
       "\n",
       "   InstitutionDMADescription  InstitutionLatitude  InstitutionLongitude  \\\n",
       "24      HARTFORD & NEW HAVEN              41.8091             -72.24995   \n",
       "\n",
       "   InstitutionConference  InstitutionEnrollment_Male  \\\n",
       "24   Big East Conference                       10645   \n",
       "\n",
       "    InstitutionEnrollment_Female  InstitutionEnrollment_Total  \\\n",
       "24                         11834                        22479   \n",
       "\n",
       "   InstitutionNCAAMemberSinceDate  RegularSeasonWins  RegularSeasonLosses  \\\n",
       "24                     09/01/1910                 31                    3   \n",
       "\n",
       "    RegularSeasonAverageAttendance  RegularSeasonAverageScore  \n",
       "24                        14017.88                      81.47  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_info[college_info[\"InstitutionID\"] == 164]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semi_midwest_south_count</th>\n",
       "      <th>semi_east_west_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerDMACode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>719</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501.0</th>\n",
       "      <td>15432</td>\n",
       "      <td>15432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502.0</th>\n",
       "      <td>347</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503.0</th>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504.0</th>\n",
       "      <td>8417</td>\n",
       "      <td>8417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855.0</th>\n",
       "      <td>325</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862.0</th>\n",
       "      <td>2230</td>\n",
       "      <td>2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866.0</th>\n",
       "      <td>492</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868.0</th>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881.0</th>\n",
       "      <td>3595</td>\n",
       "      <td>3595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 semi_midwest_south_count  semi_east_west_count\n",
       "CustomerDMACode                                                \n",
       "500.0                                 719                   719\n",
       "501.0                               15432                 15432\n",
       "502.0                                 347                   347\n",
       "503.0                                 202                   202\n",
       "504.0                                8417                  8417\n",
       "...                                   ...                   ...\n",
       "855.0                                 325                   325\n",
       "862.0                                2230                  2230\n",
       "866.0                                 492                   492\n",
       "868.0                                 180                   180\n",
       "881.0                                3595                  3595\n",
       "\n",
       "[209 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dma_count_groupby = classic1_df_train.groupby(by='CustomerDMACode').agg(semi_midwest_south_count= pd.NamedAgg(column='SemifinalWinner_South_Midwest', aggfunc='count'),\n",
    "                                              semi_east_west_count= pd.NamedAgg(column='SemifinalWinner_East_West', aggfunc='count'))\n",
    "dma_count_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SemifinalWinner_South_Midwest</th>\n",
       "      <th>559</th>\n",
       "      <th>334</th>\n",
       "      <th>387</th>\n",
       "      <th>694</th>\n",
       "      <th>169</th>\n",
       "      <th>288</th>\n",
       "      <th>772</th>\n",
       "      <th>Sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerDMACode</th>\n",
       "      <th>CustomerDMADescription</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <th>PORTLAND - AUBURN</th>\n",
       "      <td>0.199219</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501.0</th>\n",
       "      <th>NEW YORK</th>\n",
       "      <td>0.162795</td>\n",
       "      <td>0.139371</td>\n",
       "      <td>0.059340</td>\n",
       "      <td>0.093305</td>\n",
       "      <td>0.083935</td>\n",
       "      <td>0.270935</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.809682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502.0</th>\n",
       "      <th>BINGHAMTON</th>\n",
       "      <td>0.203704</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.120370</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503.0</th>\n",
       "      <th>MACON</th>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504.0</th>\n",
       "      <th>PHILADELPHIA</th>\n",
       "      <td>0.179601</td>\n",
       "      <td>0.131190</td>\n",
       "      <td>0.061345</td>\n",
       "      <td>0.101626</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>0.268662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.825942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855.0</th>\n",
       "      <th>SANTABARBRA - SANMAR - SANLUOB</th>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.311828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862.0</th>\n",
       "      <th>SACRAMNTO - STKTN - MODESTO</th>\n",
       "      <td>0.199721</td>\n",
       "      <td>0.113128</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.082402</td>\n",
       "      <td>0.057263</td>\n",
       "      <td>0.293296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.796089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866.0</th>\n",
       "      <th>FRESNO - VISALIA</th>\n",
       "      <td>0.267974</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.052288</td>\n",
       "      <td>0.287582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868.0</th>\n",
       "      <th>CHICO - REDDING</th>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881.0</th>\n",
       "      <th>SPOKANE</th>\n",
       "      <td>0.196097</td>\n",
       "      <td>0.088290</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>0.080855</td>\n",
       "      <td>0.057621</td>\n",
       "      <td>0.250929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SemifinalWinner_South_Midwest                        559       334       387  \\\n",
       "CustomerDMACode CustomerDMADescription                                         \n",
       "500.0           PORTLAND - AUBURN               0.199219  0.164062  0.054688   \n",
       "501.0           NEW YORK                        0.162795  0.139371  0.059340   \n",
       "502.0           BINGHAMTON                      0.203704  0.185185  0.046296   \n",
       "503.0           MACON                           0.253968  0.142857  0.031746   \n",
       "504.0           PHILADELPHIA                    0.179601  0.131190  0.061345   \n",
       "...                                                  ...       ...       ...   \n",
       "855.0           SANTABARBRA - SANMAR - SANLUOB  0.215054  0.075269  0.064516   \n",
       "862.0           SACRAMNTO - STKTN - MODESTO     0.199721  0.113128  0.050279   \n",
       "866.0           FRESNO - VISALIA                0.267974  0.111111  0.045752   \n",
       "868.0           CHICO - REDDING                 0.175676  0.229730  0.040541   \n",
       "881.0           SPOKANE                         0.196097  0.088290  0.071561   \n",
       "\n",
       "SemifinalWinner_South_Midwest                        694       169       288  \\\n",
       "CustomerDMACode CustomerDMADescription                                         \n",
       "500.0           PORTLAND - AUBURN               0.085938  0.078125  0.246094   \n",
       "501.0           NEW YORK                        0.093305  0.083935  0.270935   \n",
       "502.0           BINGHAMTON                      0.120370  0.046296  0.166667   \n",
       "503.0           MACON                           0.095238  0.079365  0.158730   \n",
       "504.0           PHILADELPHIA                    0.101626  0.083518  0.268662   \n",
       "...                                                  ...       ...       ...   \n",
       "855.0           SANTABARBRA - SANMAR - SANLUOB  0.053763  0.032258  0.311828   \n",
       "862.0           SACRAMNTO - STKTN - MODESTO     0.082402  0.057263  0.293296   \n",
       "866.0           FRESNO - VISALIA                0.058824  0.052288  0.287582   \n",
       "868.0           CHICO - REDDING                 0.027027  0.175676  0.189189   \n",
       "881.0           SPOKANE                         0.080855  0.057621  0.250929   \n",
       "\n",
       "SemifinalWinner_South_Midwest                        772       Sum  \n",
       "CustomerDMACode CustomerDMADescription                              \n",
       "500.0           PORTLAND - AUBURN               0.000000  0.828125  \n",
       "501.0           NEW YORK                        0.000976  0.809682  \n",
       "502.0           BINGHAMTON                      0.000000  0.768519  \n",
       "503.0           MACON                           0.000000  0.761905  \n",
       "504.0           PHILADELPHIA                    0.000000  0.825942  \n",
       "...                                                  ...       ...  \n",
       "855.0           SANTABARBRA - SANMAR - SANLUOB  0.000000  0.752688  \n",
       "862.0           SACRAMNTO - STKTN - MODESTO     0.000000  0.796089  \n",
       "866.0           FRESNO - VISALIA                0.000000  0.823529  \n",
       "868.0           CHICO - REDDING                 0.000000  0.837838  \n",
       "881.0           SPOKANE                         0.000000  0.745353  \n",
       "\n",
       "[209 rows x 8 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dma_distribution_south_midwest = classic1_df_train.groupby(by =['CustomerDMACode', 'CustomerDMADescription'])['SemifinalWinner_South_Midwest'] \\\n",
    "                                             .value_counts() \\\n",
    "                                             .unstack(fill_value=0)\n",
    "# dma_distribution_south_midwest.sort_values(559, ascending=False).head(20)\n",
    "\n",
    "dma_distribution_south_midwest_prop = dma_distribution_south_midwest.div(dma_distribution_south_midwest.sum(axis=1), axis=0)\n",
    "\n",
    "dma_distribution_south_midwest_prop.sort_values(772, ascending=False).head(10)\n",
    "top_picks_by_dma = dma_distribution_south_midwest_prop.loc[:,[559, 334, 387, 694, 169, 288, 772]]\n",
    "top_picks_by_dma['Sum'] = top_picks_by_dma[559] + top_picks_by_dma[334] + top_picks_by_dma[387] + top_picks_by_dma[694] + top_picks_by_dma[169] \\\n",
    "+ top_picks_by_dma[288]\n",
    "\n",
    "\n",
    "top_picks_by_dma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8123340775752241\n"
     ]
    }
   ],
   "source": [
    "print(top_picks_by_dma.Sum.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax_1 = ax_1 = sns.countplot(x=model_1_df['SemifinalWinner_East_West'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SemifinalWinner_East_West</th>\n",
       "      <th>29</th>\n",
       "      <th>311</th>\n",
       "      <th>457</th>\n",
       "      <th>164</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerDMACode</th>\n",
       "      <th>CustomerDMADescription</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <th>PORTLAND - AUBURN</th>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.167969</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501.0</th>\n",
       "      <th>NEW YORK</th>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.068124</td>\n",
       "      <td>0.148351</td>\n",
       "      <td>0.484287</td>\n",
       "      <td>0.819442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502.0</th>\n",
       "      <th>BINGHAMTON</th>\n",
       "      <td>0.212963</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503.0</th>\n",
       "      <th>MACON</th>\n",
       "      <td>0.063492</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504.0</th>\n",
       "      <th>PHILADELPHIA</th>\n",
       "      <td>0.133038</td>\n",
       "      <td>0.072062</td>\n",
       "      <td>0.168884</td>\n",
       "      <td>0.422395</td>\n",
       "      <td>0.796378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855.0</th>\n",
       "      <th>SANTABARBRA - SANMAR - SANLUOB</th>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862.0</th>\n",
       "      <th>SACRAMNTO - STKTN - MODESTO</th>\n",
       "      <td>0.146648</td>\n",
       "      <td>0.076816</td>\n",
       "      <td>0.148045</td>\n",
       "      <td>0.427374</td>\n",
       "      <td>0.798883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866.0</th>\n",
       "      <th>FRESNO - VISALIA</th>\n",
       "      <td>0.143791</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.849673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868.0</th>\n",
       "      <th>CHICO - REDDING</th>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881.0</th>\n",
       "      <th>SPOKANE</th>\n",
       "      <td>0.164498</td>\n",
       "      <td>0.069703</td>\n",
       "      <td>0.104089</td>\n",
       "      <td>0.474907</td>\n",
       "      <td>0.813197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "SemifinalWinner_East_West                             29       311       457  \\\n",
       "CustomerDMACode CustomerDMADescription                                         \n",
       "500.0           PORTLAND - AUBURN               0.113281  0.078125  0.167969   \n",
       "501.0           NEW YORK                        0.118680  0.068124  0.148351   \n",
       "502.0           BINGHAMTON                      0.212963  0.055556  0.138889   \n",
       "503.0           MACON                           0.063492  0.047619  0.222222   \n",
       "504.0           PHILADELPHIA                    0.133038  0.072062  0.168884   \n",
       "...                                                  ...       ...       ...   \n",
       "855.0           SANTABARBRA - SANMAR - SANLUOB  0.129032  0.075269  0.096774   \n",
       "862.0           SACRAMNTO - STKTN - MODESTO     0.146648  0.076816  0.148045   \n",
       "866.0           FRESNO - VISALIA                0.143791  0.111111  0.163399   \n",
       "868.0           CHICO - REDDING                 0.162162  0.081081  0.243243   \n",
       "881.0           SPOKANE                         0.164498  0.069703  0.104089   \n",
       "\n",
       "SemifinalWinner_East_West                            164       sum  \n",
       "CustomerDMACode CustomerDMADescription                              \n",
       "500.0           PORTLAND - AUBURN               0.500000  0.859375  \n",
       "501.0           NEW YORK                        0.484287  0.819442  \n",
       "502.0           BINGHAMTON                      0.388889  0.796296  \n",
       "503.0           MACON                           0.412698  0.746032  \n",
       "504.0           PHILADELPHIA                    0.422395  0.796378  \n",
       "...                                                  ...       ...  \n",
       "855.0           SANTABARBRA - SANMAR - SANLUOB  0.537634  0.838710  \n",
       "862.0           SACRAMNTO - STKTN - MODESTO     0.427374  0.798883  \n",
       "866.0           FRESNO - VISALIA                0.431373  0.849673  \n",
       "868.0           CHICO - REDDING                 0.324324  0.810811  \n",
       "881.0           SPOKANE                         0.474907  0.813197  \n",
       "\n",
       "[209 rows x 5 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dma_distribution_east_west = classic1_df_train.groupby(by =['CustomerDMACode', 'CustomerDMADescription'])['SemifinalWinner_East_West'] \\\n",
    "                                             .value_counts() \\\n",
    "                                             .unstack(fill_value=0)\n",
    "\n",
    "dma_distribution_east_west_prop = dma_distribution_east_west.div(dma_distribution_east_west.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "dma_ew = dma_distribution_east_west_prop.loc[:, [29,311,457,164]]\n",
    "dma_ew['sum'] = dma_ew[29] + dma_ew[311] + dma_ew[457] + dma_ew[164]\n",
    "\n",
    "dma_ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7965361293158172)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dma_ew['sum'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "ax_1 = ax_1 = sns.countplot(x=model_1_df['NationalChampion'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['CustomerPostalLongitude', 'CustomerPostalLatitude'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Reset index\u001b[39;00m\n\u001b[1;32m     16\u001b[0m df_pivot \u001b[38;5;241m=\u001b[39m df_pivot\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     18\u001b[0m df_midwest_knn \u001b[38;5;241m=\u001b[39m df_pivot\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mclassic1_df_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomerDMACode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomerPostalLongitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomerPostalLatitude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, \n\u001b[1;32m     20\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     21\u001b[0m     on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomerDMACode\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m df_midwest_knn\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# dma_count_midwest\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['CustomerPostalLongitude', 'CustomerPostalLatitude'] not in index\""
     ]
    }
   ],
   "source": [
    "#K-nearest neighbors\n",
    "\n",
    "dma_count_midwest = classic1_df_train.groupby(by= ['CustomerDMACode', 'RegionWinner_Midwest']).size().reset_index(name='count')\n",
    "\n",
    "# dma_count_midwest.loc[dma_count_midwest['CustomerDMACode'] == 500.0, :]\n",
    "dma_count_midwest['Total_Picks'] = dma_count_midwest.groupby('CustomerDMACode')['count'].transform('sum')\n",
    "dma_count_midwest['pick_prob'] = dma_count_midwest['count'] / dma_count_midwest['Total_Picks']\n",
    "\n",
    "# Pivot table to transform region winners into separate columns\n",
    "df_pivot = dma_count_midwest.pivot(index='CustomerDMACode', columns='RegionWinner_Midwest', values='pick_prob')\n",
    "\n",
    "# Fill NaNs with 0 (since a DMA might not have chosen every team)\n",
    "df_pivot = df_pivot.fillna(0)\n",
    "\n",
    "# Reset index\n",
    "df_pivot = df_pivot.reset_index()\n",
    "\n",
    "df_midwest_knn = df_pivot.merge(\n",
    "    classic1_df_train[['CustomerDMACode', 'CustomerPostalLongitude', 'CustomerPostalLatitude']], \n",
    "    how='left', \n",
    "    on='CustomerDMACode'\n",
    ")\n",
    "\n",
    "df_midwest_knn\n",
    "\n",
    "\n",
    "# dma_count_midwest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install seaborn\n",
    "# %pip install scikit-learn\n",
    "# %pip install tensorflow\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, make_scorer, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------------------\n",
    "# 0. Load Data and Preprocessing (Existing Code)\n",
    "# -------------------------------\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "bracket_training = pd.read_csv(f\"{path}/bracket_training.csv\", sep=\",\")\n",
    "bracket_test = pd.read_csv(f'{path}/bracket_test.csv')\n",
    "college_info = pd.read_csv(f'{path}/institutions.csv', sep=',', encoding='utf-8')\n",
    "df_kenpom = pd.read_csv('Kenpom Data.csv')\n",
    "distances_ew_df = pd.read_csv(f'{path}/SemifinalWinner_East_West.csv', sep='|')\n",
    "\n",
    "# --- Step 1: Process KenPom Data\n",
    "df_kenpom['Team_Name'] = df_kenpom['Team'].apply(lambda x: ' '.join(x.split()[:-1]))\n",
    "mapping = {\n",
    "    \"Connecticut\": \"UConn\", \"Houston\": \"Houston\", \"Purdue\": \"Purdue\", \"Auburn\": \"Auburn\",\n",
    "    \"Tennessee\": \"Tennessee\", \"Arizona\": \"Arizona\", \"Duke\": \"Duke\", \"Iowa St.\": \"Iowa St.\",\n",
    "    \"North Carolina\": \"North Carolina\", \"Illinois\": \"Illinois\", \"Creighton\": \"Creighton\",\n",
    "    \"Gonzaga\": \"Gonzaga\", \"Marquette\": \"Marquette\", \"Alabama\": \"Alabama\", \"Baylor\": \"Baylor\",\n",
    "    \"Michigan St.\": \"Michigan St.\", \"Wisconsin\": \"Wisconsin\", \"BYU\": \"BYU\", \"Clemson\": \"Clemson\",\n",
    "    \"Saint Mary's\": \"Saint Mary's\", \"San Diego St.\": \"San Diego St.\", \"Kentucky\": \"Kentucky\",\n",
    "    \"Colorado\": \"Colorado\", \"Texas\": \"Texas\", \"Florida\": \"Florida\", \"Kansas\": \"Kansas\",\n",
    "    \"New Mexico\": \"New Mexico\", \"Nebraska\": \"Nebraska\", \"Texas Tech\": \"Texas Tech\",\n",
    "    \"Dayton\": \"Dayton\", \"Mississippi St.\": \"Mississippi St.\", \"Texas A&M\": \"Texas A&M\",\n",
    "    \"Colorado St.\": \"Colorado St.\", \"Nevada\": \"Nevada\", \"Northwestern\": \"Northwestern\",\n",
    "    \"Washington St.\": \"Washington St.\", \"TCU\": \"TCU\", \"Boise St.\": \"Boise St.\",\n",
    "    \"N.C. State\": \"NC State\", \"Florida Atlantic\": \"FAU\", \"Utah St.\": \"Utah St.\",\n",
    "    \"Grand Canyon\": \"Grand Canyon\", \"Drake\": \"Drake\", \"South Carolina\": \"South Carolina\",\n",
    "    \"Oregon\": \"Oregon\", \"James Madison\": \"James Madison\", \"McNeese St.\": \"McNeese\",\n",
    "    \"Virginia\": \"Virginia\", \"Samford\": \"Samford\", \"Duquesne\": \"Duquesne\", \"Yale\": \"Yale\",\n",
    "    \"Charleston\": \"Charleston\", \"Vermont\": \"Vermont\", \"UAB\": \"UAB\", \"Morehead St.\": \"Morehead St.\",\n",
    "    \"Akron\": \"Akron\", \"Oakland\": \"Oakland\", \"Western Kentucky\": \"Western Ky.\",\n",
    "    \"South Dakota St.\": \"South Dakota St.\", \"Colgate\": \"Colgate\", \"Longwood\": \"Longwood\",\n",
    "    \"Long Beach St.\": \"Long Beach St.\", \"Saint Peter's\": \"Saint Peter's\", \"Stetson\": \"Stetson\",\n",
    "    \"Montana St.\": \"Montana St.\", \"Grambling St.\": \"Grambling St.\", \"Howard\": \"Howard\", \"Wagner\": \"Wagner\"\n",
    "}\n",
    "df_kenpom['Team_Name'] = df_kenpom['Team_Name'].map(mapping)\n",
    "df_kenpom['Seed_Rank'] = df_kenpom['Team'].str.extract(r'(\\d+)$')\n",
    "df_kenpom = df_kenpom.dropna(subset=['Seed_Rank'])\n",
    "df_kenpom['Seed_Rank'] = df_kenpom['Seed_Rank'].astype(int)\n",
    "df_ken_clean = df_kenpom.loc[:, ['Rk', 'Team_Name', 'Seed_Rank', 'NetRtg', 'Luck']]\n",
    "df_ken_clean = df_ken_clean.set_index('Team_Name')\n",
    "\n",
    "# --- Step 2: Merge with college_info and Join to Bracket Data\n",
    "college_info_ken_df = college_info.join(df_ken_clean, how='left', on='InstitutionName')\n",
    "college_info_ken_df['win_%'] = college_info_ken_df['RegularSeasonWins'] / (college_info_ken_df['RegularSeasonWins'] + college_info_ken_df['RegularSeasonLosses'])\n",
    "college_info_ken_df = college_info_ken_df.set_index('InstitutionID')\n",
    "\n",
    "train_df = bracket_training.join(\n",
    "    college_info_ken_df.add_prefix(\"W_\"), on=\"RegionWinner_West\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix(\"E_\"), on=\"RegionWinner_East\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix('M_'), on=\"RegionWinner_Midwest\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix('S_'), on='RegionWinner_South'\n",
    ")\n",
    "\n",
    "test_df = bracket_test.join(\n",
    "    college_info_ken_df.add_prefix(\"W_\"), on=\"RegionWinner_West\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix(\"E_\"), on=\"RegionWinner_East\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix('M_'), on=\"RegionWinner_Midwest\"\n",
    ").join(\n",
    "    college_info_ken_df.add_prefix('S_'), on='RegionWinner_South'\n",
    ")\n",
    "\n",
    "classic1_df_train = train_df[[\n",
    "    'CustomerID',\n",
    "    'CustomerPostalCodeLatitude', 'CustomerPostalCodeLongitude', 'CustomerDMACode', 'CustomerDMADescription',\n",
    "    'NCAACustomerRecordCreated', 'BracketEntryId', 'BracketEntryCreatedDate',\n",
    "    'RegionWinner_East', 'RegionWinner_West', 'RegionWinner_South', 'RegionWinner_Midwest',\n",
    "    'SemifinalWinner_East_West', 'SemifinalWinner_South_Midwest', 'NationalChampion',\n",
    "    'E_InstitutionName', 'E_InstitutionDMACode', 'E_InstitutionLatitude', 'E_InstitutionLongitude',\n",
    "    'E_InstitutionConference', 'E_InstitutionEnrollment_Male', 'E_InstitutionEnrollment_Female',\n",
    "    'E_InstitutionEnrollment_Total', 'E_InstitutionNCAAMemberSinceDate', 'E_RegularSeasonWins',\n",
    "    'E_RegularSeasonLosses', 'E_RegularSeasonAverageAttendance', 'E_RegularSeasonAverageScore',\n",
    "    'E_Rk', 'E_Seed_Rank', 'E_NetRtg', 'E_Luck',\n",
    "    'M_InstitutionName', 'M_InstitutionDMACode', 'M_InstitutionLatitude', 'M_InstitutionLongitude',\n",
    "    'M_InstitutionConference', 'M_InstitutionEnrollment_Male', 'M_InstitutionEnrollment_Female',\n",
    "    'M_InstitutionEnrollment_Total', 'M_InstitutionNCAAMemberSinceDate', 'M_RegularSeasonWins',\n",
    "    'M_RegularSeasonLosses', 'M_RegularSeasonAverageAttendance', 'M_RegularSeasonAverageScore',\n",
    "    'M_Rk', 'M_Seed_Rank', 'M_NetRtg', 'M_Luck',\n",
    "    'S_InstitutionName', 'S_InstitutionDMACode', 'S_InstitutionLatitude', 'S_InstitutionLongitude',\n",
    "    'S_InstitutionConference', 'S_InstitutionEnrollment_Male', 'S_InstitutionEnrollment_Female',\n",
    "    'S_InstitutionEnrollment_Total', 'S_InstitutionNCAAMemberSinceDate', 'S_RegularSeasonWins',\n",
    "    'S_RegularSeasonLosses', 'S_RegularSeasonAverageAttendance', 'S_RegularSeasonAverageScore',\n",
    "    'S_Rk', 'S_Seed_Rank', 'S_NetRtg', 'S_Luck',\n",
    "    'W_InstitutionName', 'W_InstitutionDMACode', 'W_InstitutionLatitude', 'W_InstitutionLongitude',\n",
    "    'W_InstitutionConference', 'W_InstitutionEnrollment_Male', 'W_InstitutionEnrollment_Female',\n",
    "    'W_InstitutionEnrollment_Total', 'W_InstitutionNCAAMemberSinceDate', 'W_RegularSeasonWins',\n",
    "    'W_RegularSeasonLosses', 'W_RegularSeasonAverageAttendance', 'W_RegularSeasonAverageScore',\n",
    "    'W_Rk', 'W_Seed_Rank', 'W_NetRtg', 'W_Luck'\n",
    "]]\n",
    "classic1_df_test = test_df[[\n",
    "    'CustomerID',\n",
    "    'CustomerPostalCodeLatitude', 'CustomerPostalCodeLongitude', 'CustomerDMACode', 'CustomerDMADescription',\n",
    "    'NCAACustomerRecordCreated', 'BracketEntryId', 'BracketEntryCreatedDate',\n",
    "    'RegionWinner_East', 'RegionWinner_West', 'RegionWinner_South', 'RegionWinner_Midwest',\n",
    "    'E_InstitutionName', 'E_InstitutionDMACode', 'E_InstitutionLatitude', 'E_InstitutionLongitude',\n",
    "    'E_InstitutionConference', 'E_InstitutionEnrollment_Male', 'E_InstitutionEnrollment_Female',\n",
    "    'E_InstitutionEnrollment_Total', 'E_InstitutionNCAAMemberSinceDate', 'E_RegularSeasonWins',\n",
    "    'E_RegularSeasonLosses', 'E_RegularSeasonAverageAttendance', 'E_RegularSeasonAverageScore',\n",
    "    'E_Rk', 'E_Seed_Rank', 'E_NetRtg', 'E_Luck',\n",
    "    'M_InstitutionName', 'M_InstitutionDMACode', 'M_InstitutionLatitude', 'M_InstitutionLongitude',\n",
    "    'M_InstitutionConference', 'M_InstitutionEnrollment_Male', 'M_InstitutionEnrollment_Female',\n",
    "    'M_InstitutionEnrollment_Total', 'M_InstitutionNCAAMemberSinceDate', 'M_RegularSeasonWins',\n",
    "    'M_RegularSeasonLosses', 'M_RegularSeasonAverageAttendance', 'M_RegularSeasonAverageScore',\n",
    "    'M_Rk', 'M_Seed_Rank', 'M_NetRtg', 'M_Luck',\n",
    "    'S_InstitutionName', 'S_InstitutionDMACode', 'S_InstitutionLatitude', 'S_InstitutionLongitude',\n",
    "    'S_InstitutionConference', 'S_InstitutionEnrollment_Male', 'S_InstitutionEnrollment_Female',\n",
    "    'S_InstitutionEnrollment_Total', 'S_InstitutionNCAAMemberSinceDate', 'S_RegularSeasonWins',\n",
    "    'S_RegularSeasonLosses', 'S_RegularSeasonAverageAttendance', 'S_RegularSeasonAverageScore',\n",
    "    'S_Rk', 'S_Seed_Rank', 'S_NetRtg', 'S_Luck',\n",
    "    'W_InstitutionName', 'W_InstitutionDMACode', 'W_InstitutionLatitude', 'W_InstitutionLongitude',\n",
    "    'W_InstitutionConference', 'W_InstitutionEnrollment_Male', 'W_InstitutionEnrollment_Female',\n",
    "    'W_InstitutionEnrollment_Total', 'W_InstitutionNCAAMemberSinceDate', 'W_RegularSeasonWins',\n",
    "    'W_RegularSeasonLosses', 'W_RegularSeasonAverageAttendance', 'W_RegularSeasonAverageScore',\n",
    "    'W_Rk', 'W_Seed_Rank', 'W_NetRtg', 'W_Luck'\n",
    "]]\n",
    "# Create separate imputers:\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='Unknown')\n",
    "\n",
    "# List the columns to impute:\n",
    "num_cols = ['CustomerPostalCodeLatitude', 'CustomerPostalCodeLongitude']\n",
    "cat_cols = ['CustomerDMACode', 'CustomerDMADescription']\n",
    "\n",
    "# Impute in the training set:\n",
    "classic1_df_train[num_cols] = num_imputer.fit_transform(classic1_df_train[num_cols])\n",
    "classic1_df_train[cat_cols] = cat_imputer.fit_transform(classic1_df_train[cat_cols])\n",
    "\n",
    "# And in the test set:\n",
    "classic1_df_test[num_cols] = num_imputer.transform(classic1_df_test[num_cols])\n",
    "classic1_df_test[cat_cols] = cat_imputer.transform(classic1_df_test[cat_cols])\n",
    "\n",
    "# Create win percentages\n",
    "classic1_df_train['m_win_%'] = classic1_df_train['M_RegularSeasonWins'] / (classic1_df_train['M_RegularSeasonWins'] + classic1_df_train['M_RegularSeasonLosses'])\n",
    "classic1_df_train['s_win_%'] = classic1_df_train['S_RegularSeasonWins'] / (classic1_df_train['S_RegularSeasonWins'] + classic1_df_train['S_RegularSeasonLosses'])\n",
    "classic1_df_train['e_win_%'] = classic1_df_train['E_RegularSeasonWins'] / (classic1_df_train['E_RegularSeasonWins'] + classic1_df_train['E_RegularSeasonLosses'])\n",
    "classic1_df_train['w_win_%'] = classic1_df_train['W_RegularSeasonWins'] / (classic1_df_train['W_RegularSeasonWins'] + classic1_df_train['W_RegularSeasonLosses'])\n",
    "\n",
    "classic1_df_test['m_win_%'] = classic1_df_test['M_RegularSeasonWins'] / (classic1_df_test['M_RegularSeasonWins'] + classic1_df_test['M_RegularSeasonLosses'])\n",
    "classic1_df_test['s_win_%'] = classic1_df_test['S_RegularSeasonWins'] / (classic1_df_test['S_RegularSeasonWins'] + classic1_df_test['S_RegularSeasonLosses'])\n",
    "classic1_df_test['e_win_%'] = classic1_df_test['E_RegularSeasonWins'] / (classic1_df_test['E_RegularSeasonWins'] + classic1_df_test['E_RegularSeasonLosses'])\n",
    "classic1_df_test['w_win_%'] = classic1_df_test['W_RegularSeasonWins'] / (classic1_df_test['W_RegularSeasonWins'] + classic1_df_test['W_RegularSeasonLosses'])\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Define Helper Functions for Modeling and Feature Engineering\n",
    "# -------------------------------\n",
    "# Custom sigmoid transformer (for ordinal features if needed)\n",
    "def sigmoid_transform(X):\n",
    "    try:\n",
    "        return  1 - (1 / (1 + np.exp(-X)))\n",
    "    except ZeroDivisionError:\n",
    "        print('Bad Process!')\n",
    "        \n",
    "sigmoid_transformer = FunctionTransformer(sigmoid_transform, validate=False)\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Earth's radius in km\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    delta_lat = lat2 - lat1\n",
    "    delta_lon = lon2 - lon1\n",
    "    a = np.sin(delta_lat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(delta_lon / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "def multioutput_accuracy(y_true, y_pred):\n",
    "    # y_true and y_pred should be numpy arrays of shape (n_samples, n_outputs)\n",
    "    accuracies = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        accuracies.append(accuracy_score(y_true[:, i], y_pred[:, i]))\n",
    "    return np.mean(accuracies)\n",
    "\n",
    "custom_scorer = make_scorer(multioutput_accuracy)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Incorporate New Geographic & Popularity Features\n",
    "# -------------------------------\n",
    "\n",
    "epsilon = 1e-5\n",
    "df_train = classic1_df_train\n",
    "df_test = classic1_df_test\n",
    "\n",
    "#Apply haversine distance for each region winner column\n",
    "for region, lat_data, lon_data in zip(\n",
    "    ['E_','W_','M_', 'S_'],\n",
    "    ['E_InstitutionLatitude', 'W_InstitutionLatitude', 'M_InstitutionLatitude', 'S_InstitutionLatitude'],\n",
    "    ['E_InstitutionLongitude', 'W_InstitutionLongitude', 'M_InstitutionLongitude', 'S_InstitutionLongitude']\n",
    "):\n",
    "    df_train[f'{region}distance'] =  df_train.apply(\n",
    "        lambda row: haversine_distance(row['CustomerPostalCodeLatitude'],\n",
    "                                       row['CustomerPostalCodeLongitude'],\n",
    "                                       row[lat_data],\n",
    "                                       row[lon_data])\n",
    "    , axis = 1)\n",
    "    df_test[f'{region}distance'] =  df_test.apply(\n",
    "        lambda row: haversine_distance(row['CustomerPostalCodeLatitude'],\n",
    "                                       row['CustomerPostalCodeLongitude'],\n",
    "                                       row[lat_data],\n",
    "                                       row[lon_data])\n",
    "    , axis = 1)\n",
    "\n",
    "for region in ['E_', 'W_', 'M_', 'S_']:\n",
    "    df_train[f'{region}dist_score'] = 1 / (df_train[f'{region}distance'] + epsilon)\n",
    "    df_train = df_train.drop(columns=[f'{region}distance'])\n",
    "\n",
    "    df_test[f'{region}dist_score'] = 1 / (df_test[f'{region}distance'] + epsilon)\n",
    "    df_test = df_test.drop(columns=[f'{region}distance'])\n",
    "\n",
    "# Sum of East & West distance scores\n",
    "df_train['total_dist_score_EW'] = df_train[['E_dist_score', 'W_dist_score']].sum(axis=1)\n",
    "\n",
    "# Sum of Midwest & South distance scores\n",
    "df_train['total_dist_score_MS'] = df_train[['M_dist_score', 'S_dist_score']].sum(axis=1)\n",
    "\n",
    "# Normalize East & West probabilities\n",
    "df_train['E_dist_prob'] = df_train['E_dist_score'] / df_train['total_dist_score_EW']\n",
    "df_train['W_dist_prob'] = df_train['W_dist_score'] / df_train['total_dist_score_EW']\n",
    "\n",
    "# Normalize Midwest & South probabilities\n",
    "df_train['M_dist_prob'] = df_train['M_dist_score'] / df_train['total_dist_score_MS']\n",
    "df_train['S_dist_prob'] = df_train['S_dist_score'] / df_train['total_dist_score_MS']\n",
    "\n",
    "df_train = df_train.drop(columns=[\n",
    "    'E_dist_score', 'W_dist_score', 'M_dist_score', 'S_dist_score',\n",
    "    'total_dist_score_EW', 'total_dist_score_MS'\n",
    "])\n",
    "\n",
    "\n",
    "# Sum of East & West distance scores\n",
    "df_test['total_dist_score_EW'] = df_test[['E_dist_score', 'W_dist_score']].sum(axis=1)\n",
    "\n",
    "# Sum of Midwest & South distance scores\n",
    "df_test['total_dist_score_MS'] = df_test[['M_dist_score', 'S_dist_score']].sum(axis=1)\n",
    "\n",
    "# Normalize East & West probabilities\n",
    "df_test['E_dist_prob'] = df_test['E_dist_score'] / df_test['total_dist_score_EW']\n",
    "df_test['W_dist_prob'] = df_test['W_dist_score'] / df_test['total_dist_score_EW']\n",
    "\n",
    "# Normalize Midwest & South probabilities\n",
    "df_test['M_dist_prob'] = df_test['M_dist_score'] / df_test['total_dist_score_MS']\n",
    "df_test['S_dist_prob'] = df_test['S_dist_score'] / df_test['total_dist_score_MS']\n",
    "\n",
    "\n",
    "df_test = df_test.drop(columns=[\n",
    "    'E_dist_score', 'W_dist_score', 'M_dist_score', 'S_dist_score',\n",
    "    'total_dist_score_EW', 'total_dist_score_MS'\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Define Feature Columns and Multi-Output Targets for Joint Modeling\n",
    "# -------------------------------\n",
    "\n",
    "# Drop withheld features\n",
    "features_to_withHold = ['CustomerID',\n",
    "                         'CustomerPostalCodeLatitude', \n",
    "                         'CustomerPostalCodeLongitude',\n",
    "                         'CustomerDMACode',\n",
    "                         'CustomerDMADescription',\n",
    "                        'NCAACustomerRecordCreated',\n",
    "                        'BracketEntryId',\n",
    "                        'BracketEntryCreatedDate',\n",
    "    'E_InstitutionName', 'E_InstitutionDMACode', 'E_InstitutionLatitude', 'E_InstitutionLongitude','E_RegularSeasonWins', 'E_RegularSeasonLosses',\n",
    "    'E_InstitutionNCAAMemberSinceDate', 'E_InstitutionEnrollment_Female','E_InstitutionEnrollment_Male','E_RegularSeasonAverageAttendance', \"E_RegularSeasonAverageScore\",\n",
    "    'E_InstitutionConference',\n",
    "\n",
    "    'W_InstitutionName', 'W_InstitutionDMACode', 'W_InstitutionLatitude', 'W_InstitutionLongitude','W_RegularSeasonWins', 'W_RegularSeasonLosses',\n",
    "    'W_InstitutionEnrollment_Male', 'W_InstitutionEnrollment_Female', 'W_InstitutionNCAAMemberSinceDate', 'W_InstitutionEnrollment_Male',\n",
    "    'W_RegularSeasonAverageAttendance', \"W_RegularSeasonAverageScore\", 'W_InstitutionConference',\n",
    "\n",
    "    'M_InstitutionName',\n",
    " 'M_InstitutionDMACode',\n",
    " 'M_InstitutionLatitude',\n",
    " 'M_InstitutionLongitude',\n",
    " 'M_RegularSeasonWins', 'M_RegularSeasonLosses',\n",
    " 'M_InstitutionNCAAMemberSinceDate',\n",
    " 'M_InstitutionEnrollment_Female', 'M_InstitutionEnrollment_Male',\n",
    " 'M_RegularSeasonAverageAttendance', \"M_RegularSeasonAverageScore\",\n",
    " 'M_InstitutionConference',\n",
    "\n",
    "\n",
    " 'S_InstitutionName',\n",
    " 'S_InstitutionDMACode',\n",
    " 'S_InstitutionLatitude',\n",
    " 'S_InstitutionLongitude',\n",
    " 'S_RegularSeasonWins', 'S_RegularSeasonLosses',\n",
    " 'S_InstitutionEnrollment_Male',\n",
    " 'S_InstitutionEnrollment_Female', 'S_InstitutionEnrollment_Male',\n",
    " 'S_RegularSeasonAverageAttendance', \"S_RegularSeasonAverageScore\",\n",
    " 'S_InstitutionNCAAMemberSinceDate',\n",
    " 'S_InstitutionConference'\n",
    "]\n",
    "\n",
    "df_train = df_train.drop(columns=features_to_withHold)\n",
    "df_test = df_test.drop(columns=features_to_withHold)\n",
    "\n",
    "\n",
    "# Create lists of features based on column name prefixes.\n",
    "features_east = [col for col in df_train.columns if col.startswith('E_') | col.startswith('e_')]\n",
    "features_west = [col for col in df_train.columns if col.startswith('W_') | col.startswith('w_')]\n",
    "features_midwest = [col for col in df_train.columns if col.startswith('M_') | col.startswith('m_')]\n",
    "features_south = [col for col in df_train.columns if col.startswith('S_') | col.startswith('s_')]\n",
    "\n",
    "\n",
    "# Define target column names.\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "target_EW = \"SemifinalWinner_East_West\"    # outcome for East-West semifinal\n",
    "target_MS = \"SemifinalWinner_South_Midwest\"  # outcome for South-Midwest semifinal\n",
    "target_NC = \"NationalChampion\"             # outcome for National Champion\n",
    "\n",
    "df_train['target_EW_Binary'] = (df_train[target_EW] == df_train['RegionWinner_East']).astype(int)\n",
    "# df_test['target_EW_Binary'] = (df_test[target_EW] == df_test['RegionWinner_East']).astype(int)\n",
    "\n",
    "df_train['target_MS_Binary'] = (df_train[target_MS] == df_train['RegionWinner_Midwest']).astype(int)\n",
    "# df_test['target_MS_Binary'] = (df_test[target_MS] == df_test['RegionWinner_Midwest']).astype(int)\n",
    "\n",
    "\n",
    "# Remove target columns from the feature lists if present.\n",
    "for target in [target_EW, target_MS, target_NC, 'target_EW_Binary', 'target_MS_Binary']:\n",
    "    if target in features_east: features_east.remove(target)\n",
    "    if target in features_west: features_west.remove(target)\n",
    "    if target in features_midwest: features_midwest.remove(target)\n",
    "    if target in features_south: features_south.remove(target)\n",
    "\n",
    "# Combine feature lists.\n",
    "features_ew = features_east + features_west\n",
    "features_ms = features_south + features_midwest\n",
    "\n",
    "# # # -------------------------------\n",
    "# # # 6. Build a Shared Preprocessing Pipeline\n",
    "# # # -------------------------------\n",
    "\n",
    "ordinal_features_ew = [col for col in features_ew if col.endswith(\"_Rk\") |  col.endswith('_Seed_Rank')]\n",
    "numerical_features_ew = [col for col in features_ew if col not in ordinal_features_ew \n",
    "                      and col not in ['E_dist_prob', 'W_dist_prob']\n",
    "                      and col not in ['RegionWinner_East','RegionWinner_South', 'RegionWinner_Midwest', 'RegionWinner_West']\n",
    "                      and col not in ['target_EW_Binary', 'target_MS_Binary']]\n",
    "\n",
    "\n",
    "ordinal_features_ms = [col for col in features_ms if col.endswith(\"_Rk\") |  col.endswith('_Seed_Rank')]\n",
    "numerical_features_ms = [col for col in features_ms if col not in ordinal_features_ms \n",
    "                      and col not in [ 'S_dist_prob', 'M_dist_prob']\n",
    "                      and col not in ['RegionWinner_East','RegionWinner_South', 'RegionWinner_Midwest', 'RegionWinner_West']\n",
    "                      and col not in ['target_EW_Binary', 'target_MS_Binary']]\n",
    "\n",
    "\n",
    "\n",
    "y_ew = df_train['target_EW_Binary']\n",
    "y_ms = df_train['target_MS_Binary']\n",
    "\n",
    "y_ms\n",
    "\n",
    "df_train = df_train.drop(columns= ['target_EW_Binary','target_MS_Binary' ])\n",
    "\n",
    "\n",
    "X_train_ew, X_test_ew, y_train_ew, y_test_ew = train_test_split(df_train[features_ew], y_ew, test_size=.2, random_state=24)\n",
    "X_train_ms, X_test_ms, y_train_ms, y_test_ms = train_test_split(df_train[features_ms], y_ms,  test_size=.2, random_state=24)\n",
    "\n",
    "preprocessor_log_ew = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features_ew),\n",
    "        ('ord', sigmoid_transformer, ordinal_features_ew)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "preprocessor_log_ms = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features_ms),\n",
    "        ('ord', sigmoid_transformer, ordinal_features_ms)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df_train[features_ew]\n",
    "processed_data = pd.DataFrame(preprocessor_log_ew.fit_transform(df_train[features_ew]))\n",
    "processed_data\n",
    "# -------------------------------\n",
    "# 7. Build the Joint Multi-Task Model\n",
    "# -------------------------------\n",
    "model_log_reg_ew = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_log_ew),\n",
    "    ('selector', RFE(LogisticRegressionCV(cv=5, max_iter=2000), n_features_to_select=10)),\n",
    "    ('classifier', LogisticRegressionCV(cv=5, max_iter=2000))\n",
    "])\n",
    "\n",
    "model_log_reg_ms = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_log_ms),\n",
    "    ('selector', RFE(LogisticRegressionCV(cv=5, max_iter=2000), n_features_to_select=10)),\n",
    "    ('classifier', LogisticRegressionCV(cv=5, max_iter=2000))\n",
    "])\n",
    "\n",
    "# # -------------------------------\n",
    "# # 8. Predict on New (Test) Data and Save Predictions\n",
    "# # -------------------------------\n",
    "\n",
    "# y_pred_multi = grid_search.predict(df_test[features])\n",
    "# predictions = pd.DataFrame(y_pred_multi, columns=[target_EW, target_MS, target_NC])\n",
    "\n",
    "# predictions[target_EW] = np.where(\n",
    "#     predictions[target_EW] == 1,\n",
    "#     df_test['RegionWinner_East'].values,\n",
    "#     df_test['RegionWinner_West'].values\n",
    "# )\n",
    "# # For SemifinalWinner_South_Midwest: if binary 1 → RegionWinner_Midwest; 0 → RegionWinner_South.\n",
    "# predictions[target_MS] = np.where(\n",
    "#     predictions[target_MS] == 1,\n",
    "#     df_test['RegionWinner_Midwest'].values,\n",
    "#     df_test['RegionWinner_South'].values\n",
    "# )\n",
    "# # Assume NationalChampion is already in the desired institution ID format.\n",
    "\n",
    "# # -------------------------------\n",
    "# # 9. Merge with BracketEntryID and Save CSV\n",
    "# # -------------------------------\n",
    "# # We assume the test DataFrame contains 'BracketEntryId'\n",
    "# predictions['BracketEntryId'] = df_test['BracketEntryId'].values\n",
    "\n",
    "# # Reorder columns as needed:\n",
    "# final_cols = ['BracketEntryId', target_MS, target_EW, target_NC]\n",
    "# final_predictions = predictions[final_cols]\n",
    "\n",
    "# final_predictions.to_csv(\"predictions_joint_final.csv\", index=False)\n",
    "# print(\"Final predictions saved to predictions_joint_final.csv ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for EW Model: 0.6748971193415638\n"
     ]
    }
   ],
   "source": [
    "model_log_reg_ew.fit(X_train_ew, y_train_ew)\n",
    "y_pred_ew = model_log_reg_ew.predict(X_test_ew)\n",
    "print( f'Accuracy for EW Model: {accuracy_score(y_true=y_test_ew, y_pred=y_pred_ew)}')\n",
    "model_log_reg_ms.fit(X_train_ms, y_train_ms)\n",
    "y_pred_ms = model_log_reg_ms.predict(X_test_ms)\n",
    "print( f'Accuracy for MS Model: {accuracy_score(y_true=y_test_ms, y_pred=y_pred_ms)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for MS Model: 0.6282835275566324\n"
     ]
    }
   ],
   "source": [
    "model_log_reg_ms.fit(X_train_ms, y_train_ms)\n",
    "y_pred_ms = model_log_reg_ms.predict(X_test_ms)\n",
    "print( f'Accuracy for MS Model: {accuracy_score(y_true=y_test_ms, y_pred=y_pred_ms)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionWinner_East</th>\n",
       "      <th>RegionWinner_West</th>\n",
       "      <th>RegionWinner_South</th>\n",
       "      <th>RegionWinner_Midwest</th>\n",
       "      <th>SemifinalWinner_East_West</th>\n",
       "      <th>SemifinalWinner_South_Midwest</th>\n",
       "      <th>NationalChampion</th>\n",
       "      <th>E_InstitutionEnrollment_Total</th>\n",
       "      <th>E_Rk</th>\n",
       "      <th>E_Seed_Rank</th>\n",
       "      <th>E_NetRtg</th>\n",
       "      <th>E_Luck</th>\n",
       "      <th>M_InstitutionEnrollment_Total</th>\n",
       "      <th>M_Rk</th>\n",
       "      <th>M_Seed_Rank</th>\n",
       "      <th>M_NetRtg</th>\n",
       "      <th>M_Luck</th>\n",
       "      <th>S_InstitutionEnrollment_Total</th>\n",
       "      <th>S_Rk</th>\n",
       "      <th>S_Seed_Rank</th>\n",
       "      <th>S_NetRtg</th>\n",
       "      <th>S_Luck</th>\n",
       "      <th>W_InstitutionEnrollment_Total</th>\n",
       "      <th>W_Rk</th>\n",
       "      <th>W_Seed_Rank</th>\n",
       "      <th>W_NetRtg</th>\n",
       "      <th>W_Luck</th>\n",
       "      <th>m_win_%</th>\n",
       "      <th>s_win_%</th>\n",
       "      <th>e_win_%</th>\n",
       "      <th>w_win_%</th>\n",
       "      <th>E_dist_prob</th>\n",
       "      <th>W_dist_prob</th>\n",
       "      <th>M_dist_prob</th>\n",
       "      <th>S_dist_prob</th>\n",
       "      <th>National_Champ_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164</td>\n",
       "      <td>29</td>\n",
       "      <td>317</td>\n",
       "      <td>694</td>\n",
       "      <td>164</td>\n",
       "      <td>694</td>\n",
       "      <td>694</td>\n",
       "      <td>22479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>33805</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>26.61</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>20346</td>\n",
       "      <td>63</td>\n",
       "      <td>12</td>\n",
       "      <td>12.42</td>\n",
       "      <td>0.093</td>\n",
       "      <td>30382</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.55</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.593122</td>\n",
       "      <td>0.406878</td>\n",
       "      <td>0.684155</td>\n",
       "      <td>0.315845</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164</td>\n",
       "      <td>51</td>\n",
       "      <td>334</td>\n",
       "      <td>328</td>\n",
       "      <td>164</td>\n",
       "      <td>334</td>\n",
       "      <td>164</td>\n",
       "      <td>22479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>18704</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.058</td>\n",
       "      <td>22723</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19.29</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>14885</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>21.90</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.583512</td>\n",
       "      <td>0.416488</td>\n",
       "      <td>0.381613</td>\n",
       "      <td>0.618387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164</td>\n",
       "      <td>51</td>\n",
       "      <td>288</td>\n",
       "      <td>559</td>\n",
       "      <td>164</td>\n",
       "      <td>559</td>\n",
       "      <td>559</td>\n",
       "      <td>22479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>37949</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.048</td>\n",
       "      <td>37943</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.17</td>\n",
       "      <td>0.042</td>\n",
       "      <td>14885</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>21.90</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.790941</td>\n",
       "      <td>0.209059</td>\n",
       "      <td>0.695405</td>\n",
       "      <td>0.304595</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311</td>\n",
       "      <td>610</td>\n",
       "      <td>490</td>\n",
       "      <td>559</td>\n",
       "      <td>311</td>\n",
       "      <td>490</td>\n",
       "      <td>490</td>\n",
       "      <td>25241</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26.47</td>\n",
       "      <td>0.002</td>\n",
       "      <td>37949</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.048</td>\n",
       "      <td>23443</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>15.90</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1949</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>19.43</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.619592</td>\n",
       "      <td>0.380408</td>\n",
       "      <td>0.551714</td>\n",
       "      <td>0.448286</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>457</td>\n",
       "      <td>387</td>\n",
       "      <td>169</td>\n",
       "      <td>457</td>\n",
       "      <td>387</td>\n",
       "      <td>457</td>\n",
       "      <td>25379</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27.99</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>4290</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>24.22</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>7528</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>23.02</td>\n",
       "      <td>0.035</td>\n",
       "      <td>20242</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.376739</td>\n",
       "      <td>0.623261</td>\n",
       "      <td>0.342400</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129997</th>\n",
       "      <td>311</td>\n",
       "      <td>457</td>\n",
       "      <td>334</td>\n",
       "      <td>694</td>\n",
       "      <td>311</td>\n",
       "      <td>694</td>\n",
       "      <td>311</td>\n",
       "      <td>25241</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26.47</td>\n",
       "      <td>0.002</td>\n",
       "      <td>33805</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>26.61</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>22723</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19.29</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>20242</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.699813</td>\n",
       "      <td>0.300187</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0.515102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129998</th>\n",
       "      <td>311</td>\n",
       "      <td>8</td>\n",
       "      <td>288</td>\n",
       "      <td>694</td>\n",
       "      <td>8</td>\n",
       "      <td>288</td>\n",
       "      <td>288</td>\n",
       "      <td>25241</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26.47</td>\n",
       "      <td>0.002</td>\n",
       "      <td>33805</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>26.61</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>37943</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.17</td>\n",
       "      <td>0.042</td>\n",
       "      <td>32458</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>22.96</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.385504</td>\n",
       "      <td>0.614496</td>\n",
       "      <td>0.028028</td>\n",
       "      <td>0.971972</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129999</th>\n",
       "      <td>164</td>\n",
       "      <td>457</td>\n",
       "      <td>288</td>\n",
       "      <td>169</td>\n",
       "      <td>164</td>\n",
       "      <td>288</td>\n",
       "      <td>164</td>\n",
       "      <td>22479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>4290</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>24.22</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>37943</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31.17</td>\n",
       "      <td>0.042</td>\n",
       "      <td>20242</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>26.19</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.474127</td>\n",
       "      <td>0.525873</td>\n",
       "      <td>0.550592</td>\n",
       "      <td>0.449408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130000</th>\n",
       "      <td>164</td>\n",
       "      <td>8</td>\n",
       "      <td>334</td>\n",
       "      <td>559</td>\n",
       "      <td>164</td>\n",
       "      <td>559</td>\n",
       "      <td>559</td>\n",
       "      <td>22479</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.43</td>\n",
       "      <td>0.037</td>\n",
       "      <td>37949</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.62</td>\n",
       "      <td>0.048</td>\n",
       "      <td>22723</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19.29</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>32458</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>22.96</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.958467</td>\n",
       "      <td>0.416476</td>\n",
       "      <td>0.583524</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130001</th>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>334</td>\n",
       "      <td>328</td>\n",
       "      <td>37</td>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "      <td>25379</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>27.99</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>18704</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.058</td>\n",
       "      <td>22723</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>19.29</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>30382</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.55</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.727358</td>\n",
       "      <td>0.272642</td>\n",
       "      <td>0.349381</td>\n",
       "      <td>0.650619</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130002 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        RegionWinner_East  RegionWinner_West  RegionWinner_South  \\\n",
       "0                     164                 29                 317   \n",
       "1                     164                 51                 334   \n",
       "2                     164                 51                 288   \n",
       "3                     311                610                 490   \n",
       "4                      37                457                 387   \n",
       "...                   ...                ...                 ...   \n",
       "129997                311                457                 334   \n",
       "129998                311                  8                 288   \n",
       "129999                164                457                 288   \n",
       "130000                164                  8                 334   \n",
       "130001                 37                 29                 334   \n",
       "\n",
       "        RegionWinner_Midwest  SemifinalWinner_East_West  \\\n",
       "0                        694                        164   \n",
       "1                        328                        164   \n",
       "2                        559                        164   \n",
       "3                        559                        311   \n",
       "4                        169                        457   \n",
       "...                      ...                        ...   \n",
       "129997                   694                        311   \n",
       "129998                   694                          8   \n",
       "129999                   169                        164   \n",
       "130000                   559                        164   \n",
       "130001                   328                         37   \n",
       "\n",
       "        SemifinalWinner_South_Midwest  NationalChampion  \\\n",
       "0                                 694               694   \n",
       "1                                 334               164   \n",
       "2                                 559               559   \n",
       "3                                 490               490   \n",
       "4                                 387               457   \n",
       "...                               ...               ...   \n",
       "129997                            694               311   \n",
       "129998                            288               288   \n",
       "129999                            288               164   \n",
       "130000                            559               559   \n",
       "130001                            334               334   \n",
       "\n",
       "        E_InstitutionEnrollment_Total  E_Rk  E_Seed_Rank  E_NetRtg  E_Luck  \\\n",
       "0                               22479     1            1     36.43   0.037   \n",
       "1                               22479     1            1     36.43   0.037   \n",
       "2                               22479     1            1     36.43   0.037   \n",
       "3                               25241     8            2     26.47   0.002   \n",
       "4                               25379     4            4     27.99  -0.080   \n",
       "...                               ...   ...          ...       ...     ...   \n",
       "129997                          25241     8            2     26.47   0.002   \n",
       "129998                          25241     8            2     26.47   0.002   \n",
       "129999                          22479     1            1     36.43   0.037   \n",
       "130000                          22479     1            1     36.43   0.037   \n",
       "130001                          25379     4            4     27.99  -0.080   \n",
       "\n",
       "        M_InstitutionEnrollment_Total  M_Rk  M_Seed_Rank  M_NetRtg  M_Luck  \\\n",
       "0                               33805     5            2     26.61  -0.026   \n",
       "1                               18704    27            4     17.94   0.058   \n",
       "2                               37949     3            1     30.62   0.048   \n",
       "3                               37949     3            1     30.62   0.048   \n",
       "4                                4290    11            3     24.22  -0.018   \n",
       "...                               ...   ...          ...       ...     ...   \n",
       "129997                          33805     5            2     26.61  -0.026   \n",
       "129998                          33805     5            2     26.61  -0.026   \n",
       "129999                           4290    11            3     24.22  -0.018   \n",
       "130000                          37949     3            1     30.62   0.048   \n",
       "130001                          18704    27            4     17.94   0.058   \n",
       "\n",
       "        S_InstitutionEnrollment_Total  S_Rk  S_Seed_Rank  S_NetRtg  S_Luck  \\\n",
       "0                               20346    63           12     12.42   0.093   \n",
       "1                               22723    23            3     19.29  -0.040   \n",
       "2                               37943     2            1     31.17   0.042   \n",
       "3                               23443    45           11     15.90   0.014   \n",
       "4                                7528    13            2     23.02   0.035   \n",
       "...                               ...   ...          ...       ...     ...   \n",
       "129997                          22723    23            3     19.29  -0.040   \n",
       "129998                          37943     2            1     31.17   0.042   \n",
       "129999                          37943     2            1     31.17   0.042   \n",
       "130000                          22723    23            3     19.29  -0.040   \n",
       "130001                          22723    23            3     19.29  -0.040   \n",
       "\n",
       "        W_InstitutionEnrollment_Total  W_Rk  W_Seed_Rank  W_NetRtg  W_Luck  \\\n",
       "0                               30382     6            2     26.55  -0.047   \n",
       "1                               14885    15            3     21.90  -0.016   \n",
       "2                               14885    15            3     21.90  -0.016   \n",
       "3                                1949    20            5     19.43   0.008   \n",
       "4                               20242     9            1     26.19  -0.038   \n",
       "...                               ...   ...          ...       ...     ...   \n",
       "129997                          20242     9            1     26.19  -0.038   \n",
       "129998                          32458    14            4     22.96  -0.001   \n",
       "129999                          20242     9            1     26.19  -0.038   \n",
       "130000                          32458    14            4     22.96  -0.001   \n",
       "130001                          30382     6            2     26.55  -0.047   \n",
       "\n",
       "         m_win_%   s_win_%   e_win_%   w_win_%  E_dist_prob  W_dist_prob  \\\n",
       "0       0.750000  0.911765  0.911765  0.757576     0.593122     0.406878   \n",
       "1       0.687500  0.718750  0.911765  0.696970     0.583512     0.416488   \n",
       "2       0.878788  0.882353  0.911765  0.696970     0.790941     0.209059   \n",
       "3       0.878788  0.611111  0.794118  0.787879     0.619592     0.380408   \n",
       "4       0.718750  0.735294  0.794118  0.794118     0.376739     0.623261   \n",
       "...          ...       ...       ...       ...          ...          ...   \n",
       "129997  0.750000  0.718750  0.794118  0.794118     0.699813     0.300187   \n",
       "129998  0.750000  0.882353  0.794118  0.656250     0.385504     0.614496   \n",
       "129999  0.718750  0.882353  0.911765  0.794118     0.474127     0.525873   \n",
       "130000  0.878788  0.718750  0.911765  0.656250     0.041533     0.958467   \n",
       "130001  0.687500  0.718750  0.794118  0.757576     0.727358     0.272642   \n",
       "\n",
       "        M_dist_prob  S_dist_prob  National_Champ_Label  \n",
       "0          0.684155     0.315845                     2  \n",
       "1          0.381613     0.618387                     0  \n",
       "2          0.695405     0.304595                     2  \n",
       "3          0.551714     0.448286                     3  \n",
       "4          0.342400     0.657600                     1  \n",
       "...             ...          ...                   ...  \n",
       "129997     0.484898     0.515102                     0  \n",
       "129998     0.028028     0.971972                     3  \n",
       "129999     0.550592     0.449408                     0  \n",
       "130000     0.416476     0.583524                     2  \n",
       "130001     0.349381     0.650619                     3  \n",
       "\n",
       "[130002 rows x 36 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def final_four_encoder(row):\n",
    "    if row['NationalChampion'] == row['RegionWinner_East']:\n",
    "        return 0\n",
    "    elif row['NationalChampion'] == row['RegionWinner_West']:\n",
    "        return 1\n",
    "    elif row['NationalChampion'] == row['RegionWinner_Midwest']:\n",
    "        return 2\n",
    "    else: \n",
    "        return 3\n",
    "    \n",
    "    # row['NationalChampion'] == row['RegionWinner_South']:\n",
    "    # else:\n",
    "    #     return np.nan  # Handle unexpected cases\n",
    "\n",
    "df_train['National_Champ_Label'] = df_train.apply(final_four_encoder, axis = 1)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = to_categorical(df_train['National_Champ_Label'], 4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 38\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# preprocessor_nc = ColumnTransformer(\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     transformers=[\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#         ('num', StandardScaler(), numerical_features_ew + numerical_features_ms ),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     remainder='passthrough'\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     32\u001b[0m model_xgb \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     33\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselector\u001b[39m\u001b[38;5;124m'\u001b[39m, RFE(LogisticRegressionCV(cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m), n_features_to_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)),\n\u001b[1;32m     34\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier(objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softmax\u001b[39m\u001b[38;5;124m'\u001b[39m, num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m, use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m     35\u001b[0m ],\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 38\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_xgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# model_log_reg_nc = Pipeline(steps=[\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#     ('preprocessor', preprocessor_nc),\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     ('selector', RFE(LogisticRegressionCV(cv=5, max_iter=2000), n_features_to_select=10)),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# y_pred = model_log_reg_nc.predict(X_test)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# print( f'Accuracy for MS Model: {accuracy_score(y_true=y_test, y_pred=y_pred)}')\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:684\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    682\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 684\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:411\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    410\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 411\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:866\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/pipeline.py:654\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    651\u001b[0m     )\n\u001b[1;32m    653\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 654\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/pipeline.py:588\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m    582\u001b[0m step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    583\u001b[0m     step_idx\u001b[38;5;241m=\u001b[39mstep_idx,\n\u001b[1;32m    584\u001b[0m     step_params\u001b[38;5;241m=\u001b[39mrouted_params[name],\n\u001b[1;32m    585\u001b[0m     all_params\u001b[38;5;241m=\u001b[39mraw_params,\n\u001b[1;32m    586\u001b[0m )\n\u001b[0;32m--> 588\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/pipeline.py:1551\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1551\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1554\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1555\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:921\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:276\u001b[0m, in \u001b[0;36mRFE.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m Bunch(estimator\u001b[38;5;241m=\u001b[39mBunch(fit\u001b[38;5;241m=\u001b[39mfit_params))\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:332\u001b[0m, in \u001b[0;36mRFE._fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[0;32m--> 332\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m    335\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[1;32m    336\u001b[0m     estimator,\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[1;32m    338\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    339\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1994\u001b[0m, in \u001b[0;36mLogisticRegressionCV.fit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1992\u001b[0m     prefer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocesses\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1994\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1997\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2007\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintercept_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2015\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2016\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2018\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2019\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_encoded_labels\u001b[49m\n\u001b[1;32m   2020\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\n\u001b[1;32m   2021\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml1_ratios_\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# _log_reg_scoring_path will output different shapes depending on the\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# multi_class param, so we need to reshape the outputs accordingly.\u001b[39;00m\n\u001b[1;32m   2026\u001b[0m \u001b[38;5;66;03m# Cs is of shape (n_classes . n_folds . n_l1_ratios, n_Cs) and all the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2033\u001b[0m \u001b[38;5;66;03m#  (n_classes, n_folds, n_Cs . n_l1_ratios) or\u001b[39;00m\n\u001b[1;32m   2034\u001b[0m \u001b[38;5;66;03m#  (1, n_folds, n_Cs . n_l1_ratios)\u001b[39;00m\n\u001b[1;32m   2035\u001b[0m coefs_paths, Cs, scores, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:746\u001b[0m, in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight, l1_ratio, score_params)\u001b[0m\n\u001b[1;32m    743\u001b[0m     sw_train \u001b[38;5;241m=\u001b[39m sample_weight[train]\n\u001b[1;32m    744\u001b[0m     sw_test \u001b[38;5;241m=\u001b[39m sample_weight[test]\n\u001b[0;32m--> 746\u001b[0m coefs, Cs, n_iter \u001b[38;5;241m=\u001b[39m \u001b[43m_logistic_regression_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msw_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39msolver, multi_class\u001b[38;5;241m=\u001b[39mmulti_class)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# The score method of Logistic Regression has a classes_ attribute.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:451\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    447\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[1;32m    448\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    449\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    450\u001b[0m ]\n\u001b[0;32m--> 451\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    466\u001b[0m     solver,\n\u001b[1;32m    467\u001b[0m     opt_res,\n\u001b[1;32m    468\u001b[0m     max_iter,\n\u001b[1;32m    469\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    470\u001b[0m )\n\u001b[1;32m    471\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/scipy/optimize/_minimize.py:738\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    735\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    736\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 738\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    741\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    742\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/scipy/optimize/_lbfgsb_py.py:441\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    433\u001b[0m _lbfgsb\u001b[38;5;241m.\u001b[39msetulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[1;32m    434\u001b[0m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:344\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x(x)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:295\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 295\u001b[0m         fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m fx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_f:\n\u001b[1;32m    297\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lowest_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/scipy/optimize/_differentiable_functions.py:21\u001b[0m, in \u001b[0;36m_wrapper_fun.<locals>.wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     17\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/scipy/optimize/_optimize.py:80\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     79\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/scipy/optimize/_optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 74\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/linear_model/_linear_loss.py:338\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    336\u001b[0m grad[:, :n_features] \u001b[38;5;241m=\u001b[39m grad_pointwise\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m X \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 338\u001b[0m     grad[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_pointwise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coef\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    340\u001b[0m     grad \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mravel(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip install xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "\n",
    "final_features = features_ew + features_ms\n",
    "\n",
    "y_nc = df_train['NationalChampion']\n",
    "# y_nc.nunique()\n",
    "\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[final_features], y_nc, stratify=  y_nc, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# preprocessor_nc = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', StandardScaler(), numerical_features_ew + numerical_features_ms ),\n",
    "#         ('ord', sigmoid_transformer, ordinal_features_ew + ordinal_features_ms)\n",
    "#     ],\n",
    "#     remainder='passthrough'\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "model_xgb = Pipeline(steps=[\n",
    "    ('selector', RFE(LogisticRegressionCV(cv=5, max_iter=2000), n_features_to_select=10)),\n",
    "    ('classifier', XGBClassifier(objective='multi:softmax', num_class=64, eval_metric='mlogloss', use_label_encoder=False))\n",
    "],\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(model_xgb, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# model_log_reg_nc = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor_nc),\n",
    "#     ('selector', RFE(LogisticRegressionCV(cv=5, max_iter=2000), n_features_to_select=10)),\n",
    "#     ('classifier', LogisticRegressionCV(cv=5, max_iter=2000, multi_class='multinomial', solver='lbfgs'))\n",
    "# ])\n",
    "\n",
    "# model_log_reg_nc.fit(X_train, y_train)\n",
    "# y_pred = model_log_reg_nc.predict(X_test)\n",
    "# print( f'Accuracy for MS Model: {accuracy_score(y_true=y_test, y_pred=y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RegionWinner_East', 'RegionWinner_West', 'RegionWinner_South',\n",
      "       'RegionWinner_Midwest', 'SemifinalWinner_East_West',\n",
      "       'SemifinalWinner_South_Midwest', 'NationalChampion',\n",
      "       'E_InstitutionEnrollment_Total', 'E_Rk', 'E_Seed_Rank', 'E_NetRtg',\n",
      "       'E_Luck', 'M_InstitutionEnrollment_Total', 'M_Rk', 'M_Seed_Rank',\n",
      "       'M_NetRtg', 'M_Luck', 'S_InstitutionEnrollment_Total', 'S_Rk',\n",
      "       'S_Seed_Rank', 'S_NetRtg', 'S_Luck', 'W_InstitutionEnrollment_Total',\n",
      "       'W_Rk', 'W_Seed_Rank', 'W_NetRtg', 'W_Luck', 'm_win_%', 's_win_%',\n",
      "       'e_win_%', 'w_win_%', 'E_dist_prob', 'W_dist_prob', 'M_dist_prob',\n",
      "       'S_dist_prob', 'National_Champ_Label', 'EW_InstitutionEnrollment_Total',\n",
      "       'EW_Rk', 'EW_Seed_Rank', 'EW_NetRtg', 'EW_Luck', 'EW_win_%',\n",
      "       'EW_dist_prob', 'MS_InstitutionEnrollment_Total', 'MS_Rk',\n",
      "       'MS_Seed_Rank', 'MS_NetRtg', 'MS_Luck', 'MS_win_%', 'MS_dist_prob'],\n",
      "      dtype='object')\n",
      "Cross-Validation Accuracy: 0.6375 ± 0.0044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# df_train\n",
    "\n",
    "df_test['Pred_SemifinalWinner_East_West'] = predictions_df['SemifinalWinner_East_West']\n",
    "df_test['Pred_SemifinalWinner_South_Midwest'] = predictions_df['SemifinalWinner_South_Midwest']\n",
    "\n",
    "\n",
    "\n",
    "# Define mappings for the EW group: (suffix, true_prefix, false_prefix)\n",
    "ew_cols = [\n",
    "    (\"InstitutionEnrollment_Total\", \"E_\", \"W_\"),\n",
    "    (\"Rk\", \"E_\", \"W_\"),\n",
    "    (\"Seed_Rank\", \"E_\", \"W_\"),\n",
    "    (\"NetRtg\", \"E_\", \"W_\"),\n",
    "    (\"Luck\", \"E_\", \"W_\"),\n",
    "    (\"win_%\", \"e_\", \"w_\"),\n",
    "    ('dist_prob', 'E_','W_')\n",
    "]\n",
    "\n",
    "# Define mappings for the MS group: (suffix, true_prefix, false_prefix)\n",
    "ms_cols = [\n",
    "     (\"InstitutionEnrollment_Total\", \"M_\", \"S_\"),\n",
    "    (\"Rk\", \"M_\", \"S_\"),\n",
    "    (\"Seed_Rank\", \"M_\", \"S_\"),\n",
    "    (\"NetRtg\", \"M_\", \"S_\"),\n",
    "    (\"Luck\", \"M_\", \"S_\"),\n",
    "    (\"win_%\", \"m_\", \"s_\"),\n",
    "    ('dist_prob', 'M_','S_')\n",
    "]\n",
    "drop_list = []\n",
    "\n",
    "print(df_train.columns)\n",
    "# Create EW columns in the training dataset\n",
    "for suffix, true_prefix, false_prefix in ew_cols:\n",
    "    new_col = \"EW_\" + suffix\n",
    "    df_train[new_col] = df_train[true_prefix + suffix].where(\n",
    "        df_train[\"SemifinalWinner_East_West\"] == df_train[\"RegionWinner_East\"],\n",
    "        df_train[false_prefix + suffix]\n",
    "    )\n",
    "    if f'true_prefix + suffix'.startswith('E_'):\n",
    "        drop_list.append(f'{false_prefix + suffix}')\n",
    "    else:\n",
    "        drop_list.append(f'{true_prefix + suffix}')\n",
    "\n",
    "\n",
    "# Create MS columns in the training dataset\n",
    "for suffix, true_prefix, false_prefix in ms_cols:\n",
    "    new_col = \"MS_\" + suffix\n",
    "    df_train[new_col] = df_train[true_prefix + suffix].where(\n",
    "        df_train[\"SemifinalWinner_South_Midwest\"] == df_train[\"RegionWinner_Midwest\"],\n",
    "        df_train[false_prefix + suffix]\n",
    "    )\n",
    "    if f'true_prefix + suffix'.startswith('M_'):\n",
    "        drop_list.append(f'{false_prefix + suffix}')\n",
    "    else:\n",
    "        drop_list.append(f'{true_prefix + suffix}')\n",
    "\n",
    "# For the test dataset\n",
    "# Assume df_test is already loaded and classic1_df_test is available for source values.\n",
    "nat_champ_df_test = df_test\n",
    "\n",
    "# Create EW columns in the test dataset\n",
    "for suffix, true_prefix, false_prefix in ew_cols:\n",
    "    new_col = \"EW_\" + suffix\n",
    "    df_test[new_col] = df_test[true_prefix + suffix].where(\n",
    "        df_test[\"Pred_SemifinalWinner_East_West\"] == df_test[\"RegionWinner_East\"],\n",
    "        df_test[false_prefix + suffix]\n",
    "    )\n",
    "\n",
    "# Create MS columns in the test dataset\n",
    "for suffix, true_prefix, false_prefix in ms_cols:\n",
    "    new_col = \"MS_\" + suffix\n",
    "    df_test[new_col] = df_test[true_prefix + suffix].where(\n",
    "        df_test[\"Pred_SemifinalWinner_South_Midwest\"] == df_test[\"RegionWinner_Midwest\"],\n",
    "        df_test[false_prefix + suffix]\n",
    "    )\n",
    "\n",
    "df_train_xgb = df_train.drop(columns=[col for col in df_train.columns if not (col.startswith('EW_') or col.startswith('MS_'))])\n",
    "df_test_xgb = df_test.drop(columns=[col for col in df_test.columns if not (col.startswith('EW_') or col.startswith('MS_'))])\n",
    "\n",
    "\n",
    "# 🎯 1️⃣ Create Binary Target Variable\n",
    "y_xgb = (df_train['NationalChampion'] == df_train['SemifinalWinner_East_West']).astype(int)\n",
    "\n",
    "# 🎯 2️⃣ Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_xgb, y_xgb, test_size=0.2, random_state=42, stratify=y_xgb)\n",
    "\n",
    "# 🎯 3️⃣ Define XGBoost Model\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='binary:logistic',  # Binary classification\n",
    "    eval_metric='logloss',        # Log loss for binary problems\n",
    "    use_label_encoder=False,\n",
    "    max_depth=3,\n",
    "    n_estimators=50,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8\n",
    ")\n",
    "\n",
    "# 🎯 4️⃣ Set Up Cross-Validation (5-Fold Stratified)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Cross-Validation\n",
    "cv_scores = cross_val_score(xgb_clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# 🎯 5️⃣ Print Cross-Validation Results\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "print(confusion_matrix())\n",
    "\n",
    "# # 🎯 6️⃣ Train Final Model on Full Training Data\n",
    "# xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# # 🎯 7️⃣ Predict on Test Set\n",
    "# y_pred_proba = xgb_clf.predict_proba(X_test)[:, 1]  # Get probabilities for class 1 (EW wins)\n",
    "# y_pred_binary = (y_pred_proba >= 0.5).astype(int)   # Convert to binary predictions\n",
    "\n",
    "# # 🎯 8️⃣ Store Predictions in df_test\n",
    "# df_test['Predicted_Champion_Group'] = y_pred_binary  # 1 = EW wins, 0 = MW/S wins\n",
    "\n",
    "# # Print a few prediction results\n",
    "# print(df_test[['Predicted_Champion_Group']].head())\n",
    "\n",
    "\n",
    "# y_xgb = (df_train['NationalChampion'] == df_train['SemifinalWinner_East_West']).astype(int)\n",
    "\n",
    "# # Train/Test Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_train_xgb, y_xgb, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Encode labels so they start from 0\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "# y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# # Train XGB Model\n",
    "# xgb_clf = XGBClassifier(\n",
    "#     objective='multi:softmax',\n",
    "#     num_class=len(label_encoder.classes_),  # Ensure num_class matches the actual number of labels\n",
    "#     eval_metric='mlogloss',\n",
    "#     use_label_encoder=False,\n",
    "#     max_depth=3,\n",
    "#     n_estimators=50,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8\n",
    "# )\n",
    "# xgb_clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "# # Predict and convert predictions back to original team IDs\n",
    "# y_pred = xgb_clf.predict(X_test)\n",
    "# y_pred_original = label_encoder.inverse_transform(y_pred).where(df_test['NationalChampion'] == df_train['SemifinalWinner_East_West'])  # Converts back to original labels\n",
    "# # Print Accuracy\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# print(\"Test Accuracy:\", accuracy_score(y_test_encoded, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SemifinalWinner_East_West</th>\n",
       "      <th>SemifinalWinner_South_Midwest</th>\n",
       "      <th>NationalChampion</th>\n",
       "      <th>BracketEntryID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2074118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2692634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1252684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1950205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2756293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14440</th>\n",
       "      <td>164</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2085292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14441</th>\n",
       "      <td>164</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>615949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14442</th>\n",
       "      <td>29</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>13727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>164</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3019220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14444</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3032491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14445 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SemifinalWinner_East_West SemifinalWinner_South_Midwest  \\\n",
       "0                            164                          None   \n",
       "1                            164                          None   \n",
       "2                            311                          None   \n",
       "3                            164                          None   \n",
       "4                            164                          None   \n",
       "...                          ...                           ...   \n",
       "14440                        164                          None   \n",
       "14441                        164                          None   \n",
       "14442                         29                          None   \n",
       "14443                        164                          None   \n",
       "14444                         37                          None   \n",
       "\n",
       "      NationalChampion  BracketEntryID  \n",
       "0                 None         2074118  \n",
       "1                 None         2692634  \n",
       "2                 None         1252684  \n",
       "3                 None         1950205  \n",
       "4                 None         2756293  \n",
       "...                ...             ...  \n",
       "14440             None         2085292  \n",
       "14441             None          615949  \n",
       "14442             None           13727  \n",
       "14443             None         3019220  \n",
       "14444             None         3032491  \n",
       "\n",
       "[14445 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize predictions DataFrame\n",
    "# Create an empty DataFrame with correct columns, initialized with NaNs\n",
    "predictions_df = pd.DataFrame({\n",
    "    'SemifinalWinner_East_West': [None] * len(df_test),  \n",
    "    'SemifinalWinner_South_Midwest': [None] * len(df_test),  \n",
    "    'NationalChampion': [None] * len(df_test),\n",
    "    'BracketEntryID': classic1_df_test['BracketEntryId'].values  # Copy BracketEntryId from df_test\n",
    "})\n",
    "\n",
    "# datamap = {'SemifinalWinner_East_West':np.array(14445), 'SemifinalWinner_South_Midwest': np.array(14445), 'NationalChamion': np.array(14445)}\n",
    "# predictions_df = pd.DataFrame(datamap)\n",
    "\n",
    "model_log_reg_ew.fit(df_train[features_ew],y_ew)\n",
    "y_pred_ew_csv = model_log_reg_ew.predict(df_test[features_ew])\n",
    "predictions_df['SemifinalWinner_East_West'] = df_test['RegionWinner_East'].where(y_pred_ew_csv == 1, df_test['RegionWinner_West'])\n",
    "\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_log_reg_ms.fit(df_train[features_ms], y_ms)\n",
    "y_pred_ms_csv = model_log_reg_ms.predict(df_test[features_ms])\n",
    "predictions_df['SemifinalWinner_South_Midwest'] = df_test['RegionWinner_Midwest'].where(y_pred_ms_csv == 1, df_test['RegionWinner_South'])\n",
    "\n",
    "\n",
    "\n",
    "# 🎯 6️⃣ Train Final Model on Full Training Data\n",
    "xgb_clf.fit(df_train_xgb, y_xgb)\n",
    "\n",
    "# # 🎯 7️⃣ Predict on Test Set\n",
    "y_pred_proba = xgb_clf.predict_proba(df_test_xgb)[:, 1]  # Get probabilities for class 1 (EW wins)\n",
    "y_pred_binary = (y_pred_proba >= 0.5).astype(int)   # Convert to binary predictions\n",
    "\n",
    "# 🎯 8️⃣ Store Predictions in df_test\n",
    "predictions_df['NationalChampion'] = df_test['Pred_SemifinalWinner_East_West'].where(y_pred_binary == 1, df_test['Pred_SemifinalWinner_South_Midwest']) # 1 = EW wins, 0 = MW/S wins\n",
    "\n",
    "\n",
    "# # Predict and convert predictions back to original team IDs\n",
    "# y_pred = xgb_clf.predict(df_test[final_features])\n",
    "# predictions_df['NationalChampion'] = label_encoder.inverse_transform(y_pred)  # Converts back to original labels\n",
    "# predictions_df['BracketEntryId'] = classic1_df_test['BracketEntryId']\n",
    "\n",
    "predictions_df.loc[:, ['BracketEntryId','SemifinalWinner_East_West','SemifinalWinner_South_Midwest', 'NationalChampion']].to_csv('prediction_uf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [26001, 14445]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:340\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03mBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m(np.int64(0), np.int64(2), np.int64(1), np.int64(1))\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 340\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:98\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [26001, 14445]"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 4ms/step - accuracy: 0.2900 - loss: 849.4430 - val_accuracy: 0.2287 - val_loss: 17.9023\n",
      "Epoch 2/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.2919 - loss: 18.2522 - val_accuracy: 0.2026 - val_loss: 22.6931\n",
      "Epoch 3/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6ms/step - accuracy: 0.2945 - loss: 12.8561 - val_accuracy: 0.3550 - val_loss: 4.9327\n",
      "Epoch 4/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.2942 - loss: 10.2109 - val_accuracy: 0.2292 - val_loss: 10.9382\n",
      "Epoch 5/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.2896 - loss: 8.3060 - val_accuracy: 0.3471 - val_loss: 2.5656\n",
      "Epoch 6/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - accuracy: 0.3532 - loss: 3.0347 - val_accuracy: 0.3811 - val_loss: 1.3403\n",
      "Epoch 7/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5ms/step - accuracy: 0.3851 - loss: 1.3380 - val_accuracy: 0.3811 - val_loss: 1.3405\n",
      "Epoch 8/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.3828 - loss: 1.3392 - val_accuracy: 0.3811 - val_loss: 1.3402\n",
      "Epoch 9/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - accuracy: 0.3819 - loss: 1.3400 - val_accuracy: 0.3811 - val_loss: 1.3403\n",
      "Epoch 10/10\n",
      "\u001b[1m5200/5200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5ms/step - accuracy: 0.3821 - loss: 1.3398 - val_accuracy: 0.3811 - val_loss: 1.3403\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.3832 - loss: 1.3405\n",
      "Final Four Model Accuracy: 0.38\n"
     ]
    }
   ],
   "source": [
    "# %pip install scikeras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Features for predicting the National Champion\n",
    "final_features = features_ew + features_ms\n",
    "X_final = df_train[final_features]\n",
    "\n",
    "\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)\n",
    "\n",
    "numerical_features = numerical_features_ew + numerical_features_ms\n",
    "numerical_features\n",
    "preprocessor_nn = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features_ew + numerical_features_ms ),\n",
    "        ('ord', sigmoid_transformer, ordinal_features_ew + ordinal_features_ms)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# processed_data = pd.DataFrame(preprocessor_nn.fit_transform(df_train[final_features]))\n",
    "# processed_data\n",
    "# Define Softmax Neural Network\n",
    "\n",
    "# Apply preprocessor to transform features\n",
    "X_train_transformed = preprocessor_nn.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor_nn.transform(X_test)\n",
    "\n",
    "# Feature Selection (Select Top K Features)\n",
    "selector = SelectKBest(score_func=f_classif, k=10)  # Select best 10 features\n",
    "\n",
    "# X_train_selected = selector.fit_transform(X_train_transformed, y_train)\n",
    "# X_test_selected = selector.transform(X_test_transformed)\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     Dense(8, activation='relu'),\n",
    "#     Dense(4, activation='softmax')  # 4 possible final teams\n",
    "# ])\n",
    "\n",
    "# Function to build the model\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train_transformed.shape[1],)),  # Match selected features\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(4, activation='softmax')  # 4 possible final teams\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Evaluate Model\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Final Four Model Accuracy: {acc:.2f}\")\n",
    "\n",
    "\n",
    "# # Wrap Keras model in Scikit-learn wrapper\n",
    "# model_cv = KerasClassifier(build_fn=build_model, epochs=20, batch_size=16, verbose=0)\n",
    "\n",
    "# # Use Stratified K-Fold for better generalization\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Run Cross-Validation\n",
    "# scores = cross_val_score(model_cv, X_train_transformed, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# # Print average accuracy\n",
    "# print(f\"Cross-Validation Accuracy: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n",
    "\n",
    "# # Compile Model\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train Model\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# # Evaluate Model\n",
    "# loss, acc = model.evaluate(X_test, y_test)\n",
    "# print(f\"Final Four Model Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>104001.000000</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>104001.000000</td>\n",
       "      <td>1.040010e+05</td>\n",
       "      <td>104001.000000</td>\n",
       "      <td>104001.000000</td>\n",
       "      <td>104001.000000</td>\n",
       "      <td>104001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.331788e-16</td>\n",
       "      <td>-1.138053e-15</td>\n",
       "      <td>-4.153902e-17</td>\n",
       "      <td>-3.771511e-15</td>\n",
       "      <td>6.804748e-17</td>\n",
       "      <td>-5.342683e-16</td>\n",
       "      <td>-5.383676e-17</td>\n",
       "      <td>-8.665805e-16</td>\n",
       "      <td>6.674938e-17</td>\n",
       "      <td>-1.096002e-15</td>\n",
       "      <td>5.875585e-18</td>\n",
       "      <td>-3.398035e-15</td>\n",
       "      <td>3.402374e-17</td>\n",
       "      <td>-7.224920e-16</td>\n",
       "      <td>-4.638980e-17</td>\n",
       "      <td>8.841731e-16</td>\n",
       "      <td>0.162825</td>\n",
       "      <td>1.845654e-01</td>\n",
       "      <td>1.006007e-03</td>\n",
       "      <td>1.429032e-01</td>\n",
       "      <td>5.262821e-02</td>\n",
       "      <td>1.465338e-01</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>1.362086e-01</td>\n",
       "      <td>0.540601</td>\n",
       "      <td>0.459399</td>\n",
       "      <td>0.477516</td>\n",
       "      <td>0.522484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>1.000005e+00</td>\n",
       "      <td>0.129350</td>\n",
       "      <td>1.072859e-01</td>\n",
       "      <td>1.173805e-03</td>\n",
       "      <td>9.835210e-02</td>\n",
       "      <td>5.911844e-02</td>\n",
       "      <td>1.129957e-01</td>\n",
       "      <td>0.022043</td>\n",
       "      <td>1.099385e-01</td>\n",
       "      <td>0.226829</td>\n",
       "      <td>0.226829</td>\n",
       "      <td>0.210189</td>\n",
       "      <td>0.210189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.148239e+00</td>\n",
       "      <td>-5.616935e+00</td>\n",
       "      <td>-2.389426e+00</td>\n",
       "      <td>-3.023691e+00</td>\n",
       "      <td>-2.796925e+00</td>\n",
       "      <td>-9.492818e+00</td>\n",
       "      <td>-3.136170e+00</td>\n",
       "      <td>-4.640026e+00</td>\n",
       "      <td>-1.933965e+00</td>\n",
       "      <td>-4.144513e+00</td>\n",
       "      <td>-1.733620e+00</td>\n",
       "      <td>-2.301930e+00</td>\n",
       "      <td>-1.608261e+00</td>\n",
       "      <td>-5.652382e+00</td>\n",
       "      <td>-1.468408e+00</td>\n",
       "      <td>-2.563632e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.125352e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.125352e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.125352e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.125352e-07</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.072356e-01</td>\n",
       "      <td>-8.222277e-01</td>\n",
       "      <td>-2.969975e-01</td>\n",
       "      <td>-9.103094e-01</td>\n",
       "      <td>-4.378313e-01</td>\n",
       "      <td>-4.681730e-01</td>\n",
       "      <td>-6.130422e-01</td>\n",
       "      <td>7.936558e-02</td>\n",
       "      <td>-3.405994e-01</td>\n",
       "      <td>-9.906292e-01</td>\n",
       "      <td>-1.161603e+00</td>\n",
       "      <td>-8.207227e-01</td>\n",
       "      <td>-1.391278e+00</td>\n",
       "      <td>-2.261383e-01</td>\n",
       "      <td>-8.965028e-01</td>\n",
       "      <td>-9.293395e-01</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>4.742587e-02</td>\n",
       "      <td>8.315280e-07</td>\n",
       "      <td>4.742587e-02</td>\n",
       "      <td>1.026188e-10</td>\n",
       "      <td>4.742587e-02</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>4.742587e-02</td>\n",
       "      <td>0.387592</td>\n",
       "      <td>0.290105</td>\n",
       "      <td>0.333009</td>\n",
       "      <td>0.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.072356e-01</td>\n",
       "      <td>7.192600e-01</td>\n",
       "      <td>5.961120e-01</td>\n",
       "      <td>7.803954e-01</td>\n",
       "      <td>-4.378313e-01</td>\n",
       "      <td>4.162203e-01</td>\n",
       "      <td>-1.845866e-01</td>\n",
       "      <td>7.936558e-02</td>\n",
       "      <td>1.748893e-01</td>\n",
       "      <td>2.049827e-01</td>\n",
       "      <td>6.259524e-01</td>\n",
       "      <td>-4.660674e-01</td>\n",
       "      <td>5.871522e-01</td>\n",
       "      <td>1.880655e-01</td>\n",
       "      <td>4.303184e-01</td>\n",
       "      <td>-1.467207e-01</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>1.233946e-04</td>\n",
       "      <td>1.192029e-01</td>\n",
       "      <td>9.110512e-04</td>\n",
       "      <td>1.192029e-01</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>1.192029e-01</td>\n",
       "      <td>0.520970</td>\n",
       "      <td>0.479030</td>\n",
       "      <td>0.476991</td>\n",
       "      <td>0.523009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.610062e-01</td>\n",
       "      <td>7.192600e-01</td>\n",
       "      <td>5.961120e-01</td>\n",
       "      <td>7.803954e-01</td>\n",
       "      <td>8.436392e-01</td>\n",
       "      <td>5.147905e-01</td>\n",
       "      <td>-1.369804e-01</td>\n",
       "      <td>7.936245e-01</td>\n",
       "      <td>8.986578e-01</td>\n",
       "      <td>9.876256e-01</td>\n",
       "      <td>7.927909e-01</td>\n",
       "      <td>1.036002e+00</td>\n",
       "      <td>8.713427e-01</td>\n",
       "      <td>8.830267e-01</td>\n",
       "      <td>7.963380e-01</td>\n",
       "      <td>1.074639e+00</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>2.472623e-03</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>1.192029e-01</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>0.709895</td>\n",
       "      <td>0.612408</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.666991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.304279e+00</td>\n",
       "      <td>7.192600e-01</td>\n",
       "      <td>3.351993e+00</td>\n",
       "      <td>7.803954e-01</td>\n",
       "      <td>1.864772e+00</td>\n",
       "      <td>5.147905e-01</td>\n",
       "      <td>4.861669e+00</td>\n",
       "      <td>2.448615e+00</td>\n",
       "      <td>1.742607e+00</td>\n",
       "      <td>9.876256e-01</td>\n",
       "      <td>2.008328e+00</td>\n",
       "      <td>1.369795e+00</td>\n",
       "      <td>9.052892e-01</td>\n",
       "      <td>8.830267e-01</td>\n",
       "      <td>2.992456e+00</td>\n",
       "      <td>1.454091e+00</td>\n",
       "      <td>0.268941</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>2.472623e-03</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>1.192029e-01</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>0.047426</td>\n",
       "      <td>2.689414e-01</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.999859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  1.040010e+05  1.040010e+05  1.040010e+05  1.040010e+05  1.040010e+05   \n",
       "mean   2.331788e-16 -1.138053e-15 -4.153902e-17 -3.771511e-15  6.804748e-17   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "min   -5.148239e+00 -5.616935e+00 -2.389426e+00 -3.023691e+00 -2.796925e+00   \n",
       "25%   -3.072356e-01 -8.222277e-01 -2.969975e-01 -9.103094e-01 -4.378313e-01   \n",
       "50%   -3.072356e-01  7.192600e-01  5.961120e-01  7.803954e-01 -4.378313e-01   \n",
       "75%    3.610062e-01  7.192600e-01  5.961120e-01  7.803954e-01  8.436392e-01   \n",
       "max    2.304279e+00  7.192600e-01  3.351993e+00  7.803954e-01  1.864772e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  1.040010e+05  1.040010e+05  1.040010e+05  1.040010e+05  1.040010e+05   \n",
       "mean  -5.342683e-16 -5.383676e-17 -8.665805e-16  6.674938e-17 -1.096002e-15   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "min   -9.492818e+00 -3.136170e+00 -4.640026e+00 -1.933965e+00 -4.144513e+00   \n",
       "25%   -4.681730e-01 -6.130422e-01  7.936558e-02 -3.405994e-01 -9.906292e-01   \n",
       "50%    4.162203e-01 -1.845866e-01  7.936558e-02  1.748893e-01  2.049827e-01   \n",
       "75%    5.147905e-01 -1.369804e-01  7.936245e-01  8.986578e-01  9.876256e-01   \n",
       "max    5.147905e-01  4.861669e+00  2.448615e+00  1.742607e+00  9.876256e-01   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  1.040010e+05  1.040010e+05  1.040010e+05  1.040010e+05  1.040010e+05   \n",
       "mean   5.875585e-18 -3.398035e-15  3.402374e-17 -7.224920e-16 -4.638980e-17   \n",
       "std    1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00  1.000005e+00   \n",
       "min   -1.733620e+00 -2.301930e+00 -1.608261e+00 -5.652382e+00 -1.468408e+00   \n",
       "25%   -1.161603e+00 -8.207227e-01 -1.391278e+00 -2.261383e-01 -8.965028e-01   \n",
       "50%    6.259524e-01 -4.660674e-01  5.871522e-01  1.880655e-01  4.303184e-01   \n",
       "75%    7.927909e-01  1.036002e+00  8.713427e-01  8.830267e-01  7.963380e-01   \n",
       "max    2.008328e+00  1.369795e+00  9.052892e-01  8.830267e-01  2.992456e+00   \n",
       "\n",
       "                 15             16            17            18            19  \\\n",
       "count  1.040010e+05  104001.000000  1.040010e+05  1.040010e+05  1.040010e+05   \n",
       "mean   8.841731e-16       0.162825  1.845654e-01  1.006007e-03  1.429032e-01   \n",
       "std    1.000005e+00       0.129350  1.072859e-01  1.173805e-03  9.835210e-02   \n",
       "min   -2.563632e+00       0.000000  1.125352e-07  0.000000e+00  1.125352e-07   \n",
       "25%   -9.293395e-01       0.000335  4.742587e-02  8.315280e-07  4.742587e-02   \n",
       "50%   -1.467207e-01       0.268941  2.689414e-01  1.233946e-04  1.192029e-01   \n",
       "75%    1.074639e+00       0.268941  2.689414e-01  2.472623e-03  2.689414e-01   \n",
       "max    1.454091e+00       0.268941  2.689414e-01  2.472623e-03  2.689414e-01   \n",
       "\n",
       "                 20            21             22            23             24  \\\n",
       "count  1.040010e+05  1.040010e+05  104001.000000  1.040010e+05  104001.000000   \n",
       "mean   5.262821e-02  1.465338e-01       0.019269  1.362086e-01       0.540601   \n",
       "std    5.911844e-02  1.129957e-01       0.022043  1.099385e-01       0.226829   \n",
       "min    0.000000e+00  1.125352e-07       0.000000  1.125352e-07       0.000029   \n",
       "25%    1.026188e-10  4.742587e-02       0.000017  4.742587e-02       0.387592   \n",
       "50%    9.110512e-04  1.192029e-01       0.006693  1.192029e-01       0.520970   \n",
       "75%    1.192029e-01  2.689414e-01       0.047426  2.689414e-01       0.709895   \n",
       "max    1.192029e-01  2.689414e-01       0.047426  2.689414e-01       0.999964   \n",
       "\n",
       "                  25             26             27  \n",
       "count  104001.000000  104001.000000  104001.000000  \n",
       "mean        0.459399       0.477516       0.522484  \n",
       "std         0.226829       0.210189       0.210189  \n",
       "min         0.000036       0.000141       0.000186  \n",
       "25%         0.290105       0.333009       0.400024  \n",
       "50%         0.479030       0.476991       0.523009  \n",
       "75%         0.612408       0.599976       0.666991  \n",
       "max         0.999971       0.999814       0.999859  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_transformed).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
